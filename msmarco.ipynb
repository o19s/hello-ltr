{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook experiments with the MSMarco Dataset, nothing that exciting to see here right now. But fun to toy with.\n",
    "\n",
    "# Setup & Indexing\n",
    "\n",
    "The next several cells we setup the SolrClient (run everytime), we download the MSMarco dataset, and index it into Solr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import SolrClient\n",
    "from ltr.index import rebuild\n",
    "\n",
    "\n",
    "client=SolrClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MSMarco Corpus and Queries -> data directory\n",
    "from ltr import download\n",
    "download_msmarco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to Solr. Docs & Question fro convenience\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "def marco_docs():\n",
    "    with open('data/msmarco-docs.tsv') as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        i = 0;\n",
    "        for row in reader:\n",
    "        \n",
    "                yield {\"id\": row[0],\n",
    "                       \"url\": row[1],\n",
    "                       \"title\": row[2],\n",
    "                       \"body\": row[3],\n",
    "                       \"type\": \"document\"}\n",
    "                i+=1\n",
    "                if i % 10000 == 0:\n",
    "                    print(\"Dumped (%s/%s) %s\" % (i, 3213835, row[1]))\n",
    "                    \n",
    "def marco_questions():\n",
    "    with open('data/msmarco-doctrain-queries.tsv') as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        i = 0;\n",
    "        for row in reader:\n",
    "        \n",
    "                yield {\"id\": 'Q' + row[0],\n",
    "                       \"url\": '',\n",
    "                       \"title\": row[1],\n",
    "                       \"body\": row[1],\n",
    "                       \"type\": \"question\"}\n",
    "                i+=1\n",
    "                if i % 10000 == 0:\n",
    "                    print(\"Dumped (q) (%s/%s) %s\" % (i, 367013, row[1]))\n",
    "                    \n",
    "\n",
    "def marco_questions_and_docs():\n",
    "    for q in marco_questions():\n",
    "        yield q\n",
    "    for d in marco_docs():\n",
    "        yield d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import SolrClient\n",
    "from ltr.index import rebuild\n",
    "\n",
    "\n",
    "client=SolrClient()\n",
    "rebuild(client, index='msmarco', doc_type='passage', doc_src=marco_questions_and_docs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out all the msmarco qrels\n",
    "\n",
    "from ltr.helpers.msmarco.evaluate import QRel\n",
    "\n",
    "qrels = {}\n",
    "\n",
    "for qrel in QRel.read_qrels():\n",
    "    qrels[qrel.qid] = qrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.helpers.solr_escape import esc_kw\n",
    "\n",
    "\n",
    "def eval_one(client, qrel, params, at=50):\n",
    "    \"\"\" Eval a single Solr query param for MRR\"\"\"\n",
    "    kw = esc_kw(qrel.keywords)\n",
    "\n",
    "    params['q'] = kw\n",
    "    params['rows'] = at\n",
    "    params['fl'] = 'id'\n",
    "    if 'fq' in params:\n",
    "        params['fq'] = [params['fq'], 'type:document']\n",
    "    else:\n",
    "        params['fq'] = \"type:document\"\n",
    "    \n",
    "    hits = client.query(index='msmarco', query=params)\n",
    "    \n",
    "    ranking = [hit['id'] for hit in hits]\n",
    "    rr = qrel.eval_rr(ranking)\n",
    "    return rr\n",
    "\n",
    "def eval_many(client, qrels, sample_qids, params):\n",
    "    \"\"\" Execute many Solr searches, return MRR\n",
    "        (this should show distribution...)\"\"\"\n",
    "    sum_rr = 0.0\n",
    "    num_evald = 0\n",
    "    \n",
    "    HIST_SLOTS = 100\n",
    "    \n",
    "    all_rrs = []\n",
    "\n",
    "    print(\"Running %s queries\" % len(sample_qids))\n",
    "\n",
    "    for qid in sample_qids:\n",
    "        qrel = qrels[qid]        \n",
    "        rr = eval_one(client, qrel, params)\n",
    "        \n",
    "        all_rrs.append(rr)\n",
    "  \n",
    "        sum_rr += rr\n",
    "        num_evald += 1\n",
    "        print(\"%s, last rr: %s, mrr: %s\" % (num_evald, rr, sum_rr / num_evald))      \n",
    "    return all_rrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(terms):\n",
    "    \"\"\" Every item in a list with it's next item \"\"\"\n",
    "    return zip(terms, terms[1:])\n",
    "\n",
    "def analyze_tokenize(client, keywords):\n",
    "    \"\"\" Use the appropriatte analyzer for bigrams\"\"\"\n",
    "    tok_stream = client.analyze(index='msmarco', fieldtype='text_general',\n",
    "                                text=keywords)\n",
    "    terms = [tok['text'] for tok in tok_stream]\n",
    "    return terms\n",
    "\n",
    "\n",
    "def phrase_search(client, qrel):\n",
    "    \"\"\"Find the bigrams that optimize mrr\"\"\"\n",
    "    params = {\"qf\": \"body\", \"defType\": \"edismax\"}\n",
    "    \n",
    "    sorted_bigrams = []\n",
    "    \n",
    "    base_rr = 0\n",
    "    \n",
    "    # Try to find the single best bigram...\n",
    "    #all_bigrams = [big for big in bigrams(qrel.keywords.split(' '))]\n",
    "    \n",
    "    all_bigrams = [big for big in bigrams(analyze_tokenize(client, qrel.keywords))]\n",
    "    all_bigrams.insert(0, ('', '') ) # Dont append any bigram\n",
    "    for idx, bigram in enumerate(all_bigrams):\n",
    "        if idx > 0 and bigram is not None and len(bigram) > 1: \n",
    "            params['fq'] = '{!lucene df=body}\"%s %s\"' % bigram\n",
    "        \n",
    "        rr = eval_one(client, qrel, params)\n",
    "        if idx == 0:\n",
    "            base_rr = rr\n",
    "        sorted_bigrams.append( (rr - base_rr, bigram, idx) )\n",
    "    sorted_bigrams.sort(key=lambda v: v[0], reverse=True)\n",
    "    return sorted_bigrams\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample first queries to build a training set\n",
    "import random\n",
    "\n",
    "\n",
    "all_qrel_keys = [k for k in qrels.keys()]\n",
    "random.shuffle(all_qrel_keys)\n",
    "gain = 0\n",
    "loss = 0\n",
    "import csv\n",
    "\n",
    "with open('data/train.csv', 'w') as f:\n",
    "    \n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for idx, qid in enumerate(all_qrel_keys):\n",
    "        qrel = qrels[qid]\n",
    "        sorted_bigrams = phrase_search(client, qrel)\n",
    "        formatted_big = [(scored_bigram[0], \n",
    "                          \"%s %s\" % (scored_bigram[1][0],scored_bigram[1][1]),\n",
    "                          scored_bigram[2]\n",
    "                         ) \n",
    "                         for scored_bigram in sorted_bigrams]\n",
    "        \n",
    "        for big in formatted_big:\n",
    "            row = (big[0], big[1], big[2], qid, qrel.keywords)\n",
    "            writer.writerow(row)\n",
    "\n",
    "        gain += formatted_big[0][0]\n",
    "        loss += formatted_big[-1][0]\n",
    "\n",
    "        if (idx % 20 == 19):\n",
    "            print(\"Generated training data %s queries\" % idx)\n",
    "            print(\"Gain/Loss %s/%s\" % (gain/(idx+1), loss/(idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rrs_title = eval_many(client, qrels, sample_qids, {\"qf\": \"title\", \"defType\": \"edismax\"})\n",
    "all_rrs_body = eval_many(client, qrels, sample_qids, {\"qf\": \"body\", \"defType\": \"edismax\"})\n",
    "all_rrs_all = eval_many(client, qrels, sample_qids, {\"qf\": \"title body url\", \"defType\": \"edismax\"})\n",
    "all_rrs_all_tie = eval_many(client, qrels, sample_qids, {\"qf\": \"title body url\", \"tie\": 1.0, \"defType\": \"edismax\"})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 18\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(15, 5)\n",
    "\n",
    "\n",
    "def draw_rr_dist(all_rrs, experiment_name):\n",
    "    bins = [0.0, 0.05,0.1,0.15,0.2,0.25,\n",
    "                 0.3,0.35,0.4,0.45,0.5,\n",
    "                 0.55,0.6,0.65,0.7,0.75,\n",
    "                 0.8,0.85,0.9,0.95,1.0]\n",
    "    \n",
    "    all_rrs = np.array(all_rrs)\n",
    "\n",
    "\n",
    "    # Make the histogram using matplotlib, bins must be integet\n",
    "    plt.hist(all_rrs, color = 'blue', edgecolor = 'black',\n",
    "             bins = bins)\n",
    "\n",
    "    # Add labels\n",
    "    plt.title('RR by Query )' + experiment_name)\n",
    "    plt.xlabel('RR'); plt.ylabel('Num Qs');\n",
    "    plt.axvline(all_rrs.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_rr_dist(all_rrs_title, \"Title Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_rr_dist(all_rrs_body, \"Body Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_rr_dist(all_rrs_all, \"Title Body Url Dismax Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_rr_dist(all_rrs_all_tie, \"Title Body Url Dismax Search, tie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rrs_all_pf2 = eval_many(client, qrels, sample_qids, \n",
    "                            {\"qf\": \"body\",\n",
    "                             \"pf2\": \"body\",\n",
    "                             \"tie\": 1.0, \n",
    "                             \"defType\": \"edismax\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
