{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from ltr.client import OpenSearchClient\n",
    "client = OpenSearchClient()\n",
    "\n",
    "host = client.get_host()\n",
    "port = 9201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the index if necessary\n",
    "from ltr import download\n",
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "download([corpus], dest='data/');\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Default Feature Store\n",
    "The feature store can be removed by sending a DELETE request to `_ltr` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'http://{host}:{port}/_ltr/'\n",
    "print(url)\n",
    "requests.delete(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the LTR plugin, issue a PUT request to the `_ltr` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)\n",
    "requests.put(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Set\n",
    "\n",
    "A feature set can be created by issuing a PUT to `_ltr/featureset/[feature_name]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "   \"featureset\": {\n",
    "      \"features\": [\n",
    "         {\n",
    "            \"name\": \"title_bm25\",\n",
    "            \"params\": [\n",
    "               \"keywords\"\n",
    "            ],\n",
    "            \"template\": {\n",
    "                     \"match\": {\n",
    "                        \"title\": \"{{keywords}}\"\n",
    "                     }\n",
    "               }\n",
    "         },\n",
    "         {\n",
    "            \"name\": \"overview_bm25\",\n",
    "            \"params\": [\n",
    "               \"keywords\"\n",
    "            ],\n",
    "            \"template\": {\n",
    "                     \"match\": {\n",
    "                        \"overview\": \"{{keywords}}\"\n",
    "                     }\n",
    "               }\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "     \"validation\": {\n",
    "      \"index\": \"tmdb\",\n",
    "      \"params\": {\n",
    "         \"keywords\": \"rambo\"\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "feature_set_url = f'{url}_featureset/my_feature_set'\n",
    "print(feature_set_url)\n",
    "requests.put(feature_set_url, json=feature_set)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Some Judged Queries To Build Training Set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have 4 judged documents: 7555,1370, 1369, and 1368 for keywords rambo:\n",
    "\n",
    "```\n",
    "doc_id, relevant?, keywords\n",
    "1368, 1, rambo\n",
    "1369, 1, rambo\n",
    "1370, 1, rambo\n",
    "7555, 0, rambo\n",
    "```\n",
    "\n",
    "\n",
    "We need to get feature value for each row.\n",
    "\n",
    "To do this, we utilize the logging extension to populate the judgment list with features for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_log = {\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": [\n",
    "        {\n",
    "          \"sltr\": {\n",
    "            \"_name\": \"logged_features\",\n",
    "            \"featureset\": \"my_feature_set\",\n",
    "            \"params\": {\n",
    "              \"keywords\": \"rambo\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "         {\n",
    "          \"terms\": {\n",
    "            \"_id\": [\n",
    "              \"7555\",\"1370\", \"1369\", \"1368\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"ext\": {\n",
    "    \"ltr_log\": {\n",
    "      \"log_specs\": {\n",
    "        \"name\": \"ltr_features\",\n",
    "        \"named_query\": \"logged_features\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "search_with_log_url = f'http://{host}:{port}/tmdb/_search'\n",
    "print(search_with_log_url)\n",
    "resp = requests.get(search_with_log_url, json=search_with_log).json()\n",
    "print(json.dumps(resp['hits']['hits'][0], indent=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Now...\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "doc_id, relevant?, keywords, title_bm25, overview_bm25\n",
    "1368, 1, rambo, 0, 11.113943\n",
    "1369, 1, rambo, 11.657, 10.08\n",
    "1370, 1, rambo, 9.456, 13.265\n",
    "7555, 0, rambo, 6.037, 11.114\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model\n",
    "\n",
    "We won't do this here, but if you like you can try out training a model using Ranklib \n",
    "\n",
    "```\n",
    "cd notebooks/elasticsearch/tmdb\n",
    "java -jar data/RankyMcRankFace.jar -train data/title_judgments.txt -save data/model.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading a Model\n",
    "Once features have been logged and training data has been generated, a model can be pushed into OpenSearch.  The following shows what a request to PUT a new model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"## LambdaMART\n",
    "## No. of trees = 10\n",
    "## No. of leaves = 10\n",
    "## No. of threshold candidates = 256\n",
    "## Learning rate = 0.1\n",
    "## Stop early = 100\n",
    "\n",
    "<ensemble>\n",
    "\t<tree id=\"1\" weight=\"0.1\">\n",
    "\t\t<split>\n",
    "\t\t\t<feature> 2 </feature>\n",
    "\t\t\t<threshold> 10.664251 </threshold>\n",
    "\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t<output> -1.8305741548538208 </output>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t<threshold> 9.502127 </threshold>\n",
    "\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t<threshold> 7.0849166 </threshold>\n",
    "\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t<output> 0.23645669221878052 </output>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t<output> 1.7593677043914795 </output>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t<output> 1.9719607830047607 </output>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t</split>\n",
    "\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t<output> 1.3728954792022705 </output>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t<threshold> 8.602512 </threshold>\n",
    "\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t\t\t<threshold> 13.815164 </threshold>\n",
    "\t\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.9401178359985352 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.99532949924469 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t\t<threshold> 11.085816 </threshold>\n",
    "\t\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t\t<output> 2.0 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.99308180809021 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t<output> 1.9870178699493408 </output>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t</split>\n",
    "\t\t</split>\n",
    "\t</tree>\n",
    "</ensemble>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "create_model = {\n",
    "  \"model\": {\n",
    "     \"name\": \"my_model\",\n",
    "     \"model\": {\n",
    "         \"type\": \"model/ranklib\",\n",
    "         \"definition\": model\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9201/_ltr/_featureset/my_feature_set/_createmodel'.format(host)\n",
    "print(url)\n",
    "requests.post(url, json=create_model).json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with a Model\n",
    "Now that a model has been uploaded to Elasticsearch we can use it to re-rank the results of a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = {\n",
    "  \"query\": {\n",
    "      \"sltr\": {\n",
    "          \"params\": {\n",
    "              \"keywords\": \"rambo\"\n",
    "          },\n",
    "          \"model\": \"my_model\"\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9201/tmdb/_search'.format(host)\n",
    "resp = requests.get(url, json=search).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(hit['_source']['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
