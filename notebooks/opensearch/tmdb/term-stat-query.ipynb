{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TermStatQuery\n",
    "## Note: still need to work on this for OpenSearch\n",
    "Introduced in ES-LTR v1.5.2, the TermStatQuery provides for access to deep level statistics available in Lucene expression and Painless scripting contexts.\n",
    "\n",
    "This allows feature engineers to easily experiment with features derived directly from the index without having to write any Java code.\n",
    "\n",
    "Review the documentation [here](https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/advanced-functionality.html#termstat-query) and use the notebook below to experiment with the functionality that the TermStatQuery provides.\n",
    "\n",
    "The TermStatQuery seems to not work equally well with OpenSearch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import OpenSearchClient\n",
    "import ltr.index as index\n",
    "import ltr.helpers.movies as helpers\n",
    "client = OpenSearchClient()\n",
    "\n",
    "from ltr import download\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments.txt'\n",
    "download([corpus, judgments], dest='data/')\n",
    "\n",
    "movies = helpers.indexable_movies(movies='data/tmdb.json')\n",
    "\n",
    "index.rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Create a Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  TASK:\n",
    "  Experiment with the TermStatQuery\n",
    "  - Create a feature that utilizes a lucene expression.\n",
    "  - Create a feature that utilizes painless scripting\n",
    "'''\n",
    "\n",
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = {\n",
    "   \"featureset\": {\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"name\": \"tsq_script_title_unique_terms\",\n",
    "                \"params\": [\"keywordsList\"],\n",
    "                \"template_language\": \"script_feature\",\n",
    "                \"template\": {\n",
    "                    \"lang\": \"painless\",\n",
    "                    \"source\": \"params.uniqueTerms\",\n",
    "                    \"params\": {\n",
    "                        \"term_stat\": {\n",
    "                            \"analyzer\": \"!standard\",\n",
    "                            \"terms\": \"keywordsList\",\n",
    "                            \"fields\": [\"title\"]\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "client.create_featureset(index='tmdb', name='tsq', ftr_config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Log Features for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open, judgments_to_dataframe\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='tsq')\n",
    "with judgments_open('data/title_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))\n",
    "\n",
    "df = judgments_to_dataframe(ftr_logger.logged)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  TASK:\n",
    "  Experiment with the leafs and trees variables, how do they affect NGCG?\n",
    "  Does a high leaf value increase your NDCG?  What could be the potential downfalls?\n",
    "'''\n",
    "from ltr.ranklib import train\n",
    "trainResponse  = train(client,\n",
    "                  index='tmdb',\n",
    "                  training_set=ftr_logger.logged,\n",
    "                  metric2t='NDCG@10',\n",
    "                  leafs=20,\n",
    "                  trees=20,\n",
    "                  featureSet='tsq',\n",
    "                  modelName='tsq')\n",
    "\n",
    "trainLog = trainResponse.trainingLogs[0]\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(client.get_feature_name(config, ftrId), impact))\n",
    "    \n",
    "for roundDcg in trainLog.rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Train NDCG@10 %s\" % trainLog.rounds[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr import search\n",
    "search(client, \"rambo\", modelName='tsq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
