{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hello-ltr (Solr Edition)\n",
    "\n",
    "Fire up a Solr server with the LTR plugin enabled and with the `tmdb` configset available.  See the Dockerfile under the solr folder for assistance.  These notebooks we'll use in this training have something of an ltr client library, and a starting point for demonstrating several important learning to rank capabilities.\n",
    "\n",
    "This notebook will document many of the important pieces so you can reuse them in future training sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download needed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr import download\n",
    "\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "download([corpus], dest='data/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LTR Client\n",
    "\n",
    "Instantiate a Solr client, so we talk to LtR with Solrese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client.solr_client import SolrClient\n",
    "client = SolrClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create FeatureStore\n",
    "We'll discuss the feature store a bit more. You can think of them as a series of queries that will be stored and executed before we need to train a model.\n",
    "\n",
    "setup is our function for preparing learning to rank to optimize search using a set of features. In this stock demo, we just have one feature, the year of the movie's release.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = [\n",
    "  {\n",
    "    \"store\": \"release\", # Note: This overrides the _DEFAULT_ feature store location\n",
    "    \"name\" : \"release_year\",\n",
    "    \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\" : {\n",
    "      \"q\" : \"{!func}def(release_year,2000)\"\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "client.create_featureset(index='tmdb', name='release', ftr_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this thing on?\n",
    "\n",
    "Before we dive into all the pieces, with a real training set, we'll try out two examples of models. One that always prefers newer movies. And another that always prefers older movies. If you're curious you can opet classic-training.txt and latest-training.txt after running this to see what the training set looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.judgments import judgments_from_file\n",
    "from ltr import years_as_ratings\n",
    "years_as_ratings.synthesize(client, \n",
    "                            featureSet='release',\n",
    "                            classicTrainingSetOut='data/classic-training.txt',\n",
    "                            latestTrainingSetOut='data/latest-training.txt')\n",
    "\n",
    "# Load into training set \n",
    "classic_training_set = [j for j in judgments_from_file(open('data/classic-training.txt'))]\n",
    "latest_training_set = [j for j in judgments_from_file(open('data/latest-training.txt'))]\n",
    "\n",
    "classic_training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Submit\n",
    "Using the training data from the previous step, we'll use RankyMcRankFace to spit out two LambaMART models.  Once these files are generated, we can then submit them to elastic to be used in scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.ranklib import train\n",
    "train(client=client, training_set=latest_training_set, \n",
    "      index='tmdb', featureSet='release', modelName='latest')\n",
    "train(client=client, training_set=classic_training_set, \n",
    "      index='tmdb', featureSet='release', modelName='classic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ben Affleck vs Adam West\n",
    "If we search for `batman`, how do the results compare?  Since the `classic` model prefered old movies it has old movies in the top position, and the opposite is true for the `latest` model.  To continue learning LTR, brainstorm more features and generate some real judgments for real queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltr.release_date_plot as rdp\n",
    "rdp.plot(client, 'why does no one care')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Query\n",
    "http://localhost:8983/solr/tmdb/select?rq={!ltr%20model=latest}&q=batman&fl=title,release_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classic_results = rdp.search(client, 'batman', 'classic')\n",
    "print('top results from classic model:')\n",
    "pd.json_normalize(classic_results)[['id', 'title', 'release_year', 'score']].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_results = rdp.search(client, 'batman', 'latest')\n",
    "print('top results from latest model:')\n",
    "pd.json_normalize(latest_results)[['id', 'title', 'release_year', 'score']].head(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
