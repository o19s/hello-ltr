{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get to know Solr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solr Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import SolrClient\n",
    "client = SolrClient()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download & Build Index (run once)\n",
    "\n",
    "If you don't already have the downloaded dependencies; if you don't have TheMovieDB data indexed run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr import download\n",
    "\n",
    "tmdb_corpus='http://es-learn-to-rank.labs.o19s.com/tmdb_ai_pow_search.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments_binary.txt'\n",
    "download([tmdb_corpus, judgments]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "movies=indexable_movies(movies='data/tmdb_ai_pow_search.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for movie titles\n",
    "\n",
    "We'll be searching movie titles (think searching for a specific movie on Netflix). And we have a set of judgments around the appropriatte movie to return. IE search for \"Star Wars\" return good star wars matches, in quality order...\n",
    "\n",
    "These cover various aspects of the problem (searching title by phrase, title bm25 score, release date, etc). We'll use this to explore and analyze a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "ftr_config = [\n",
    "    #1\n",
    "    {\n",
    "      \"name\" : \"title_bm25\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #2\n",
    "    {\n",
    "      \"name\" : \"overview_bm25\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {#3\n",
    "      \"name\" : \"release_year\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!func}def(release_year,2000)\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "client.create_featureset(index='tmdb', name='title', ftr_config=ftr_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Generation\n",
    "\n",
    "Log out features for each of the above queries out to a training set file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import judgments_to_training_set\n",
    "trainingSet = judgments_to_training_set(client, \n",
    "                                        judgmentInFile='data/title_judgments_binary.txt', \n",
    "                                        trainingOutFile='data/title_judgments_binary_train.txt', \n",
    "                                        featureSet='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ltr.judgments import judgments_from_file, judgments_to_nparray\n",
    "\n",
    "def pairwise_transform(features, predictors):\n",
    "    \"\"\" Informed by\n",
    "        https://gist.github.com/agramfort/2071994\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "    GRADE = 0\n",
    "    QID = 1\n",
    "\n",
    "    \n",
    "    assert features.shape[0] == predictors.shape[0]\n",
    "    assert predictors.shape[1] == 2\n",
    "    assert features.shape[1] > 0\n",
    "    \n",
    "    num_samples = features.shape[0]\n",
    "    \n",
    "    transformed_predictors = []\n",
    "    transformed_features = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_samples):\n",
    "            if (predictors[i][GRADE] != predictors[j][GRADE] and \\\n",
    "                predictors[i][QID] == predictors[j][QID]):\n",
    "                                \n",
    "                transformed_predictors.append([predictors[i][GRADE] - predictors[j][GRADE]])\n",
    "                transformed_features.append(features[i, :] - features[j, :])\n",
    "    return np.array(transformed_features), np.array(transformed_predictors)\n",
    "\n",
    "def samples_from_training_data(fname):\n",
    "    with open(fname) as f:\n",
    "        judgs = judgments_from_file(f)\n",
    "        features, predictors = judgments_to_nparray(judgs)\n",
    "    \n",
    "    # Scale data\n",
    "    print(\"Scaling\")\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler.fit(features)\n",
    "    features = scaler.transform(features)\n",
    "        \n",
    "    print(\"Pairwise Transform\")\n",
    "    features, predictors = pairwise_transform(features, predictors)\n",
    "    return features, predictors.ravel(), scaler\n",
    "\n",
    "features, predictors, scaler = samples_from_training_data(fname='data/title_judgments_binary_train.txt')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, linear_model\n",
    "model = svm.LinearSVC(max_iter=1000, verbose=1)\n",
    "model.fit(features, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = {\n",
    "  \"store\": \"title\",\n",
    "  \"class\": \"org.apache.solr.ltr.model.LinearModel\",\n",
    "  \"name\": \"movie_titles\",\n",
    "  \"features\": [\n",
    "  ],\n",
    "  \"params\": {\n",
    "      \"weights\": {\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "import math\n",
    "ftr_model = {}\n",
    "ftr_names = [ftr['name'] for ftr in ftr_config]\n",
    "for idx, ftr_name in enumerate(ftr_names):\n",
    "    config = {\n",
    "        \"name\": ftr_name,\n",
    "        \"norm\": {\n",
    "            \"class\": \"org.apache.solr.ltr.norm.StandardNormalizer\",\n",
    "            \"params\": {\n",
    "                \"avg\": str(scaler.mean_[idx]),\n",
    "                \"std\": str(math.sqrt(scaler.var_[idx]))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    linear_model['features'].append(config)\n",
    "    linear_model['params']['weights'][ftr_name] =  model.coef_[0][idx] \n",
    "\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "client.submit_model(featureset='title', \n",
    "                    index='tmdb', \n",
    "                    model_name='movie_titles', \n",
    "                    solr_model=linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr import search\n",
    "search(client, keywords='rambo', modelName='movie_titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
