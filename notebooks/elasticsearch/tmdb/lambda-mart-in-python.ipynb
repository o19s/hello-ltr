{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LambdaMART in Python\n",
    "\n",
    "This is an implementation of LambdaMART in Python using sklearn and pandas. This is for educational purposes. \n",
    "\n",
    "But a secondary goal in getting this into Python is to more easily hack the algorithm to try new ideas. For example, this [blog article on two-sided marketplaces](https://opensourceconnections.com/blog/2017/07/04/optimizing-user-product-match-economies/), perhaps as more of an online algorithm (retiring old trees in the ensemble, adding new ones over time), perhaps with different model architectures in the ensemble (BERTy transformery things?) but all that preserve some of the nice things about LambdaMART (directly optimizing a list-wise metric)\n",
    "\n",
    "This is adapted from [RankLib](https://github.com/o19s/RankyMcRankFace/blob/master/src/ciir/umass/edu/learning/tree/LambdaMART.java#L444) based on [this paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) from Microsoft Research.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup - TheMovieDB corpus and log Elasticsearch features from TMDB](#Part-Zero---Setup---Get-TheMovieDB-Corpus-and-Log-Simple-Features) - plumbing to interact with Elasticsearch Learning to Rank to log a few basic features for our exploration\n",
    "2. [Pairwise swapping](#Part-One---Collect-pair-wise-DCG-diffs) - here we demonstrate the core operation of LambdaMART - pairwise swapping of pairs and examining DCG (or another ranking metric) impact\n",
    "3. [Scale to learn errors, not just swaps](#Part-Two---Compute-the-swaps-but-scaled-to-current-model's-error) - here we show how LambdaMART isn't just about learning the pairwise DCG difference of a swap, but the error currently in the model at predicting the DCG impact of that swap\n",
    "4. [Weigh predictions](#Part-Three---Weigh-each-leaf's-predictions) - here we weigh the predictions of the next model in the ensemble based on how much DCG remains to be learned. \n",
    "5. [Putting it all together](#Part-Four---Putting-it-all-together,-from-the-top!) - the full algorithm in one place. You can also compare this notebook's output and learning to Ranklib.\n",
    "\n",
<<<<<<< HEAD
    "---\n",
    "\n",
    "6. [A Pandas version!](#5.-Pure-Pandas-Implementation?) -- walking through a faster version computing the per-tree training data using Pandas - a much for useful toy example.\n",
    "\n",
=======
>>>>>>> 4ef4e05 (Save lambda mart)
    "## Known Issues\n",
    "\n",
    "I'm still learning the nooks and crannies of the algorithm. So there are some known issues as this is actively being developed.\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "1. **Performance** - a single training round takes about 9 seconds. There's room for improvement in the hot part of the loop (dcg computation and swapping)"
=======
    "1. **Likely bug** - When using DCG, the model here seems to wander around more than Ranklib, instead of converging. I think likely this points at an underlying bug that's actively being investigated.\n",
    "2. **Performance** - a single training round takes about 9 seconds. There's room for improvement in the hot part of the loop (dcg computation and swapping)"
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "1. **Performance** - a single training round takes about 9 seconds. There's room for improvement in the hot part of the loop (dcg computation and swapping)"
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Zero - Setup - Get TheMovieDB Corpus and Log Simple Features\n",
    "\n",
    "In this step we download TheMovieDB Corpus and log some featurs (title and overview BM25). At the end we have a simple dataframe"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 80,
=======
   "execution_count": 475,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 517,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 2,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 106,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 1,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 80,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import ElasticClient\n",
    "client = ElasticClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and index TMDB corpus and training set\n",
    "\n",
    "Download [TheMovieDB](http://themoviedb.org) corpus and small toy training set with 40 queries labeled."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 476,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 518,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 3,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 107,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 2,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 81,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tmdb.json already exists\n",
      "data/title_judgments.txt already exists\n",
      "Index tmdb already exists. Use `force = True` to delete and recreate\n"
     ]
    }
   ],
   "source": [
    "from ltr import download\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments.txt'\n",
    "\n",
    "download([corpus, judgments], dest='data/');\n",
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log two features - title & overview\n",
    "\n",
    "Using the Elasticsearch Learning to Rank plugin, we:\n",
    "\n",
    "1. Log two features: title and overview bm25\n",
    "2. Create a pandas dataframe containing the labels and features"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 82,
=======
   "execution_count": 477,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 519,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 4,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 108,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 3,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 82,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Default LTR feature store [Status: 200]\n",
      "Initialize Default LTR feature store [Status: 200]\n",
      "Create movies feature set [Status: 201]\n",
      "Recognizing 40 queries...\n"
     ]
    }
   ],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "from ltr.judgments import to_dataframe\n",
    "\n",
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = {\"validation\": {\n",
    "              \"index\": \"tmdb\",\n",
    "              \"params\": {\n",
    "                  \"keywords\": \"rambo\"\n",
    "              }\n",
    "    \n",
    "           },\n",
    "           \"featureset\": {\n",
    "            \"features\": [\n",
    "                { #1\n",
    "                    \"name\": \"title_bm25\",\n",
    "                    \"params\": [\"keywords\"],\n",
    "                    \"template\": {\n",
    "                        \"match\": {\"title\": \"{{keywords}}\"}\n",
    "                    }\n",
    "                },\n",
    "                { #2\n",
    "                    \"name\": \"overview_bm25\",\n",
    "                    \"params\": [\"keywords\"],\n",
    "                    \"template\": {\n",
    "                        \"match\": {\"overview\": \"{{keywords}}\"}\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    }}\n",
    "\n",
    "\n",
    "client.create_featureset(index='tmdb', name='movies', ftr_config=config)\n",
    "\n",
    "# Log features for each query\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='movies')\n",
    "with judgments_open('data/title_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))\n",
    "        \n",
    "# Convert to Pandas Dataframe\n",
    "judgments = to_dataframe(ftr_logger.logged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine judgments dataframe\n",
    "\n",
    "In the dataframe we have a set of (query, document, grade) that label how relevant a document (movie) is for each query.\n",
    "\n",
    "* qid - 'query id' - a unique identifier for this query\n",
    "* docId - an identifier for the document (here movie) being labeled\n",
    "* grade - how relevant a movie is on a 0-4 scale\n",
    "* keywords - the query keywords that go along with the query id\n",
    "* features - the two features we logged, 0th is title_bm25, 1st is overview_bm25"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 83,
=======
   "execution_count": 478,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 520,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 5,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 109,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 4,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 83,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_7555</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.083591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1370</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1369</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_13258</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_1368</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>40_37079</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>40_126757</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>40_39797</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>40_18112</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>40_43052</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uid  qid   keywords   docId  grade                features\n",
       "0        1_7555    1      rambo    7555      4  [11.657399, 10.083591]\n",
       "1        1_1370    1      rambo    1370      3   [9.456276, 13.265001]\n",
       "2        1_1369    1      rambo    1369      3   [6.036743, 11.113943]\n",
       "3       1_13258    1      rambo   13258      2         [0.0, 6.869545]\n",
       "4        1_1368    1      rambo    1368      4        [0.0, 11.113943]\n",
       "...         ...  ...        ...     ...    ...                     ...\n",
       "1385   40_37079   40  star wars   37079      0              [0.0, 0.0]\n",
       "1386  40_126757   40  star wars  126757      0              [0.0, 0.0]\n",
       "1387   40_39797   40  star wars   39797      0              [0.0, 0.0]\n",
       "1388   40_18112   40  star wars   18112      0              [0.0, 0.0]\n",
       "1389   40_43052   40  star wars   43052      0              [0.0, 0.0]\n",
       "\n",
       "[1390 rows x 6 columns]"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 83,
=======
     "execution_count": 478,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 520,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 5,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 109,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 4,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 83,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One - Collect pair-wise DCG diffs\n",
    "\n",
    "The first-pass iteration of LambdaMART, for each query, we examine the DCG\\* impact of swapping each result with another result in the listing.\n",
    "\n",
    "\\* replace DCG with your metric of interest: MAP, Precision@N, etc"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 84,
=======
   "execution_count": 480,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 521,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 6,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 | 0 4 | 0.0\n",
      "0 4 | 1 4 | 0.0\n",
      "0 4 | 2 3 | 4.0\n",
      "0 4 | 3 2 | 6.831881303119283\n",
      "0 4 | 4 1 | 8.584060698716417\n",
      "1 4 | 0 4 | -0.0\n",
      "1 4 | 1 4 | 0.0\n",
      "1 4 | 2 3 | 1.0474380285716594\n",
      "1 4 | 3 2 | 2.403038345976772\n",
      "1 4 | 4 1 | 3.4170772487168213\n",
      "2 3 | 0 4 | 4.0\n",
      "2 3 | 1 4 | 1.0474380285716594\n",
      "2 3 | 2 3 | 0.0\n",
      "2 3 | 3 2 | 0.2772937677064278\n",
      "2 3 | 4 1 | 0.6788831565927502\n",
      "3 2 | 0 4 | 6.831881303119283\n",
      "3 2 | 1 4 | 2.403038345976772\n",
      "3 2 | 2 3 | 0.2772937677064278\n",
      "3 2 | 3 2 | 0.0\n",
      "3 2 | 4 1 | 0.08764750167770285\n",
      "4 1 | 0 4 | 8.584060698716417\n",
      "4 1 | 1 4 | 3.4170772487168213\n",
      "4 1 | 2 3 | 0.6788831565927502\n",
      "4 1 | 3 2 | 0.08764750167770285\n",
      "4 1 | 4 1 | 0.0\n"
     ]
    }
   ],
   "source": [
    "from math import log, exp\n",
    "\n",
    "def gain(grade):\n",
    "    return (2**grade) - 1\n",
    "    \n",
    "def discount(rank):\n",
    "    return 1 / log(rank+2, 2)\n",
    "\n",
    "rel = [4,4,3,2,1]\n",
    "for i in range(len(rel)):\n",
    "    for j in range(len(rel)):\n",
    "        print(i,rel[i], '|', j, rel[j], '|', (discount(i) - discount(j)) * (gain(rel[i]) - gain(rel[j])))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 128,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 213,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 6,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 84,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>discount</th>\n",
       "      <th>gain</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1_7555</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.083591]</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> bd537d0 (Fix DCG calculation)
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>427.587115</td>\n",
<<<<<<< HEAD
=======
       "      <td>0.500000</td>\n",
<<<<<<< HEAD
       "      <td>8.000000</td>\n",
       "      <td>22.796491</td>\n",
       "      <td>183.343798</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>7.500000</td>\n",
       "      <td>19.788248</td>\n",
       "      <td>173.363849</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
>>>>>>> bd537d0 (Fix DCG calculation)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1_1368</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "      <td>1</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> bd537d0 (Fix DCG calculation)
       "      <td>0.630930</td>\n",
       "      <td>9.463946</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>219.800566</td>\n",
<<<<<<< HEAD
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1370</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>62.204093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
=======
       "      <td>0.386853</td>\n",
       "      <td>5.802792</td>\n",
       "      <td>19.788248</td>\n",
       "      <td>109.661979</td>\n",
=======
>>>>>>> bd537d0 (Fix DCG calculation)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>2</td>\n",
       "      <td>1_1369</td>\n",
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>[6.036743, 11.113943]</td>\n",
<<<<<<< HEAD
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>3.014736</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>43.694734</td>\n",
=======
=======
       "      <td>[9.456276, 13.265001]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>62.204093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1_1369</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>0.301030</td>\n",
<<<<<<< HEAD
       "      <td>2.408240</td>\n",
       "      <td>22.796491</td>\n",
       "      <td>30.087439</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>2.107210</td>\n",
       "      <td>19.788248</td>\n",
       "      <td>26.275559</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>0.430677</td>\n",
       "      <td>3.014736</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>43.694734</td>\n",
>>>>>>> bd537d0 (Fix DCG calculation)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1_13258</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> bd537d0 (Fix DCG calculation)
       "      <td>0.386853</td>\n",
       "      <td>1.160558</td>\n",
       "      <td>33.734341</td>\n",
       "      <td>5.542298</td>\n",
<<<<<<< HEAD
=======
       "      <td>0.278943</td>\n",
<<<<<<< HEAD
       "      <td>1.115772</td>\n",
       "      <td>22.796491</td>\n",
       "      <td>8.628473</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.836829</td>\n",
       "      <td>19.788248</td>\n",
       "      <td>5.501292</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
>>>>>>> bd537d0 (Fix DCG calculation)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>25</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>1385</td>\n",
       "      <td>40_37079</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.598524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1386</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.715586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1387</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.826142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1388</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>28</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.930783</td>\n",
=======
       "      <td>1371</td>\n",
       "      <td>40_81899</td>\n",
=======
       "      <td>1385</td>\n",
       "      <td>40_37079</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.598524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1386</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.715586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1387</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.826142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1388</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>28</td>\n",
<<<<<<< HEAD
       "      <td>0.169294</td>\n",
<<<<<<< HEAD
       "      <td>0.169294</td>\n",
       "      <td>21.491637</td>\n",
       "      <td>-11.236624</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.000000</td>\n",
       "      <td>18.546823</td>\n",
       "      <td>-9.976269</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-20.930783</td>\n",
>>>>>>> bd537d0 (Fix DCG calculation)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1389</td>\n",
       "      <td>40_43052</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>8</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-21.030027</td>\n",
=======
       "      <td>0.231378</td>\n",
<<<<<<< HEAD
       "      <td>0.231378</td>\n",
       "      <td>21.491637</td>\n",
       "      <td>-11.317325</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.000000</td>\n",
       "      <td>18.546823</td>\n",
       "      <td>-10.044865</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.225149</td>\n",
       "      <td>-21.030027</td>\n",
>>>>>>> bd537d0 (Fix DCG calculation)
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        uid  qid   keywords   docId  grade  \\\n",
       "qid                                                       \n",
       "1   0       0     1_7555    1      rambo    7555      4   \n",
       "    1       4     1_1368    1      rambo    1368      4   \n",
<<<<<<< HEAD
<<<<<<< HEAD
       "    2       1     1_1370    1      rambo    1370      3   \n",
       "    3       2     1_1369    1      rambo    1369      3   \n",
       "    4       3    1_13258    1      rambo   13258      2   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1385   40_37079   40  star wars   37079      0   \n",
       "    26   1386  40_126757   40  star wars  126757      0   \n",
       "    27   1387   40_39797   40  star wars   39797      0   \n",
       "    28   1388   40_18112   40  star wars   18112      0   \n",
       "    29   1389   40_43052   40  star wars   43052      0   \n",
       "\n",
       "                      features  display_rank  discount       gain        dcg  \\\n",
       "qid                                                                            \n",
       "1   0   [11.657399, 10.083591]             0  1.000000  15.000000  33.734341   \n",
       "    1         [0.0, 11.113943]             1  0.630930   9.463946  33.734341   \n",
       "    2    [9.456276, 13.265001]             2  0.500000   3.500000  33.734341   \n",
       "    3    [6.036743, 11.113943]             3  0.430677   3.014736  33.734341   \n",
       "    4          [0.0, 6.869545]             4  0.386853   1.160558  33.734341   \n",
       "...                        ...           ...       ...        ...        ...   \n",
       "40  25              [0.0, 0.0]            25  0.210310   0.000000  31.225149   \n",
       "    26              [0.0, 0.0]            26  0.208015   0.000000  31.225149   \n",
       "    27              [0.0, 0.0]            27  0.205847   0.000000  31.225149   \n",
       "    28              [0.0, 0.0]            28  0.203795   0.000000  31.225149   \n",
       "    29              [0.0, 0.0]             8  0.301030   0.000000  31.225149   \n",
       "\n",
       "            lambda  \n",
       "qid                 \n",
       "1   0   427.587115  \n",
       "    1   219.800566  \n",
       "    2    62.204093  \n",
       "    3    43.694734  \n",
       "    4     5.542298  \n",
       "...            ...  \n",
       "40  25  -20.598524  \n",
       "    26  -20.715586  \n",
       "    27  -20.826142  \n",
       "    28  -20.930783  \n",
       "    29  -21.030027  \n",
=======
       "    2       2     1_1369    1      rambo    1369      3   \n",
       "    3       1     1_1370    1      rambo    1370      3   \n",
=======
       "    2       1     1_1370    1      rambo    1370      3   \n",
       "    3       2     1_1369    1      rambo    1369      3   \n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    4       3    1_13258    1      rambo   13258      2   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1385   40_37079   40  star wars   37079      0   \n",
       "    26   1386  40_126757   40  star wars  126757      0   \n",
       "    27   1387   40_39797   40  star wars   39797      0   \n",
       "    28   1388   40_18112   40  star wars   18112      0   \n",
       "    29   1389   40_43052   40  star wars   43052      0   \n",
       "\n",
       "                      features  display_rank  discount       gain        dcg  \\\n",
       "qid                                                                            \n",
       "1   0   [11.657399, 10.083591]             0  1.000000  15.000000  33.734341   \n",
       "    1         [0.0, 11.113943]             1  0.630930   9.463946  33.734341   \n",
       "    2    [9.456276, 13.265001]             2  0.500000   3.500000  33.734341   \n",
       "    3    [6.036743, 11.113943]             3  0.430677   3.014736  33.734341   \n",
       "    4          [0.0, 6.869545]             4  0.386853   1.160558  33.734341   \n",
       "...                        ...           ...       ...        ...        ...   \n",
       "40  25              [0.0, 0.0]            25  0.210310   0.000000  31.225149   \n",
       "    26              [0.0, 0.0]            26  0.208015   0.000000  31.225149   \n",
       "    27              [0.0, 0.0]            27  0.205847   0.000000  31.225149   \n",
       "    28              [0.0, 0.0]            28  0.203795   0.000000  31.225149   \n",
       "    29              [0.0, 0.0]             8  0.301030   0.000000  31.225149   \n",
       "\n",
       "            lambda  \n",
       "qid                 \n",
       "1   0   427.587115  \n",
       "    1   219.800566  \n",
       "    2    62.204093  \n",
       "    3    43.694734  \n",
       "    4     5.542298  \n",
       "...            ...  \n",
<<<<<<< HEAD
<<<<<<< HEAD
       "40  25  -10.968332  \n",
       "    26  -11.062526  \n",
       "    27  -11.151815  \n",
       "    28  -11.236624  \n",
       "    29  -11.317325  \n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "40  25   -9.748220  \n",
       "    26   -9.828286  \n",
       "    27   -9.904182  \n",
       "    28   -9.976269  \n",
       "    29  -10.044865  \n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "40  25  -20.598524  \n",
       "    26  -20.715586  \n",
       "    27  -20.826142  \n",
       "    28  -20.930783  \n",
       "    29  -21.030027  \n",
>>>>>>> bd537d0 (Fix DCG calculation)
       "\n",
       "[1390 rows x 12 columns]"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 84,
=======
     "execution_count": 480,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 521,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 6,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 128,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 213,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
     "execution_count": 6,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 84,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log, exp\n",
    "import numpy as np \n",
    "\n",
    "def rank_with_swap(ranked_list, rank1=0, rank2=0):\n",
    "    \"\"\" Set the display rank of positions given the provided swap \"\"\"\n",
    "    ranked_list['display_rank'] = ranked_list.index.to_series()\n",
    "    \n",
    "    if rank1 != rank2:\n",
    "        ranked_list.loc[rank1, 'display_rank'] = rank2\n",
    "        ranked_list.loc[rank2, 'display_rank'] = rank1\n",
    "    return ranked_list\n",
    "    \n",
    "\n",
    "def dcg(ranked_list, at=10):\n",
    "    \"\"\"Given a list, compute DCG -- \n",
    "       uses same variant as lambdamart 2**grade / log2(displayrank)\n",
    "    \"\"\"\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> bd537d0 (Fix DCG calculation)
    "    ranked_list['discount'] = 1 / np.log2(2 + ranked_list['display_rank'])\n",
    "    ranked_list['gain'] = (2**ranked_list['grade'] - 1) * ranked_list['discount'] # TODO - precompute gain on swapping\n",
=======
    "    ranked_list['discount'] = 1 / (1 + (np.log2(2 + ranked_list['display_rank'])))\n",
<<<<<<< HEAD
    "    ranked_list['gain'] = (2**ranked_list['grade']) * ranked_list['discount'] # TODO - precompute gain on swapping\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "    ranked_list['gain'] = (2**ranked_list['grade'] - 1) * ranked_list['discount'] # TODO - precompute gain on swapping\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
    "    return sum(ranked_list['gain'].head(at))\n",
    "\n",
    "def compute_swaps(query_judgments, axis, metric=dcg, at=10):\n",
    "    \"\"\"Compute the 'lambda' the DCG impact of every query result swapped with every-other query result\"\"\"\n",
    "    \n",
    "    # Sort to see ideal ordering\n",
    "    # This isn't strictly nescesarry, but it's helpful to understand the algorithm\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    query_judgments = query_judgments.sort_values('grade', kind='stable', ascending=False).reset_index()\n",
=======
    "    query_judgments = query_judgments.sort_values('grade', ascending=False).reset_index()\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "    query_judgments = query_judgments.sort_values('grade', kind='stable', ascending=False).reset_index()\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
    "\n",
    "    # Instead of explicitly 'swapping' we just swap the 'display_rank' - where \n",
    "    # in the final ranking this would be placed. We can easily use that to compute DCG\n",
    "    query_judgments['display_rank'] = query_judgments.index.to_series()\n",
    "    query_judgments['dcg'] = metric(query_judgments, at=at)\n",
    "    best_dcg = query_judgments.loc[0, 'dcg']\n",
    "\n",
    "    query_judgments['lambda'] = 0.0\n",
    "    \n",
    "    # TODO - redo inner body as \n",
    "    for better in range(0,len(query_judgments)):\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "        for worse in range(0,len(query_judgments)):\n",
=======
    "        for worse in range(better+1,len(query_judgments)):\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "        for worse in range(0,len(query_judgments)):\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
    "            if better > at and worse > at:\n",
    "                break\n",
    "\n",
    "            if query_judgments.loc[better, 'grade'] > query_judgments.loc[worse, 'grade']:\n",
    "                query_judgments = rank_with_swap(query_judgments, better, worse)\n",
    "                query_judgments['dcg'] = metric(query_judgments, at=at)\n",
    "\n",
    "                dcg_after_swap = query_judgments.loc[0, 'dcg']\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "                delta = abs(best_dcg - dcg_after_swap)\n",
=======
    "                delta = best_dcg - dcg_after_swap\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "                delta = abs(best_dcg - dcg_after_swap)\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "\n",
    "                if delta > 0.0:\n",
    "\n",
    "                    # Add delta to better's lambda (-delta to worse's lambda)\n",
    "                    query_judgments.loc[better, 'lambda'] += delta\n",
    "                    query_judgments.loc[worse, 'lambda'] -= delta\n",
    "\n",
    "    # print(query_judgments[['keywords', 'docId', 'grade', 'lambda', 'features']])\n",
    "    return query_judgments\n",
    "\n",
    "# For each query, compute lambdas\n",
    "# %prun -s cumulative lambdas_per_query = judgments.groupby('qid').apply(compute_swaps, axis=1)\n",
    "# judgments\n",
    "lambdas_per_query = judgments.groupby('qid').apply(compute_swaps, axis=1)\n",
    "lambdas_per_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Precision instead of DCG\n",
    "\n",
    "We can really use any ranking metric to achieve goals important to our product. This includes potentially ones we invent or come up with ourselves!"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": 481,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 522,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 7,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 129,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 7,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 85,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>5_603</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>603</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.040129]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>150</td>\n",
       "      <td>5_604</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>604</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 9.392262]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
=======
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>151</td>\n",
       "      <td>5_605</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>605</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 0.0]</td>\n",
<<<<<<< HEAD
=======
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>150</td>\n",
       "      <td>5_604</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>604</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 9.392262]</td>\n",
<<<<<<< HEAD
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>5_605</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>605</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>5_55931</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>55931</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 10.798681]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>5_73262</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>73262</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>153</td>\n",
       "      <td>5_1857</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>1857</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 9.65805]</td>\n",
=======
       "      <td>174</td>\n",
       "      <td>5_33068</td>\n",
=======
       "      <td>153</td>\n",
       "      <td>5_1857</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>1857</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 9.65805]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>154</td>\n",
       "      <td>5_10999</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>10999</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 11.466951]</td>\n",
=======
       "      <td>169</td>\n",
       "      <td>5_3573</td>\n",
=======
       "      <td>154</td>\n",
       "      <td>5_10999</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>10999</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 11.466951]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>155</td>\n",
       "      <td>5_4247</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>4247</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 8.114125]</td>\n",
=======
       "      <td>170</td>\n",
       "      <td>5_12254</td>\n",
=======
       "      <td>155</td>\n",
       "      <td>5_4247</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>4247</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 8.114125]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>156</td>\n",
       "      <td>5_21874</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>21874</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 7.8627386]</td>\n",
=======
       "      <td>171</td>\n",
       "      <td>5_17813</td>\n",
=======
       "      <td>156</td>\n",
       "      <td>5_21874</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>21874</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 7.8627386]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>157</td>\n",
       "      <td>5_181886</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>181886</td>\n",
=======
       "      <td>173</td>\n",
       "      <td>5_17960</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>17960</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>157</td>\n",
       "      <td>5_181886</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>181886</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>158</td>\n",
       "      <td>5_21208</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>21208</td>\n",
=======
       "      <td>175</td>\n",
       "      <td>5_28377</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28377</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>158</td>\n",
       "      <td>5_21208</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>21208</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>159</td>\n",
       "      <td>5_125607</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>125607</td>\n",
=======
       "      <td>167</td>\n",
       "      <td>5_104221</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>104221</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>159</td>\n",
       "      <td>5_125607</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>125607</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>160</td>\n",
       "      <td>5_56441</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>56441</td>\n",
=======
       "      <td>176</td>\n",
       "      <td>5_13300</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>13300</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>160</td>\n",
       "      <td>5_56441</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>56441</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>161</td>\n",
       "      <td>5_124080</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>124080</td>\n",
=======
       "      <td>177</td>\n",
       "      <td>5_680</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>680</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>161</td>\n",
       "      <td>5_124080</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>124080</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>13</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>162</td>\n",
       "      <td>5_1487</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>1487</td>\n",
=======
       "      <td>178</td>\n",
       "      <td>5_28131</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28131</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>162</td>\n",
       "      <td>5_1487</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>1487</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>163</td>\n",
       "      <td>5_72867</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>72867</td>\n",
=======
       "      <td>179</td>\n",
       "      <td>5_37988</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>37988</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>163</td>\n",
       "      <td>5_72867</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>72867</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>164</td>\n",
       "      <td>5_11253</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>11253</td>\n",
=======
       "      <td>180</td>\n",
       "      <td>5_18451</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>18451</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>164</td>\n",
       "      <td>5_11253</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>11253</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>165</td>\n",
       "      <td>5_213110</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>213110</td>\n",
=======
       "      <td>168</td>\n",
       "      <td>5_183894</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>183894</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>165</td>\n",
       "      <td>5_213110</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>213110</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>166</td>\n",
       "      <td>5_13805</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>13805</td>\n",
=======
       "      <td>165</td>\n",
       "      <td>5_213110</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>213110</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>166</td>\n",
       "      <td>5_13805</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>13805</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>167</td>\n",
       "      <td>5_104221</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>104221</td>\n",
=======
       "      <td>166</td>\n",
       "      <td>5_13805</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>13805</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>167</td>\n",
       "      <td>5_104221</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>104221</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>168</td>\n",
       "      <td>5_183894</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>183894</td>\n",
=======
       "      <td>164</td>\n",
       "      <td>5_11253</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>11253</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>168</td>\n",
       "      <td>5_183894</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>183894</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>169</td>\n",
       "      <td>5_3573</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>3573</td>\n",
=======
       "      <td>163</td>\n",
       "      <td>5_72867</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>72867</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>169</td>\n",
       "      <td>5_3573</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>3573</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>21</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>170</td>\n",
       "      <td>5_12254</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>12254</td>\n",
=======
       "      <td>162</td>\n",
       "      <td>5_1487</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>1487</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>170</td>\n",
       "      <td>5_12254</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>12254</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>171</td>\n",
       "      <td>5_17813</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>17813</td>\n",
=======
       "      <td>161</td>\n",
       "      <td>5_124080</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>124080</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>171</td>\n",
       "      <td>5_17813</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>17813</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>23</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>173</td>\n",
       "      <td>5_17960</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>17960</td>\n",
=======
       "      <td>160</td>\n",
       "      <td>5_56441</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>56441</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>173</td>\n",
       "      <td>5_17960</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>17960</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>24</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>174</td>\n",
       "      <td>5_33068</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>33068</td>\n",
=======
       "      <td>159</td>\n",
       "      <td>5_125607</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>125607</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>174</td>\n",
       "      <td>5_33068</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>33068</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>175</td>\n",
       "      <td>5_28377</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28377</td>\n",
=======
       "      <td>158</td>\n",
       "      <td>5_21208</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>21208</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>175</td>\n",
       "      <td>5_28377</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28377</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>176</td>\n",
       "      <td>5_13300</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>13300</td>\n",
=======
       "      <td>157</td>\n",
       "      <td>5_181886</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>181886</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>176</td>\n",
       "      <td>5_13300</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>13300</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>177</td>\n",
       "      <td>5_680</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
=======
       "      <td>156</td>\n",
       "      <td>5_21874</td>\n",
=======
       "      <td>177</td>\n",
       "      <td>5_680</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 7.8627386]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>28</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>178</td>\n",
       "      <td>5_28131</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28131</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
=======
       "      <td>155</td>\n",
       "      <td>5_4247</td>\n",
=======
       "      <td>178</td>\n",
       "      <td>5_28131</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28131</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 8.114125]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>29</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>179</td>\n",
       "      <td>5_37988</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>37988</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
=======
       "      <td>154</td>\n",
       "      <td>5_10999</td>\n",
=======
       "      <td>179</td>\n",
       "      <td>5_37988</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>37988</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 11.466951]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>180</td>\n",
       "      <td>5_18451</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>18451</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
=======
       "      <td>153</td>\n",
       "      <td>5_1857</td>\n",
=======
       "      <td>180</td>\n",
       "      <td>5_18451</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>18451</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>[0.0, 9.65805]</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>31</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>181</td>\n",
       "      <td>5_75404</td>\n",
       "      <td>5</td>\n",
       "      <td>matrix</td>\n",
       "      <td>75404</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index       uid  qid keywords   docId  grade                features  \\\n",
       "0     149     5_603    5   matrix     603      4  [11.657399, 10.040129]   \n",
<<<<<<< HEAD
<<<<<<< HEAD
       "1     150     5_604    5   matrix     604      3    [9.456276, 9.392262]   \n",
       "2     151     5_605    5   matrix     605      3         [9.456276, 0.0]   \n",
       "3     152   5_55931    5   matrix   55931      2        [0.0, 10.798681]   \n",
       "4     172   5_73262    5   matrix   73262      1              [0.0, 0.0]   \n",
       "5     153    5_1857    5   matrix    1857      0          [0.0, 9.65805]   \n",
       "6     154   5_10999    5   matrix   10999      0        [0.0, 11.466951]   \n",
       "7     155    5_4247    5   matrix    4247      0         [0.0, 8.114125]   \n",
       "8     156   5_21874    5   matrix   21874      0        [0.0, 7.8627386]   \n",
       "9     157  5_181886    5   matrix  181886      0              [0.0, 0.0]   \n",
       "10    158   5_21208    5   matrix   21208      0              [0.0, 0.0]   \n",
       "11    159  5_125607    5   matrix  125607      0              [0.0, 0.0]   \n",
       "12    160   5_56441    5   matrix   56441      0              [0.0, 0.0]   \n",
       "13    161  5_124080    5   matrix  124080      0              [0.0, 0.0]   \n",
       "14    162    5_1487    5   matrix    1487      0              [0.0, 0.0]   \n",
       "15    163   5_72867    5   matrix   72867      0              [0.0, 0.0]   \n",
       "16    164   5_11253    5   matrix   11253      0              [0.0, 0.0]   \n",
       "17    165  5_213110    5   matrix  213110      0              [0.0, 0.0]   \n",
       "18    166   5_13805    5   matrix   13805      0              [0.0, 0.0]   \n",
       "19    167  5_104221    5   matrix  104221      0              [0.0, 0.0]   \n",
       "20    168  5_183894    5   matrix  183894      0              [0.0, 0.0]   \n",
       "21    169    5_3573    5   matrix    3573      0              [0.0, 0.0]   \n",
       "22    170   5_12254    5   matrix   12254      0              [0.0, 0.0]   \n",
       "23    171   5_17813    5   matrix   17813      0              [0.0, 0.0]   \n",
       "24    173   5_17960    5   matrix   17960      0              [0.0, 0.0]   \n",
       "25    174   5_33068    5   matrix   33068      0              [0.0, 0.0]   \n",
       "26    175   5_28377    5   matrix   28377      0              [0.0, 0.0]   \n",
       "27    176   5_13300    5   matrix   13300      0              [0.0, 0.0]   \n",
       "28    177     5_680    5   matrix     680      0              [0.0, 0.0]   \n",
       "29    178   5_28131    5   matrix   28131      0              [0.0, 0.0]   \n",
       "30    179   5_37988    5   matrix   37988      0              [0.0, 0.0]   \n",
       "31    180   5_18451    5   matrix   18451      0              [0.0, 0.0]   \n",
=======
       "1     151     5_605    5   matrix     605      3         [9.456276, 0.0]   \n",
       "2     150     5_604    5   matrix     604      3    [9.456276, 9.392262]   \n",
       "3     152   5_55931    5   matrix   55931      2        [0.0, 10.798681]   \n",
       "4     172   5_73262    5   matrix   73262      1              [0.0, 0.0]   \n",
       "5     174   5_33068    5   matrix   33068      0              [0.0, 0.0]   \n",
       "6     169    5_3573    5   matrix    3573      0              [0.0, 0.0]   \n",
       "7     170   5_12254    5   matrix   12254      0              [0.0, 0.0]   \n",
       "8     171   5_17813    5   matrix   17813      0              [0.0, 0.0]   \n",
       "9     173   5_17960    5   matrix   17960      0              [0.0, 0.0]   \n",
       "10    175   5_28377    5   matrix   28377      0              [0.0, 0.0]   \n",
       "11    167  5_104221    5   matrix  104221      0              [0.0, 0.0]   \n",
       "12    176   5_13300    5   matrix   13300      0              [0.0, 0.0]   \n",
       "13    177     5_680    5   matrix     680      0              [0.0, 0.0]   \n",
       "14    178   5_28131    5   matrix   28131      0              [0.0, 0.0]   \n",
       "15    179   5_37988    5   matrix   37988      0              [0.0, 0.0]   \n",
       "16    180   5_18451    5   matrix   18451      0              [0.0, 0.0]   \n",
       "17    168  5_183894    5   matrix  183894      0              [0.0, 0.0]   \n",
       "18    165  5_213110    5   matrix  213110      0              [0.0, 0.0]   \n",
       "19    166   5_13805    5   matrix   13805      0              [0.0, 0.0]   \n",
       "20    164   5_11253    5   matrix   11253      0              [0.0, 0.0]   \n",
       "21    163   5_72867    5   matrix   72867      0              [0.0, 0.0]   \n",
       "22    162    5_1487    5   matrix    1487      0              [0.0, 0.0]   \n",
       "23    161  5_124080    5   matrix  124080      0              [0.0, 0.0]   \n",
       "24    160   5_56441    5   matrix   56441      0              [0.0, 0.0]   \n",
       "25    159  5_125607    5   matrix  125607      0              [0.0, 0.0]   \n",
       "26    158   5_21208    5   matrix   21208      0              [0.0, 0.0]   \n",
       "27    157  5_181886    5   matrix  181886      0              [0.0, 0.0]   \n",
       "28    156   5_21874    5   matrix   21874      0        [0.0, 7.8627386]   \n",
       "29    155    5_4247    5   matrix    4247      0         [0.0, 8.114125]   \n",
       "30    154   5_10999    5   matrix   10999      0        [0.0, 11.466951]   \n",
       "31    153    5_1857    5   matrix    1857      0          [0.0, 9.65805]   \n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "1     150     5_604    5   matrix     604      3    [9.456276, 9.392262]   \n",
       "2     151     5_605    5   matrix     605      3         [9.456276, 0.0]   \n",
       "3     152   5_55931    5   matrix   55931      2        [0.0, 10.798681]   \n",
       "4     172   5_73262    5   matrix   73262      1              [0.0, 0.0]   \n",
       "5     153    5_1857    5   matrix    1857      0          [0.0, 9.65805]   \n",
       "6     154   5_10999    5   matrix   10999      0        [0.0, 11.466951]   \n",
       "7     155    5_4247    5   matrix    4247      0         [0.0, 8.114125]   \n",
       "8     156   5_21874    5   matrix   21874      0        [0.0, 7.8627386]   \n",
       "9     157  5_181886    5   matrix  181886      0              [0.0, 0.0]   \n",
       "10    158   5_21208    5   matrix   21208      0              [0.0, 0.0]   \n",
       "11    159  5_125607    5   matrix  125607      0              [0.0, 0.0]   \n",
       "12    160   5_56441    5   matrix   56441      0              [0.0, 0.0]   \n",
       "13    161  5_124080    5   matrix  124080      0              [0.0, 0.0]   \n",
       "14    162    5_1487    5   matrix    1487      0              [0.0, 0.0]   \n",
       "15    163   5_72867    5   matrix   72867      0              [0.0, 0.0]   \n",
       "16    164   5_11253    5   matrix   11253      0              [0.0, 0.0]   \n",
       "17    165  5_213110    5   matrix  213110      0              [0.0, 0.0]   \n",
       "18    166   5_13805    5   matrix   13805      0              [0.0, 0.0]   \n",
       "19    167  5_104221    5   matrix  104221      0              [0.0, 0.0]   \n",
       "20    168  5_183894    5   matrix  183894      0              [0.0, 0.0]   \n",
       "21    169    5_3573    5   matrix    3573      0              [0.0, 0.0]   \n",
       "22    170   5_12254    5   matrix   12254      0              [0.0, 0.0]   \n",
       "23    171   5_17813    5   matrix   17813      0              [0.0, 0.0]   \n",
       "24    173   5_17960    5   matrix   17960      0              [0.0, 0.0]   \n",
       "25    174   5_33068    5   matrix   33068      0              [0.0, 0.0]   \n",
       "26    175   5_28377    5   matrix   28377      0              [0.0, 0.0]   \n",
       "27    176   5_13300    5   matrix   13300      0              [0.0, 0.0]   \n",
       "28    177     5_680    5   matrix     680      0              [0.0, 0.0]   \n",
       "29    178   5_28131    5   matrix   28131      0              [0.0, 0.0]   \n",
       "30    179   5_37988    5   matrix   37988      0              [0.0, 0.0]   \n",
       "31    180   5_18451    5   matrix   18451      0              [0.0, 0.0]   \n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "32    181   5_75404    5   matrix   75404      0              [0.0, 0.0]   \n",
       "\n",
       "    display_rank  dcg  lambda  \n",
       "0              0  0.3   2.300  \n",
       "1              1  0.3   1.725  \n",
       "2              2  0.3   1.725  \n",
       "3              3  0.3   1.150  \n",
       "4             32  0.3   0.575  \n",
       "5              5  0.3   0.000  \n",
       "6              6  0.3   0.000  \n",
       "7              7  0.3   0.000  \n",
       "8              8  0.3   0.000  \n",
       "9              9  0.3   0.000  \n",
       "10            10  0.3  -0.325  \n",
       "11            11  0.3  -0.325  \n",
       "12            12  0.3  -0.325  \n",
       "13            13  0.3  -0.325  \n",
       "14            14  0.3  -0.325  \n",
       "15            15  0.3  -0.325  \n",
       "16            16  0.3  -0.325  \n",
       "17            17  0.3  -0.325  \n",
       "18            18  0.3  -0.325  \n",
       "19            19  0.3  -0.325  \n",
       "20            20  0.3  -0.325  \n",
       "21            21  0.3  -0.325  \n",
       "22            22  0.3  -0.325  \n",
       "23            23  0.3  -0.325  \n",
       "24            24  0.3  -0.325  \n",
       "25            25  0.3  -0.325  \n",
       "26            26  0.3  -0.325  \n",
       "27            27  0.3  -0.325  \n",
       "28            28  0.3  -0.325  \n",
       "29            29  0.3  -0.325  \n",
       "30            30  0.3  -0.325  \n",
       "31            31  0.3  -0.325  \n",
       "32             4  0.3  -0.325  "
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 85,
=======
     "execution_count": 481,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 522,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 7,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 129,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 7,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 85,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision(ranked_list, max_grade=4.0, at=10):\n",
    "    \"\"\"Given a list, compute simple precision. Really this is cumalitive gain.\"\"\"\n",
    "    above_n = ranked_list[ranked_list['display_rank'] < at]\n",
    "    \n",
    "    if (max_grade * at) == 0.0:\n",
    "        print(\"0\")\n",
    "        return 0.0\n",
    "    \n",
    "    return float(sum(above_n['grade'])) / (max_grade * at)\n",
    "\n",
    "\n",
    "lambdas_per_query_prec = judgments.groupby('qid').apply(compute_swaps, axis=1, metric=precision)\n",
    "lambdas_per_query_prec.loc[5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model on the lambdas\n",
    "\n",
    "The core operation is fitting an operation on the lambdas (the accumulated pairwise differences)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 86,
=======
   "execution_count": 482,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 523,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 8,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 130,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 8,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 86,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>427.587115</td>\n",
=======
       "      <td>183.343798</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>173.363849</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>427.587115</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[11.657399, 10.083591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>219.800566</td>\n",
=======
       "      <td>116.134366</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>109.661979</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>219.800566</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[0.0, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>62.204093</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.694734</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.542298</td>\n",
=======
       "      <td>39.713833</td>\n",
=======
       "      <td>34.900550</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
       "      <td>[6.036743, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.275559</td>\n",
=======
       "      <td>62.204093</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[9.456276, 13.265001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.694734</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>8.628473</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>5.501292</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>5.542298</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[0.0, 6.869545]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>25</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>-20.598524</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-20.715586</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-20.826142</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-20.930783</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-21.030027</td>\n",
=======
       "      <td>-10.968332</td>\n",
=======
       "      <td>-9.748220</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
       "      <td>[0.0, 6.868508]</td>\n",
=======
       "      <td>-20.598524</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-20.715586</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-20.826142</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-20.930783</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>-11.317325</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>-10.044865</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>-21.030027</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lambda                features\n",
       "qid                                       \n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "1   0   427.587115  [11.657399, 10.083591]\n",
       "    1   219.800566        [0.0, 11.113943]\n",
       "    2    62.204093   [9.456276, 13.265001]\n",
       "    3    43.694734   [6.036743, 11.113943]\n",
       "    4     5.542298         [0.0, 6.869545]\n",
<<<<<<< HEAD
       "...            ...                     ...\n",
       "40  25  -20.598524              [0.0, 0.0]\n",
       "    26  -20.715586              [0.0, 0.0]\n",
       "    27  -20.826142              [0.0, 0.0]\n",
       "    28  -20.930783              [0.0, 0.0]\n",
       "    29  -21.030027              [0.0, 0.0]\n",
=======
       "1   0   183.343798  [11.657399, 10.083591]\n",
       "    1   116.134366        [0.0, 11.113943]\n",
       "    2    39.713833   [6.036743, 11.113943]\n",
       "    3    30.087439   [9.456276, 13.265001]\n",
       "    4     8.628473         [0.0, 6.869545]\n",
       "...            ...                     ...\n",
       "40  25  -10.968332         [0.0, 6.868508]\n",
       "    26  -11.062526        [5.8994045, 0.0]\n",
       "    27  -11.151815           [7.2726, 0.0]\n",
       "    28  -11.236624           [7.2726, 0.0]\n",
       "    29  -11.317325              [0.0, 0.0]\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "1   0   173.363849  [11.657399, 10.083591]\n",
       "    1   109.661979        [0.0, 11.113943]\n",
       "    2    34.900550   [6.036743, 11.113943]\n",
       "    3    26.275559   [9.456276, 13.265001]\n",
       "    4     5.501292         [0.0, 6.869545]\n",
       "...            ...                     ...\n",
       "40  25   -9.748220         [0.0, 6.868508]\n",
       "    26   -9.828286        [5.8994045, 0.0]\n",
       "    27   -9.904182           [7.2726, 0.0]\n",
       "    28   -9.976269           [7.2726, 0.0]\n",
       "    29  -10.044865              [0.0, 0.0]\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "...            ...                     ...\n",
       "40  25  -20.598524              [0.0, 0.0]\n",
       "    26  -20.715586              [0.0, 0.0]\n",
       "    27  -20.826142              [0.0, 0.0]\n",
       "    28  -20.930783              [0.0, 0.0]\n",
       "    29  -21.030027              [0.0, 0.0]\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "\n",
       "[1390 rows x 2 columns]"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 86,
=======
     "execution_count": 482,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 523,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 8,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 130,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 8,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 86,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = lambdas_per_query[['lambda', 'features']]\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 87,
=======
   "execution_count": 483,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 524,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 9,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 131,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 9,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 87,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 87,
=======
     "execution_count": 483,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 524,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 9,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 131,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 9,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 87,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(train_set['features'].tolist(), train_set['lambda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCG-based Lambda Predictions\n",
    "\n",
    "We show predicting some known examples. In the first case, strong title and overview scores. In the second case, no title or overview scores"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 88,
=======
   "execution_count": 484,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 525,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 10,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 132,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 12,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 88,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "array([445.85277429])"
      ]
     },
     "execution_count": 88,
=======
       "array([183.34379848])"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 484,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 525,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 10,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "array([173.36384867])"
      ]
     },
     "execution_count": 132,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "array([345.6500854])"
      ]
     },
     "execution_count": 12,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
       "array([445.85277429])"
      ]
     },
     "execution_count": 88,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "tree.predict([[11.1, 10.08]])"
=======
    "tree.predict([[11.6, 10.08]])"
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "tree.predict([[11.1, 10.08]])"
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 89,
=======
   "execution_count": 485,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 526,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 11,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 133,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 13,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 89,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "array([-15.3987952])"
      ]
     },
     "execution_count": 89,
=======
       "array([-6.80365819])"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 485,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 526,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 11,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "array([-6.28686321])"
      ]
     },
     "execution_count": 133,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "array([-15.3987952])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 13,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 89,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict([[0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's more typical we would restrict the complexity of each tree in the ensemble. We can dump the tree see [understanding sklearn's tree structure](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 90,
=======
   "execution_count": 379,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 527,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 12,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 134,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 14,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 90,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
       "[Text(167.4, 181.2, 'X[0] <= 10.666\\nmse = 4161.543\\nsamples = 1390\\nvalue = -0.0'),\n",
       " Text(83.7, 108.72, 'X[0] <= 9.182\\nmse = 1038.341\\nsamples = 1329\\nvalue = -9.745'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 421.042\\nsamples = 1301\\nvalue = -11.724'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 21086.54\\nsamples = 28\\nvalue = 82.191'),\n",
       " Text(251.10000000000002, 108.72, 'X[0] <= 18.186\\nmse = 25061.546\\nsamples = 61\\nvalue = 212.311'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 26150.423\\nsamples = 51\\nvalue = 188.147'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 1343.167\\nsamples = 10\\nvalue = 335.547')]"
<<<<<<< HEAD
      ]
     },
     "execution_count": 90,
=======
       "[Text(167.4, 181.2, 'X[0] <= 10.666\\nmse = 793.283\\nsamples = 1390\\nvalue = 0.0'),\n",
       " Text(83.7, 108.72, 'X[0] <= 9.182\\nmse = 222.998\\nsamples = 1329\\nvalue = -4.264'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 107.23\\nsamples = 1301\\nvalue = -5.173'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 3778.904\\nsamples = 28\\nvalue = 37.982'),\n",
       " Text(251.10000000000002, 108.72, 'X[0] <= 13.782\\nmse = 4190.964\\nsamples = 61\\nvalue = 92.903'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 4938.44\\nsamples = 34\\nvalue = 72.93'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 2114.76\\nsamples = 27\\nvalue = 118.054')]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 379,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 527,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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\n",
=======
      "image/png": "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\n",
>>>>>>> 4ef4e05 (Save lambda mart)
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
=======
       "[Text(248.0, 308.0, 'X[0] <= 10.666\\nmse = 793.283\\nsamples = 1390\\nvalue = 0.0'),\n",
       " Text(124.0, 184.79999999999998, 'X[0] <= 9.182\\nmse = 222.998\\nsamples = 1329\\nvalue = -4.264'),\n",
       " Text(62.0, 61.599999999999966, 'mse = 107.23\\nsamples = 1301\\nvalue = -5.173'),\n",
       " Text(186.0, 61.599999999999966, 'mse = 3778.904\\nsamples = 28\\nvalue = 37.982'),\n",
       " Text(372.0, 184.79999999999998, 'X[0] <= 13.782\\nmse = 4190.964\\nsamples = 61\\nvalue = 92.903'),\n",
       " Text(310.0, 61.599999999999966, 'mse = 4938.44\\nsamples = 34\\nvalue = 72.93'),\n",
       " Text(434.0, 61.599999999999966, 'mse = 2114.76\\nsamples = 27\\nvalue = 118.054')]"
=======
       "[Text(167.4, 181.2, 'X[0] <= 10.666\\nmse = 701.591\\nsamples = 1390\\nvalue = 0.0'),\n",
       " Text(83.7, 108.72, 'X[0] <= 9.182\\nmse = 190.687\\nsamples = 1329\\nvalue = -4.011'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 87.65\\nsamples = 1301\\nvalue = -4.856'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 3406.42\\nsamples = 28\\nvalue = 35.215'),\n",
       " Text(251.10000000000002, 108.72, 'X[0] <= 13.782\\nmse = 3843.623\\nsamples = 61\\nvalue = 87.398'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 4489.674\\nsamples = 34\\nvalue = 68.244'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 1986.303\\nsamples = 27\\nvalue = 111.518')]"
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "[Text(248.0, 308.0, 'X[0] <= 10.666\\nmse = 4161.543\\nsamples = 1390\\nvalue = -0.0'),\n",
       " Text(124.0, 184.79999999999998, 'X[0] <= 9.182\\nmse = 1038.341\\nsamples = 1329\\nvalue = -9.745'),\n",
       " Text(62.0, 61.599999999999966, 'mse = 421.042\\nsamples = 1301\\nvalue = -11.724'),\n",
       " Text(186.0, 61.599999999999966, 'mse = 21086.54\\nsamples = 28\\nvalue = 82.191'),\n",
       " Text(372.0, 184.79999999999998, 'X[0] <= 18.186\\nmse = 25061.546\\nsamples = 61\\nvalue = 212.311'),\n",
       " Text(310.0, 61.599999999999966, 'mse = 26150.423\\nsamples = 51\\nvalue = 188.147'),\n",
       " Text(434.0, 61.599999999999966, 'mse = 1343.167\\nsamples = 10\\nvalue = 335.547')]"
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
    },
    {
     "data": {
      "image/png": "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\n",
=======
    },
    {
     "data": {
      "image/png": "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\n",
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
<<<<<<< HEAD
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_leaf_nodes=4)\n",
    "tree.fit(train_set['features'].tolist(), train_set['lambda'])\n",
    "plot_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two - Compute the swaps but _scaled_ to current model's error\n",
    "\n",
    "LambdaMART is an _ensemble_ model. It's not just about the first model, but collecting a series of models where each model makes a gradual improvement on the current model. The technique used is known as [Gradient Boosting]()\n",
    "\n",
    "To build a model that compensates for the current model's error, we scale the next set of dependent vars to predict based on the correctness of the existing model in ranking. In this way, we eliminate where the model currently does a good job (no need to learn these) and leave in places where the model isn't doing a good job (this is where. we want ot learn)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 91,
=======
   "execution_count": 381,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 528,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 15,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 135,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 16,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 91,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>last_prediction</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>discount</th>\n",
       "      <th>gain</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <th>delta</th>\n",
=======
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <th>delta</th>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <th></th>\n",
=======
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <th></th>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1_7555</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.083591]</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>213.776822</td>\n",
       "      <td>427.553645</td>\n",
=======
       "      <td>7.292951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>0.100504</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>0.500000</td>\n",
<<<<<<< HEAD
       "      <td>8.000000</td>\n",
       "      <td>11.453678</td>\n",
       "      <td>91.640615</td>\n",
       "      <td>183.281230</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>7.500000</td>\n",
       "      <td>8.445435</td>\n",
       "      <td>86.813758</td>\n",
       "      <td>173.627515</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>213.776822</td>\n",
       "      <td>427.553645</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1370</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
<<<<<<< HEAD
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>48.987136</td>\n",
       "      <td>97.974272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1_1369</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>31.835338</td>\n",
       "      <td>63.670676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1_13258</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>1.292030</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>6.723500</td>\n",
       "      <td>13.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1_1368</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>5.802792</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>41.948006</td>\n",
       "      <td>83.896012</td>\n",
=======
       "      <td>3.798236</td>\n",
=======
       "      <td>223195</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
=======
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0.0</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <td>1</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>48.987136</td>\n",
       "      <td>97.974272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1_1369</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>31.835338</td>\n",
       "      <td>63.670676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1_13258</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>1.292030</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>6.723500</td>\n",
       "      <td>13.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1_1368</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>0.278943</td>\n",
<<<<<<< HEAD
       "      <td>0.278943</td>\n",
<<<<<<< HEAD
       "      <td>13.741487</td>\n",
       "      <td>-0.022346</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>11.453678</td>\n",
=======
       "      <td>0.000000</td>\n",
       "      <td>8.445435</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
       "      <td>-1.657928</td>\n",
       "      <td>-3.315856</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>0.386853</td>\n",
       "      <td>5.802792</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>41.948006</td>\n",
       "      <td>83.896012</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>...</td>\n",
=======
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>...</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>25</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>1385</td>\n",
       "      <td>40_37079</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-9.846078</td>\n",
       "      <td>-19.692155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1386</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-9.903461</td>\n",
       "      <td>-19.806921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1387</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-9.957655</td>\n",
       "      <td>-19.915309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1388</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-10.008949</td>\n",
       "      <td>-20.017899</td>\n",
=======
       "      <td>1366</td>\n",
       "      <td>40_1891</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>1891</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>25</td>\n",
       "      <td>0.173765</td>\n",
       "      <td>1.390123</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
=======
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <td>1365</td>\n",
       "      <td>40_1892</td>\n",
=======
       "      <td>1385</td>\n",
       "      <td>40_37079</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-9.846078</td>\n",
       "      <td>-19.692155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1386</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-9.903461</td>\n",
       "      <td>-19.806921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1387</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-9.957655</td>\n",
       "      <td>-19.915309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1388</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
<<<<<<< HEAD
       "      <td>0.169294</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>1.354350</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.002145</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.677175</td>\n",
       "      <td>13.216213</td>\n",
       "      <td>-3.515886</td>\n",
       "      <td>-7.031771</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>0.507881</td>\n",
       "      <td>10.207970</td>\n",
       "      <td>-3.241753</td>\n",
       "      <td>-6.483506</td>\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-10.008949</td>\n",
       "      <td>-20.017899</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1389</td>\n",
       "      <td>40_43052</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-10.057598</td>\n",
       "      <td>-20.115197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 14 columns</p>\n",
=======
       "      <td>-0.517338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.013697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 13 columns</p>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>-10.057598</td>\n",
       "      <td>-20.115197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 14 columns</p>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "</div>"
      ],
      "text/plain": [
       "        index        uid  qid   keywords   docId  grade  \\\n",
       "qid                                                       \n",
       "1   0       0     1_7555    1      rambo    7555      4   \n",
<<<<<<< HEAD
<<<<<<< HEAD
       "    1       1     1_1370    1      rambo    1370      3   \n",
<<<<<<< HEAD
       "    2       2     1_1369    1      rambo    1369      3   \n",
       "    3       3    1_13258    1      rambo   13258      2   \n",
       "    4       4     1_1368    1      rambo    1368      4   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1385   40_37079   40  star wars   37079      0   \n",
       "    26   1386  40_126757   40  star wars  126757      0   \n",
       "    27   1387   40_39797   40  star wars   39797      0   \n",
       "    28   1388   40_18112   40  star wars   18112      0   \n",
=======
       "    2      39    1_32221    1      rambo   32221      0   \n",
       "    3      29      1_801    1      rambo     801      1   \n",
       "    4      22       1_70    1      rambo      70      0   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1366    40_1891   40  star wars    1891      3   \n",
       "    26   1365    40_1892   40  star wars    1892      3   \n",
       "    27   1364    40_1895   40  star wars    1895      2   \n",
       "    28   1363  40_330459   40  star wars  330459      3   \n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "    1      21   1_223195    1      rambo  223195      0   \n",
       "    2      23    1_22777    1      rambo   22777      0   \n",
       "    3      24    1_43189    1      rambo   43189      0   \n",
       "    4      25      1_318    1      rambo     318      0   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1365    40_1892   40  star wars    1892      3   \n",
       "    26   1364    40_1895   40  star wars    1895      2   \n",
       "    27   1363  40_330459   40  star wars  330459      3   \n",
       "    28   1362   40_12180   40  star wars   12180      2   \n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "    1       1     1_1370    1      rambo    1370      3   \n",
       "    2       2     1_1369    1      rambo    1369      3   \n",
       "    3       3    1_13258    1      rambo   13258      2   \n",
       "    4       4     1_1368    1      rambo    1368      4   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1385   40_37079   40  star wars   37079      0   \n",
       "    26   1386  40_126757   40  star wars  126757      0   \n",
       "    27   1387   40_39797   40  star wars   39797      0   \n",
       "    28   1388   40_18112   40  star wars   18112      0   \n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    29   1389   40_43052   40  star wars   43052      0   \n",
       "\n",
       "                      features  last_prediction  display_rank  discount  \\\n",
       "qid                                                                       \n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "1   0   [11.657399, 10.083591]              0.0             0  1.000000   \n",
       "    1    [9.456276, 13.265001]              0.0             1  0.630930   \n",
       "    2    [6.036743, 11.113943]              0.0             2  0.500000   \n",
       "    3          [0.0, 6.869545]              0.0             3  0.430677   \n",
       "    4         [0.0, 11.113943]              0.0             4  0.386853   \n",
<<<<<<< HEAD
       "...                        ...              ...           ...       ...   \n",
       "40  25              [0.0, 0.0]              0.0            25  0.210310   \n",
       "    26              [0.0, 0.0]              0.0            26  0.208015   \n",
       "    27              [0.0, 0.0]              0.0            27  0.205847   \n",
       "    28              [0.0, 0.0]              0.0            28  0.203795   \n",
       "    29              [0.0, 0.0]              0.0             9  0.289065   \n",
       "\n",
       "             gain        dcg      lambda       delta  \n",
       "qid                                                   \n",
       "1   0   15.000000  30.700871  213.776822  427.553645  \n",
       "    1    4.416508  30.700871   48.987136   97.974272  \n",
       "    2    3.500000  30.700871   31.835338   63.670676  \n",
       "    3    1.292030  30.700871    6.723500   13.447000  \n",
       "    4    5.802792  30.700871   41.948006   83.896012  \n",
       "...           ...        ...         ...         ...  \n",
       "40  25   0.000000  30.207651   -9.846078  -19.692155  \n",
       "    26   0.000000  30.207651   -9.903461  -19.806921  \n",
       "    27   0.000000  30.207651   -9.957655  -19.915309  \n",
       "    28   0.000000  30.207651  -10.008949  -20.017899  \n",
       "    29   0.000000  30.207651  -10.057598  -20.115197  \n",
       "\n",
       "[1390 rows x 14 columns]"
      ]
     },
     "execution_count": 91,
<<<<<<< HEAD
=======
       "1   0   [11.657399, 10.083591]         7.292951             0  0.500000   \n",
       "    1    [9.456276, 13.265001]         3.798236             1  0.386853   \n",
       "    2               [0.0, 0.0]        -0.517338             2  0.333333   \n",
       "    3               [0.0, 0.0]        -0.517338             3  0.301030   \n",
       "    4               [0.0, 0.0]        -0.517338             4  0.278943   \n",
=======
       "1   0   [11.657399, 10.083591]              0.0             0  0.500000   \n",
       "    1               [0.0, 0.0]              0.0             1  0.386853   \n",
       "    2               [0.0, 0.0]              0.0             2  0.333333   \n",
       "    3               [0.0, 0.0]              0.0             3  0.301030   \n",
       "    4               [0.0, 0.0]              0.0             4  0.278943   \n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "...                        ...              ...           ...       ...   \n",
       "40  25              [0.0, 0.0]              0.0            25  0.210310   \n",
       "    26              [0.0, 0.0]              0.0            26  0.208015   \n",
       "    27              [0.0, 0.0]              0.0            27  0.205847   \n",
       "    28              [0.0, 0.0]              0.0            28  0.203795   \n",
       "    29              [0.0, 0.0]              0.0             9  0.289065   \n",
       "\n",
       "             gain        dcg      lambda       delta  \n",
       "qid                                                   \n",
       "1   0   15.000000  30.700871  213.776822  427.553645  \n",
       "    1    4.416508  30.700871   48.987136   97.974272  \n",
       "    2    3.500000  30.700871   31.835338   63.670676  \n",
       "    3    1.292030  30.700871    6.723500   13.447000  \n",
       "    4    5.802792  30.700871   41.948006   83.896012  \n",
       "...           ...        ...         ...         ...  \n",
       "40  25   0.000000  30.207651   -9.846078  -19.692155  \n",
       "    26   0.000000  30.207651   -9.903461  -19.806921  \n",
       "    27   0.000000  30.207651   -9.957655  -19.915309  \n",
       "    28   0.000000  30.207651  -10.008949  -20.017899  \n",
       "    29   0.000000  30.207651  -10.057598  -20.115197  \n",
       "\n",
       "[1390 rows x 14 columns]"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 381,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 528,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 15,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 135,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 16,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "judgments['last_prediction'] = tree.predict(judgments['features'].tolist()) * learning_rate\n",
    "\n",
    "def compute_swaps_scaled(query_judgments, axis, metric=dcg, at=10):\n",
    "    \"\"\"Compute the 'lambda' the DCG impact of every query result swapped with every-other query result\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "    # Important - stable sort. Otherwise DCG swaps get kind of wonky due to position discounts\n",
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False, kind='stable').reset_index()\n",
=======
    "    # Sort to see ideal ordering\n",
    "    # This isn't strictly nescesarry, but it's helpful to understand the algorithm\n",
=======
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False).reset_index()\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "    # Important - stable sort. Otherwise DCG swaps get kind of wonky due to position discounts\n",
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False, kind='stable').reset_index()\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
    "\n",
    "    # Instead of explicitly 'swapping' we just swap the 'display_rank' - where \n",
    "    # in the final ranking this would be placed. We can easily use that to compute DCG\n",
    "    query_judgments['display_rank'] = query_judgments.index.to_series()\n",
    "    query_judgments['dcg'] = metric(query_judgments, at=at)\n",
    "    best_dcg = query_judgments.loc[0, 'dcg']\n",
    "\n",
    "    query_judgments['lambda'] = 0.0\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    query_judgments['delta'] = 0.0\n",
=======
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "    query_judgments['delta'] = 0.0\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "    \n",
    "    for better in range(0,len(query_judgments)):\n",
    "        for worse in range(better+1,len(query_judgments)):\n",
    "            if better > at and worse > at:\n",
    "                break\n",
    "            if query_judgments.loc[better, 'grade'] > query_judgments.loc[worse, 'grade']:\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "                swap_judgments = rank_with_swap(query_judgments, better, worse)\n",
    "                dcg_after_swap = metric(swap_judgments, at=at)\n",
    "\n",
    "                delta = abs(best_dcg - dcg_after_swap)\n",
=======
    "                query_judgments = rank_with_swap(query_judgments, better, worse)\n",
    "                query_judgments['dcg'] = metric(query_judgments, at=at)\n",
    "\n",
    "                dcg_after_swap = query_judgments.loc[0, 'dcg']\n",
    "                delta = best_dcg - dcg_after_swap\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "                swap_judgments = rank_with_swap(query_judgments, better, worse)\n",
    "                dcg_after_swap = metric(swap_judgments, at=at)\n",
    "\n",
    "                delta = abs(best_dcg - dcg_after_swap)\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "\n",
    "                if delta > 0.0:\n",
    "                    \n",
    "                    # --------------\n",
    "                    # NEW!\n",
    "                    model_score_diff = query_judgments.loc[better, 'last_prediction'] - query_judgments.loc[worse, 'last_prediction']\n",
    "                    rho = 1.0 / (1.0 + exp(model_score_diff))    \n",
    "                    # --------------\n",
    "                    # rho works as follows\n",
    "                    # \n",
    "                    # model ranks                    rho\n",
    "                    # better higher than worse       approaches 0      <-- model currently doing well!\n",
    "                    # better same as worse.          0.5  \n",
    "                    # worse higher than better       approaches 1      <-- model currently doing poorly!\n",
    "                    # \n",
<<<<<<< HEAD
<<<<<<< HEAD
    "                    query_judgments.loc[better, 'delta'] += delta\n",
    "                    \n",
=======
    "\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "                    query_judgments.loc[better, 'delta'] += delta\n",
    "                    \n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "                    # Use rho to scale the lambdas\n",
    "                    query_judgments.loc[better, 'lambda'] += delta * rho\n",
    "        \n",
    "                    query_judgments.loc[worse, 'lambda'] -= delta * rho\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "                    query_judgments.loc[worse, 'delta'] -= delta\n",
    "\n",
    "    return query_judgments\n",
    "\n",
    "judgments = to_dataframe(ftr_logger.logged)\n",
    "judgments['last_prediction'] = 0.0\n",
    "lambdas_per_query = judgments.groupby('qid').apply(compute_swaps_scaled, axis=1)\n",
    "#\n",
=======
=======
    "                    query_judgments.loc[worse, 'delta'] -= delta\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "\n",
    "    return query_judgments\n",
    "\n",
    "judgments = to_dataframe(ftr_logger.logged)\n",
    "judgments['last_prediction'] = 0.0\n",
    "lambdas_per_query = judgments.groupby('qid').apply(compute_swaps_scaled, axis=1)\n",
<<<<<<< HEAD
    "\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "#\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "lambdas_per_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero in on 2 swapped by each result worse than it in query `ramba`\n",
    "\n",
    "```\n",
    "better_grade worse_grade, model_score_diffs, rho,                 dcg_delta\n",
    "2 1                       0.758706128029972  0.31892724571177816  0.02502724555344038\n",
    "2 1                       0.981162516523929  0.2726611758805124   0.04377062727053094\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.11698017724693699\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.14090604137532914\n",
    "2 1                       1.142439045359345  0.24187283082372052  0.08043118677314176\n",
    "2 1                       1.142439045359345  0.24187283082372052  0.17784892734690594\n",
    "2 1                       1.142439045359345  0.24187283082372052  0.19254512210920538\n",
    "2 1                       1.142439045359345  0.24187283082372052  0.20543079947538878\n",
    "2 1                       1.142439045359345  0.24187283082372052  0.21685570619866112\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.22708156316293504\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.23630863576764227\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.24469312448475122\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.2523588995024131\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.25940563061320177\n",
    "2 0                       1.142439045359345  0.24187283082372052  0.2659145510893115\n",
    "...\n",
    "2 0                       1.142439045359345  0.24187283082372052 0.34214193097965406\n",
    "```\n",
    "\n",
    "Summing all the model score diffs, we see those are rather high. This results in a high-ish rho between (for each value here 0.25-0.31). So each dcg_delta is added to the model.\n",
    "\n",
    "What's the intuition here? The model hasn't entirely nailed this example, the model feels there's more 'dcg_delta' to learn to push it away from those less relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zooming out to more of `rambo`\n",
    "\n",
    "We see a similar pattern in results with mediocre grades (2 and 3) where the resulting rho-scaled lambda's are higher than you might expect. The model's happy with the position of 0, but the ranking of other results could be separated more. The model diff should be higher when compared to the dcg diff to push the middling results away from the irrelevant result.\n",
    "\n",
    "So the next tree learns these lambdas using the resulting features moreso than other results."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 92,
=======
   "execution_count": 382,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 529,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 16,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 69,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 17,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 92,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <th>display_rank</th>\n",
       "      <th>grade</th>\n",
       "      <th>last_prediction</th>\n",
       "      <th>delta</th>\n",
<<<<<<< HEAD
=======
       "      <th>grade</th>\n",
       "      <th>last_prediction</th>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <th>lambda</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>427.553645</td>\n",
       "      <td>213.776822</td>\n",
<<<<<<< HEAD
       "      <td>[11.657399, 10.083591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rambo</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.868699</td>\n",
       "      <td>-9.934349</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rambo</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.149295</td>\n",
       "      <td>-10.074647</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rambo</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.276314</td>\n",
       "      <td>-10.138157</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rambo</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.395685</td>\n",
       "      <td>-10.197842</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rambo</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.508155</td>\n",
       "      <td>-10.254078</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rambo</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.336529</td>\n",
       "      <td>-10.168264</td>\n",
=======
=======
       "      <td>0</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.281230</td>\n",
       "      <td>91.640615</td>\n",
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[11.657399, 10.083591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rambo</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.868699</td>\n",
       "      <td>-9.934349</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rambo</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.149295</td>\n",
       "      <td>-10.074647</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rambo</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.276314</td>\n",
       "      <td>-10.138157</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rambo</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.395685</td>\n",
       "      <td>-10.197842</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rambo</td>\n",
       "      <td>26</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
<<<<<<< HEAD
       "      <td>-0.517338</td>\n",
       "      <td>-0.019625</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.432963</td>\n",
       "      <td>-10.216481</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rambo</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.524423</td>\n",
       "      <td>-10.262211</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rambo</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.611330</td>\n",
       "      <td>-10.305665</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rambo</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.694056</td>\n",
       "      <td>-10.347028</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rambo</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.069351</td>\n",
       "      <td>-10.534675</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rambo</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.147879</td>\n",
       "      <td>-10.573939</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rambo</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.222977</td>\n",
       "      <td>-10.611488</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rambo</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.294893</td>\n",
       "      <td>-10.647447</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rambo</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.363851</td>\n",
       "      <td>-10.681926</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rambo</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.430053</td>\n",
       "      <td>-10.715026</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rambo</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.493681</td>\n",
       "      <td>-10.746841</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rambo</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.554902</td>\n",
       "      <td>-10.777451</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rambo</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.013760</td>\n",
       "      <td>-10.006880</td>\n",
=======
       "      <td>1</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>-0.025089</td>\n",
       "      <td>[0.0, 4.563677]</td>\n",
=======
       "      <td>0.0</td>\n",
       "      <td>-5.244873</td>\n",
       "      <td>-2.622437</td>\n",
       "      <td>[0.0, 7.8627386]</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.508155</td>\n",
       "      <td>-10.254078</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rambo</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.336529</td>\n",
       "      <td>-10.168264</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>11</th>\n",
       "      <td>rambo</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>-0.020225</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.712923</td>\n",
       "      <td>-9.856462</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rambo</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.974272</td>\n",
       "      <td>48.987136</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rambo</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.545028</td>\n",
       "      <td>-9.772514</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rambo</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.670676</td>\n",
       "      <td>31.835338</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rambo</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.447000</td>\n",
       "      <td>6.723500</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rambo</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.896012</td>\n",
       "      <td>41.948006</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rambo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.400912</td>\n",
       "      <td>-4.200456</td>\n",
       "      <td>[0.0, 7.8627386]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rambo</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.024956</td>\n",
       "      <td>-5.012478</td>\n",
       "      <td>[0.0, 4.563677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rambo</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.243092</td>\n",
       "      <td>-7.621546</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rambo</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.950401</td>\n",
       "      <td>-7.975200</td>\n",
=======
       "      <td>1</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>-0.023536</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.536694</td>\n",
       "      <td>-8.268347</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rambo</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.032666</td>\n",
       "      <td>-8.516333</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rambo</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.459201</td>\n",
       "      <td>-8.729601</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rambo</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.831043</td>\n",
       "      <td>-8.915522</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rambo</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.158927</td>\n",
       "      <td>-9.079464</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rambo</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.450871</td>\n",
       "      <td>-9.225435</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rambo</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.712994</td>\n",
       "      <td>-9.356497</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rambo</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.950060</td>\n",
       "      <td>-9.475030</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rambo</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.165834</td>\n",
       "      <td>-9.582917</td>\n",
=======
       "      <td>1</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>1.098537</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rambo</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>2.992312</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
=======
       "      <th>28</th>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <td>rambo</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.432963</td>\n",
       "      <td>-10.216481</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rambo</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.524423</td>\n",
       "      <td>-10.262211</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rambo</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.611330</td>\n",
       "      <td>-10.305665</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rambo</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.694056</td>\n",
       "      <td>-10.347028</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rambo</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.069351</td>\n",
       "      <td>-10.534675</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rambo</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.147879</td>\n",
       "      <td>-10.573939</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rambo</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.222977</td>\n",
       "      <td>-10.611488</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rambo</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.294893</td>\n",
       "      <td>-10.647447</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rambo</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.363851</td>\n",
       "      <td>-10.681926</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rambo</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.430053</td>\n",
       "      <td>-10.715026</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rambo</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.493681</td>\n",
       "      <td>-10.746841</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rambo</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.554902</td>\n",
       "      <td>-10.777451</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rambo</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.013760</td>\n",
       "      <td>-10.006880</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rambo</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.712923</td>\n",
       "      <td>-9.856462</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rambo</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.974272</td>\n",
       "      <td>48.987136</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rambo</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>-0.517338</td>\n",
       "      <td>-0.177656</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.0</td>\n",
<<<<<<< HEAD
       "      <td>-5.440092</td>\n",
       "      <td>-2.720046</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>-19.545028</td>\n",
       "      <td>-9.772514</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.363338</td>\n",
       "      <td>-9.681669</td>\n",
=======
=======
       "      <td>2</td>\n",
<<<<<<< HEAD
>>>>>>> 95bbadd (use absolute value in delta calculatio)
       "      <td>0</td>\n",
=======
       "      <td>3</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>0.0</td>\n",
       "      <td>63.670676</td>\n",
       "      <td>31.835338</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rambo</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.447000</td>\n",
       "      <td>6.723500</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rambo</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.896012</td>\n",
       "      <td>41.948006</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rambo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.400912</td>\n",
       "      <td>-4.200456</td>\n",
       "      <td>[0.0, 7.8627386]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rambo</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.024956</td>\n",
       "      <td>-5.012478</td>\n",
       "      <td>[0.0, 4.563677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rambo</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.243092</td>\n",
       "      <td>-7.621546</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rambo</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.950401</td>\n",
       "      <td>-7.975200</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rambo</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.536694</td>\n",
       "      <td>-8.268347</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rambo</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.032666</td>\n",
       "      <td>-8.516333</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rambo</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.459201</td>\n",
       "      <td>-8.729601</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rambo</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD
       "      <td>-0.517338</td>\n",
       "      <td>-0.129999</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>0.0</td>\n",
       "      <td>-17.831043</td>\n",
       "      <td>-8.915522</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rambo</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.158927</td>\n",
       "      <td>-9.079464</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rambo</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.450871</td>\n",
       "      <td>-9.225435</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rambo</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.712994</td>\n",
       "      <td>-9.356497</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rambo</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.950060</td>\n",
       "      <td>-9.475030</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rambo</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.165834</td>\n",
       "      <td>-9.582917</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rambo</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
<<<<<<< HEAD
       "      <td>-5.381225</td>\n",
       "      <td>-2.690613</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>-19.363338</td>\n",
       "      <td>-9.681669</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rambo</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.613868</td>\n",
       "      <td>-10.806934</td>\n",
=======
       "      <td>0</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>-0.238927</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.136362</td>\n",
       "      <td>-3.068181</td>\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.613868</td>\n",
       "      <td>-10.806934</td>\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "   keywords  display_rank  grade  last_prediction       delta      lambda  \\\n",
       "0     rambo             0      4              0.0  427.553645  213.776822   \n",
       "21    rambo            21      0              0.0  -19.868699   -9.934349   \n",
       "23    rambo            23      0              0.0  -20.149295  -10.074647   \n",
       "24    rambo            24      0              0.0  -20.276314  -10.138157   \n",
       "25    rambo            25      0              0.0  -20.395685  -10.197842   \n",
       "26    rambo            26      0              0.0  -20.508155  -10.254078   \n",
       "27    rambo            27      1              0.0  -20.336529  -10.168264   \n",
       "28    rambo            28      1              0.0  -20.432963  -10.216481   \n",
       "29    rambo            29      1              0.0  -20.524423  -10.262211   \n",
       "30    rambo            30      1              0.0  -20.611330  -10.305665   \n",
       "31    rambo            31      1              0.0  -20.694056  -10.347028   \n",
       "32    rambo            32      0              0.0  -21.069351  -10.534675   \n",
       "33    rambo            33      0              0.0  -21.147879  -10.573939   \n",
       "34    rambo            34      0              0.0  -21.222977  -10.611488   \n",
       "35    rambo            35      0              0.0  -21.294893  -10.647447   \n",
       "36    rambo            36      0              0.0  -21.363851  -10.681926   \n",
       "37    rambo            37      0              0.0  -21.430053  -10.715026   \n",
       "38    rambo            38      0              0.0  -21.493681  -10.746841   \n",
       "39    rambo            39      0              0.0  -21.554902  -10.777451   \n",
       "22    rambo            22      0              0.0  -20.013760  -10.006880   \n",
       "20    rambo            20      0              0.0  -19.712923   -9.856462   \n",
       "1     rambo             1      3              0.0   97.974272   48.987136   \n",
       "19    rambo            19      0              0.0  -19.545028   -9.772514   \n",
       "2     rambo             2      3              0.0   63.670676   31.835338   \n",
       "3     rambo             3      2              0.0   13.447000    6.723500   \n",
       "4     rambo             4      4              0.0   83.896012   41.948006   \n",
       "5     rambo             5      1              0.0   -8.400912   -4.200456   \n",
       "6     rambo            40      1              0.0  -10.024956   -5.012478   \n",
       "7     rambo             7      0              0.0  -15.243092   -7.621546   \n",
       "8     rambo             8      0              0.0  -15.950401   -7.975200   \n",
       "9     rambo             9      0              0.0  -16.536694   -8.268347   \n",
       "10    rambo            10      0              0.0  -17.032666   -8.516333   \n",
       "11    rambo            11      0              0.0  -17.459201   -8.729601   \n",
       "12    rambo            12      0              0.0  -17.831043   -8.915522   \n",
       "13    rambo            13      0              0.0  -18.158927   -9.079464   \n",
       "14    rambo            14      0              0.0  -18.450871   -9.225435   \n",
       "15    rambo            15      0              0.0  -18.712994   -9.356497   \n",
       "16    rambo            16      0              0.0  -18.950060   -9.475030   \n",
       "17    rambo            17      0              0.0  -19.165834   -9.582917   \n",
       "18    rambo            18      0              0.0  -19.363338   -9.681669   \n",
       "40    rambo             6      0              0.0  -21.613868  -10.806934   \n",
<<<<<<< HEAD
       "\n",
       "                  features  \n",
       "0   [11.657399, 10.083591]  \n",
       "21              [0.0, 0.0]  \n",
       "23              [0.0, 0.0]  \n",
       "24              [0.0, 0.0]  \n",
       "25              [0.0, 0.0]  \n",
       "26              [0.0, 0.0]  \n",
       "27              [0.0, 0.0]  \n",
=======
       "   keywords  display_rank  grade  last_prediction       delta     lambda  \\\n",
       "0     rambo             0      4              0.0  183.281230  91.640615   \n",
       "21    rambo            21      3              0.0   -5.103318  -2.551659   \n",
       "23    rambo            23      3              0.0   -5.165059  -2.582529   \n",
       "24    rambo            24      2              0.0   -5.193199  -2.596599   \n",
       "25    rambo            25      4              0.0    0.000000   0.000000   \n",
       "26    rambo            26      1              0.0   -5.244873  -2.622437   \n",
       "27    rambo            27      1              0.0   -5.268684  -2.634342   \n",
       "28    rambo            28      0              0.0   -5.827818  -2.913909   \n",
       "29    rambo            29      0              0.0   -5.860098  -2.930049   \n",
       "30    rambo            30      0              0.0   -5.890869  -2.945435   \n",
       "31    rambo            31      0              0.0   -5.920248  -2.960124   \n",
       "32    rambo            32      0              0.0   -5.948340  -2.974170   \n",
       "33    rambo            33      0              0.0   -5.975240  -2.987620   \n",
       "34    rambo            34      0              0.0   -6.001032  -3.000516   \n",
       "35    rambo            35      0              0.0   -6.025794  -3.012897   \n",
       "36    rambo            36      0              0.0   -6.049595  -3.024798   \n",
       "37    rambo            37      0              0.0   -6.072498  -3.036249   \n",
       "38    rambo            38      0              0.0   -6.094559  -3.047279   \n",
       "39    rambo            39      0              0.0   -6.115831  -3.057916   \n",
       "22    rambo            22      0              0.0   -5.593615  -2.796808   \n",
       "20    rambo            20      0              0.0   -5.494807  -2.747403   \n",
       "1     rambo             1      0              0.0   -1.697208  -0.848604   \n",
       "19    rambo            19      0              0.0   -5.440092  -2.720046   \n",
       "2     rambo             2      0              0.0   -2.500000  -1.250000   \n",
       "3     rambo             3      0              0.0   -2.984550  -1.492275   \n",
       "4     rambo             4      0              0.0   -3.315856  -1.657928   \n",
       "5     rambo             5      0              0.0   -3.560257  -1.780128   \n",
       "6     rambo             6      1              0.0   -0.003253  -0.001626   \n",
       "7     rambo             7      1              0.0   -0.634880  -0.317440   \n",
       "8     rambo             8      1              0.0   -1.157804  -0.578902   \n",
       "9     rambo             9      1              0.0   -1.600136  -0.800068   \n",
       "10    rambo            40      1              0.0   -4.510331  -2.255166   \n",
       "11    rambo            11      0              0.0   -4.784964  -2.392482   \n",
       "12    rambo            12      0              0.0   -4.898519  -2.449259   \n",
       "13    rambo            13      0              0.0   -4.999788  -2.499894   \n",
       "14    rambo            14      0              0.0   -5.090869  -2.545435   \n",
       "15    rambo            15      0              0.0   -5.173390  -2.586695   \n",
       "16    rambo            16      0              0.0   -5.248635  -2.624318   \n",
       "17    rambo            17      0              0.0   -5.317635  -2.658818   \n",
       "18    rambo            18      0              0.0   -5.381225  -2.690613   \n",
       "40    rambo            10      0              0.0   -6.136362  -3.068181   \n",
       "\n",
       "                  features  \n",
       "0   [11.657399, 10.083591]  \n",
       "21   [9.456276, 13.265001]  \n",
       "23   [6.036743, 11.113943]  \n",
       "24         [0.0, 6.869545]  \n",
       "25        [0.0, 11.113943]  \n",
       "26        [0.0, 7.8627386]  \n",
       "27         [0.0, 4.563677]  \n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "\n",
       "                  features  \n",
       "0   [11.657399, 10.083591]  \n",
       "21              [0.0, 0.0]  \n",
       "23              [0.0, 0.0]  \n",
       "24              [0.0, 0.0]  \n",
       "25              [0.0, 0.0]  \n",
       "26              [0.0, 0.0]  \n",
       "27              [0.0, 0.0]  \n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "28              [0.0, 0.0]  \n",
       "29              [0.0, 0.0]  \n",
       "30              [0.0, 0.0]  \n",
       "31              [0.0, 0.0]  \n",
       "32              [0.0, 0.0]  \n",
       "33              [0.0, 0.0]  \n",
       "34              [0.0, 0.0]  \n",
       "35              [0.0, 0.0]  \n",
       "36              [0.0, 0.0]  \n",
       "37              [0.0, 0.0]  \n",
       "38              [0.0, 0.0]  \n",
       "39              [0.0, 0.0]  \n",
       "22              [0.0, 0.0]  \n",
       "20              [0.0, 0.0]  \n",
<<<<<<< HEAD
<<<<<<< HEAD
       "1    [9.456276, 13.265001]  \n",
       "19              [0.0, 0.0]  \n",
       "2    [6.036743, 11.113943]  \n",
       "3          [0.0, 6.869545]  \n",
       "4         [0.0, 11.113943]  \n",
       "5         [0.0, 7.8627386]  \n",
       "6          [0.0, 4.563677]  \n",
=======
       "1               [0.0, 0.0]  \n",
       "19              [0.0, 0.0]  \n",
       "2               [0.0, 0.0]  \n",
       "3               [0.0, 0.0]  \n",
       "4               [0.0, 0.0]  \n",
       "5               [0.0, 0.0]  \n",
       "6               [0.0, 0.0]  \n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
       "1    [9.456276, 13.265001]  \n",
       "19              [0.0, 0.0]  \n",
       "2    [6.036743, 11.113943]  \n",
       "3          [0.0, 6.869545]  \n",
       "4         [0.0, 11.113943]  \n",
       "5         [0.0, 7.8627386]  \n",
       "6          [0.0, 4.563677]  \n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "7               [0.0, 0.0]  \n",
       "8               [0.0, 0.0]  \n",
       "9               [0.0, 0.0]  \n",
       "10              [0.0, 0.0]  \n",
       "11              [0.0, 0.0]  \n",
       "12              [0.0, 0.0]  \n",
       "13              [0.0, 0.0]  \n",
       "14              [0.0, 0.0]  \n",
       "15              [0.0, 0.0]  \n",
       "16              [0.0, 0.0]  \n",
       "17              [0.0, 0.0]  \n",
       "18              [0.0, 0.0]  \n",
       "40              [0.0, 0.0]  "
<<<<<<< HEAD
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 92,
=======
       "   keywords  grade  last_prediction    lambda                features\n",
       "0     rambo      4         7.292951  0.100504  [11.657399, 10.083591]\n",
       "26    rambo      4        -0.517338  0.000000        [0.0, 11.113943]\n",
       "24    rambo      3        -0.517338 -0.002105   [6.036743, 11.113943]\n",
       "1     rambo      3         3.798236  0.697540   [9.456276, 13.265001]\n",
       "25    rambo      2        -0.517338 -0.024589         [0.0, 6.869545]\n",
       "10    rambo      1        -0.517338 -0.019625              [0.0, 0.0]\n",
       "28    rambo      1        -0.517338 -0.025089         [0.0, 4.563677]\n",
       "27    rambo      1        -0.517338 -0.024931        [0.0, 7.8627386]\n",
       "11    rambo      1        -0.517338 -0.020225              [0.0, 0.0]\n",
       "20    rambo      1        -0.517338 -0.023536              [0.0, 0.0]\n",
       "9     rambo      1        -0.517338  1.098537              [0.0, 0.0]\n",
       "3     rambo      1        -0.517338  2.992312              [0.0, 0.0]\n",
       "4     rambo      0        -0.517338 -0.022346              [0.0, 0.0]\n",
       "39    rambo      0        -0.517338 -0.237120              [0.0, 0.0]\n",
       "38    rambo      0        -0.517338 -0.235248              [0.0, 0.0]\n",
       "37    rambo      0        -0.517338 -0.233307              [0.0, 0.0]\n",
       "36    rambo      0        -0.517338 -0.231291              [0.0, 0.0]\n",
       "35    rambo      0        -0.517338 -0.229197              [0.0, 0.0]\n",
       "34    rambo      0        -0.517338 -0.227018              [0.0, 0.0]\n",
       "33    rambo      0        -0.517338 -0.224748              [0.0, 0.0]\n",
       "32    rambo      0        -0.517338 -0.222381              [0.0, 0.0]\n",
       "31    rambo      0        -0.517338 -0.219909              [0.0, 0.0]\n",
       "30    rambo      0        -0.517338 -0.217324              [0.0, 0.0]\n",
       "29    rambo      0        -0.517338 -0.214616              [0.0, 0.0]\n",
       "2     rambo      0        -0.517338 -0.005952              [0.0, 0.0]\n",
       "5     rambo      0        -0.517338 -0.032095              [0.0, 0.0]\n",
       "8     rambo      0        -0.517338 -0.050806              [0.0, 0.0]\n",
       "6     rambo      0        -0.517338 -0.039664              [0.0, 0.0]\n",
       "23    rambo      0        -0.517338 -0.195112              [0.0, 0.0]\n",
       "22    rambo      0        -0.517338 -0.191166              [0.0, 0.0]\n",
       "21    rambo      0        -0.517338 -0.186963              [0.0, 0.0]\n",
       "7     rambo      0        -0.517338 -0.045760              [0.0, 0.0]\n",
       "19    rambo      0        -0.517338 -0.177656              [0.0, 0.0]\n",
       "18    rambo      0        -0.517338 -0.172476              [0.0, 0.0]\n",
       "17    rambo      0        -0.517338 -0.166880              [0.0, 0.0]\n",
       "16    rambo      0        -0.517338 -0.160809              [0.0, 0.0]\n",
       "15    rambo      0        -0.517338 -0.154187              [0.0, 0.0]\n",
       "14    rambo      0        -0.517338 -0.146926              [0.0, 0.0]\n",
       "13    rambo      0        -0.517338 -0.138911              [0.0, 0.0]\n",
       "12    rambo      0        -0.517338 -0.129999              [0.0, 0.0]\n",
       "40    rambo      0        -0.517338 -0.238927              [0.0, 0.0]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 382,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 529,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
      ]
     },
<<<<<<< HEAD
     "execution_count": 16,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 69,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 17,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 92,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "lambdas_per_query.loc[1, :][['keywords', 'display_rank',  'grade', 'last_prediction', 'delta', 'lambda', 'features']].sort_values('last_prediction', ascending=False)"
=======
    "lambdas_per_query.loc[1, :][['keywords', 'grade', 'last_prediction', 'lambda', 'features']].sort_values('grade', ascending=False)"
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "lambdas_per_query.loc[1, :][['keywords', 'display_rank',  'grade', 'last_prediction', 'delta', 'lambda', 'features']].sort_values('last_prediction', ascending=False)"
>>>>>>> 95bbadd (use absolute value in delta calculatio)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 93,
=======
   "execution_count": 383,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 530,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 17,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 70,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 18,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 93,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 93,
=======
     "execution_count": 383,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 530,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
     "execution_count": 17,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 70,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
     "execution_count": 18,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 93,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "train_set = lambdas_per_query[['lambda', 'features']]\n",
    "train_set\n",
    "\n",
    "tree2 = DecisionTreeRegressor()\n",
    "tree2.fit(train_set['features'].tolist(), train_set['lambda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More 'oomph' in second tree for the last tree's error cases\n",
    "\n",
    "We see in the following lambdas our next tree learns more about the areas the last model seemed to need correction. \n",
    "\n",
    "The first example is well covered by the first tree."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 94,
=======
   "execution_count": 384,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 531,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 18,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 71,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 19,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 94,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "array([173.48027244])"
      ]
     },
     "execution_count": 94,
=======
       "array([0.10050401])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 384,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 531,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
       "array([91.64061509])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 18,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 71,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "array([173.48027244])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 19,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 94,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree2.predict([[11.6, 10.08]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example reflects some of the middling ranked results"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 95,
=======
   "execution_count": 385,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 532,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 19,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 72,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 20,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 95,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "array([6.72350002])"
      ]
     },
     "execution_count": 95,
=======
       "array([-0.02458865])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 385,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 532,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
       "array([-2.59659949])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 19,
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
     "execution_count": 72,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "array([6.72350002])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 20,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 95,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree2.predict([[0.0, 6.869545]])"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.75718641e-16]],\n",
       "\n",
       "       [[-4.26415296e+00]],\n",
       "\n",
       "       [[ 9.29026112e+01]],\n",
       "\n",
       "       [[-5.17337837e+00]],\n",
       "\n",
       "       [[ 3.79823562e+01]],\n",
       "\n",
       "       [[ 7.29295071e+01]],\n",
       "\n",
       "       [[ 1.18053928e+02]]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree_.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'apply',\n",
       " 'capacity',\n",
       " 'children_left',\n",
       " 'children_right',\n",
       " 'compute_feature_importances',\n",
       " 'compute_partial_dependence',\n",
       " 'decision_path',\n",
       " 'feature',\n",
       " 'impurity',\n",
       " 'max_depth',\n",
       " 'max_n_classes',\n",
       " 'n_classes',\n",
       " 'n_features',\n",
       " 'n_leaves',\n",
       " 'n_node_samples',\n",
       " 'n_outputs',\n",
       " 'node_count',\n",
       " 'predict',\n",
       " 'threshold',\n",
       " 'value',\n",
       " 'weighted_n_node_samples']"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree.tree_.decision_path(np.array([[0.0, 6.869545]], dtype='float32')).toarray()\n",
    "dir(tree.tree_)"
   ]
  },
  {
>>>>>>> 4ef4e05 (Save lambda mart)
=======
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three - Weigh each leaf's predictions\n",
    "\n",
    "Because we're dealing with trees, each leaf corresponds to a set of examples that have been grouped to this node. In addition to per-swap 'rho' we also care about a per-swap 'weight', referred to in gradient boosting as 'gamma'. \n",
    "\n",
    "Gamma means picking a weight for this sub-model that best predicts the final function.\n",
    "\n",
    "First we group by the paths in the tree to uniquely identify each leaf"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 96,
=======
   "execution_count": 414,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 534,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>qid</th>\n",
       "      <th>uid</th>\n",
=======
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>last_prediction</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>discount</th>\n",
       "      <th>gain</th>\n",
       "      <th>train_dcg</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
<<<<<<< HEAD
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_7555</td>\n",
=======
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1_7555</td>\n",
       "      <td>1</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.083591]</td>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>213.776822</td>\n",
       "      <td>106.888411</td>\n",
=======
       "      <td>7.292951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>0.100504</td>\n",
       "      <td>0.099688</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1370</td>\n",
<<<<<<< HEAD
=======
       "      <td>1</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>48.010828</td>\n",
       "      <td>26.458003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1369</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>31.382749</td>\n",
       "      <td>18.143963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1_13258</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>1.292030</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>6.460558</td>\n",
       "      <td>7.448315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1368</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>5.802792</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>43.639845</td>\n",
       "      <td>21.819923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
=======
       "      <td>3.798236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>3.094822</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>0.697540</td>\n",
       "      <td>0.740546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>1_32221</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>32221</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>-0.005952</td>\n",
       "      <td>0.005887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>1_801</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>801</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>3</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>2.992312</td>\n",
       "      <td>1.507942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1_70</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>13.741487</td>\n",
       "      <td>-0.022346</td>\n",
       "      <td>0.016692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>1385</th>\n",
       "      <td>40</td>\n",
       "      <td>40_37079</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.846078</td>\n",
       "      <td>4.923039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>40</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.903461</td>\n",
       "      <td>4.951730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>40</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.957655</td>\n",
       "      <td>4.978827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>40</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-10.008949</td>\n",
       "      <td>5.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>40</td>\n",
       "      <td>40_43052</td>\n",
=======
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>25</th>\n",
       "      <td>1366</td>\n",
       "      <td>40_1891</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>1891</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>25</td>\n",
       "      <td>0.173765</td>\n",
       "      <td>1.390123</td>\n",
       "      <td>11.668802</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1365</td>\n",
       "      <td>40_1892</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>1892</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 2.4547963]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>26</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>1.377563</td>\n",
       "      <td>11.668802</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.002126</td>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1364</td>\n",
       "      <td>40_1895</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>1895</td>\n",
       "      <td>2</td>\n",
       "      <td>[6.487482, 2.062405]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>27</td>\n",
       "      <td>0.170707</td>\n",
       "      <td>0.682829</td>\n",
       "      <td>11.668802</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1363</td>\n",
       "      <td>40_330459</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>330459</td>\n",
       "      <td>3</td>\n",
       "      <td>[7.2694716, 4.237955]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>28</td>\n",
       "      <td>0.169294</td>\n",
       "      <td>1.354350</td>\n",
       "      <td>11.668802</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1389</td>\n",
       "      <td>40_43052</td>\n",
       "      <td>40</td>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-10.057598</td>\n",
       "      <td>5.028799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid        uid   keywords   docId  grade                features  \\\n",
       "0       1     1_7555      rambo    7555      4  [11.657399, 10.083591]   \n",
       "1       1     1_1370      rambo    1370      3   [9.456276, 13.265001]   \n",
       "2       1     1_1369      rambo    1369      3   [6.036743, 11.113943]   \n",
       "3       1    1_13258      rambo   13258      2         [0.0, 6.869545]   \n",
       "4       1     1_1368      rambo    1368      4        [0.0, 11.113943]   \n",
       "...   ...        ...        ...     ...    ...                     ...   \n",
       "1385   40   40_37079  star wars   37079      0              [0.0, 0.0]   \n",
       "1386   40  40_126757  star wars  126757      0              [0.0, 0.0]   \n",
       "1387   40   40_39797  star wars   39797      0              [0.0, 0.0]   \n",
       "1388   40   40_18112  star wars   18112      0              [0.0, 0.0]   \n",
       "1389   40   40_43052  star wars   43052      0              [0.0, 0.0]   \n",
       "\n",
       "      last_prediction  display_rank  discount       gain  train_dcg  \\\n",
       "0                   0             0  1.000000  15.000000  30.700871   \n",
       "1                   0             1  0.630930   4.416508  30.700871   \n",
       "2                   0             2  0.500000   3.500000  30.700871   \n",
       "3                   0             3  0.430677   1.292030  30.700871   \n",
       "4                   0             4  0.386853   5.802792  30.700871   \n",
       "...               ...           ...       ...        ...        ...   \n",
       "1385                0            25  0.210310   0.000000  30.207651   \n",
       "1386                0            26  0.208015   0.000000  30.207651   \n",
       "1387                0            27  0.205847   0.000000  30.207651   \n",
       "1388                0            28  0.203795   0.000000  30.207651   \n",
       "1389                0             9  0.289065   0.000000  30.207651   \n",
       "\n",
       "            dcg      lambda      weight  \n",
       "0     30.552986  213.776822  106.888411  \n",
       "1     30.552986   48.010828   26.458003  \n",
       "2     30.552986   31.382749   18.143963  \n",
       "3     30.552986    6.460558    7.448315  \n",
       "4     30.552986   43.639845   21.819923  \n",
       "...         ...         ...         ...  \n",
       "1385  30.120435   -9.846078    4.923039  \n",
       "1386  30.120435   -9.903461    4.951730  \n",
       "1387  30.120435   -9.957655    4.978827  \n",
       "1388  30.120435  -10.008949    5.004475  \n",
       "1389  30.120435  -10.057598    5.028799  \n",
       "\n",
       "[1390 rows x 14 columns]"
      ]
     },
     "execution_count": 96,
=======
       "      <td>-0.517338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>11.668802</td>\n",
       "      <td>10.793185</td>\n",
       "      <td>-0.013697</td>\n",
       "      <td>0.013544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        uid  qid   keywords   docId  grade  \\\n",
       "qid                                                       \n",
       "1   0       0     1_7555    1      rambo    7555      4   \n",
       "    1       1     1_1370    1      rambo    1370      3   \n",
       "    2      39    1_32221    1      rambo   32221      0   \n",
       "    3      29      1_801    1      rambo     801      1   \n",
       "    4      22       1_70    1      rambo      70      0   \n",
       "...       ...        ...  ...        ...     ...    ...   \n",
       "40  25   1366    40_1891   40  star wars    1891      3   \n",
       "    26   1365    40_1892   40  star wars    1892      3   \n",
       "    27   1364    40_1895   40  star wars    1895      2   \n",
       "    28   1363  40_330459   40  star wars  330459      3   \n",
       "    29   1389   40_43052   40  star wars   43052      0   \n",
       "\n",
       "                      features  last_prediction  display_rank  discount  \\\n",
       "qid                                                                       \n",
       "1   0   [11.657399, 10.083591]         7.292951             0  0.500000   \n",
       "    1    [9.456276, 13.265001]         3.798236             1  0.386853   \n",
       "    2               [0.0, 0.0]        -0.517338             2  0.333333   \n",
       "    3               [0.0, 0.0]        -0.517338             3  0.301030   \n",
       "    4               [0.0, 0.0]        -0.517338             4  0.278943   \n",
       "...                        ...              ...           ...       ...   \n",
       "40  25              [0.0, 0.0]        -0.517338            25  0.173765   \n",
       "    26        [0.0, 2.4547963]        -0.517338            26  0.172195   \n",
       "    27    [6.487482, 2.062405]        -0.517338            27  0.170707   \n",
       "    28   [7.2694716, 4.237955]        -0.517338            28  0.169294   \n",
       "    29              [0.0, 0.0]        -0.517338             1  0.386853   \n",
       "\n",
       "            gain  train_dcg        dcg    lambda    weight  \n",
       "qid                                                         \n",
       "1   0   8.000000  13.741487  13.741487  0.100504  0.099688  \n",
       "    1   3.094822  13.741487  13.741487  0.697540  0.740546  \n",
       "    2   0.333333  13.741487  13.741487 -0.005952  0.005887  \n",
       "    3   0.602060  13.741487  13.741487  2.992312  1.507942  \n",
       "    4   0.278943  13.741487  13.741487 -0.022346  0.016692  \n",
       "...          ...        ...        ...       ...       ...  \n",
       "40  25  1.390123  11.668802  10.793185 -0.002116  0.002115  \n",
       "    26  1.377563  11.668802  10.793185 -0.002126  0.002125  \n",
       "    27  0.682829  11.668802  10.793185 -0.002136  0.002135  \n",
       "    28  1.354350  11.668802  10.793185 -0.002145  0.002144  \n",
       "    29  0.386853  11.668802  10.793185 -0.013697  0.013544  \n",
       "\n",
       "[1390 rows x 15 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 414,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 534,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
     "metadata": {},
     "output_type": "execute_result"
=======
   "execution_count": 21,
=======
   "execution_count": 194,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 214,
>>>>>>> bd537d0 (Fix DCG calculation)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND TWO\n",
      "---------\n",
      "DCG 30.70087057817986 -- 1 rambo\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.952561971428338  |  0.02419282234900899 0.49395208939300733\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 2            | 3 0            |  6.831881303119282  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 1            | 5 0            |  9.013099380487688  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 1            | 6 0            |  9.333333333333332  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214067  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.81585581523305  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590201  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442094  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852764  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226608  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478027  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545704  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736366  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.68402905813744  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.76992581444955  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.80880919669955  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142711  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 1            | 27 0            |  11.912297513093481  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 1            | 28 0            |  11.943074293642404  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 1            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 1            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 1            | 31 0            |  12.02640205244159  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593204  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.3407066065980212 0.41563784409136695\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901597  |  0.3407066065980212 0.41563784409136695\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598398  |  0.3407066065980212 0.41563784409136695\n",
      "0 37       |  4 0            | 37 0            |  12.161994607246946  |  0.3407066065980212 0.41563784409136695\n",
      "0 38       |  4 0            | 38 0            |  12.181472629363384  |  0.3407066065980212 0.41563784409136695\n",
      "0 39       |  4 0            | 39 0            |  12.200213831415848  |  0.3407066065980212 0.41563784409136695\n",
      "0 40       |  4 0            | 40 0            |  12.218264648769463  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 3       |  3 2            | 3 1            |  0.8010127819922559  |  0.3165137842490122 0.4215255995031885\n",
      "1 5       |  3 1            | 5 1            |  1.6483353987806133  |  0.3165137842490122 0.4215255995031885\n",
      "1 6       |  3 1            | 6 1            |  1.785578521428743  |  0.3165137842490122 0.4215255995031885\n",
      "1 7       |  3 0            | 7 1            |  2.2082541375000986  |  0.3165137842490122 0.4215255995031885\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.3165137842490122 0.4215255995031885\n",
      "1 9       |  3 0            | 9 1            |  2.393054490774986  |  0.3165137842490122 0.4215255995031885\n",
      "1 10       |  3 0            | 10 1            |  2.4639076554422914  |  0.3165137842490122 0.4215255995031885\n",
      "1 11       |  3 0            | 11 1            |  2.524841194008964  |  0.3165137842490122 0.4215255995031885\n",
      "1 12       |  3 0            | 12 1            |  2.577961529739845  |  0.3165137842490122 0.4215255995031885\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.3165137842490122 0.4215255995031885\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.3165137842490122 0.4215255995031885\n",
      "1 15       |  3 0            | 15 1            |  2.7039544801726194  |  0.3165137842490122 0.4215255995031885\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.3165137842490122 0.4215255995031885\n",
      "1 17       |  3 0            | 17 1            |  2.7686458814337342  |  0.3165137842490122 0.4215255995031885\n",
      "1 18       |  3 0            | 18 1            |  2.796860782881886  |  0.3165137842490122 0.4215255995031885\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215288  |  0.3165137842490122 0.4215255995031885\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477174  |  0.3165137842490122 0.4215255995031885\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.3165137842490122 0.4215255995031885\n",
      "1 22       |  3 0            | 22 1            |  2.889778231101481  |  0.3165137842490122 0.4215255995031885\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.3165137842490122 0.4215255995031885\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.3165137842490122 0.4215255995031885\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.3165137842490122 0.4215255995031885\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.3165137842490122 0.4215255995031885\n",
      "1 27       |  3 1            | 27 1            |  2.975580447777162  |  0.3165137842490122 0.4215255995031885\n",
      "1 28       |  3 1            | 28 1            |  2.989942945366657  |  0.3165137842490122 0.4215255995031885\n",
      "1 29       |  3 1            | 29 1            |  3.003564668925506  |  0.3165137842490122 0.4215255995031885\n",
      "1 30       |  3 1            | 30 1            |  3.0165082750002057  |  0.3165137842490122 0.4215255995031885\n",
      "1 31       |  3 1            | 31 1            |  3.028829232806281  |  0.3165137842490122 0.4215255995031885\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.3165137842490122 0.4215255995031885\n",
      "1 33       |  3 0            | 33 1            |  3.0517951217437016  |  0.3165137842490122 0.4215255995031885\n",
      "1 34       |  3 0            | 34 1            |  3.062523449679304  |  0.3165137842490122 0.4215255995031885\n",
      "1 35       |  3 0            | 35 1            |  3.0727972349542796  |  0.3165137842490122 0.4215255995031885\n",
      "1 36       |  3 0            | 36 1            |  3.0826483880127853  |  0.3165137842490122 0.4215255995031885\n",
      "1 37       |  3 0            | 37 1            |  3.092105758382111  |  0.3165137842490122 0.4215255995031885\n",
      "1 38       |  3 0            | 38 1            |  3.101195502036447  |  0.3165137842490122 0.4215255995031885\n",
      "1 39       |  3 0            | 39 1            |  3.1099413963275993  |  0.3165137842490122 0.4215255995031885\n",
      "1 40       |  3 0            | 40 1            |  3.118365111092622  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "2 3       |  3 2            | 3 2            |  0.2772937677064249  |  0.0 0.5\n",
      "2 5       |  3 1            | 5 2            |  0.8627568773518668  |  0.0 0.5\n",
      "2 6       |  3 1            | 6 2            |  0.9999999999999964  |  0.0 0.5\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624998943  |  0.0 0.5\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.0 0.5\n",
      "2 9       |  3 0            | 9 2            |  1.476546215774782  |  0.0 0.5\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420871  |  0.0 0.5\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087596  |  0.0 0.5\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396408  |  0.0 0.5\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.0 0.5\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724151  |  0.0 0.5\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 0            | 17 2            |  1.85213760643353  |  0.0 0.5\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816818  |  0.0 0.5\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213245  |  0.0 0.5\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769698  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012765  |  0.0 0.5\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n"
     ]
<<<<<<< HEAD
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 1            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "2 28       |  3 1            | 28 2            |  2.073434670366453  |  0.0 0.5\n",
      "2 29       |  3 1            | 29 2            |  2.0870563939253017  |  0.0 0.5\n",
      "2 30       |  3 1            | 30 2            |  2.1000000000000014  |  0.0 0.5\n",
      "2 31       |  3 1            | 31 2            |  2.1123209578060766  |  0.0 0.5\n",
      "2 32       |  3 0            | 32 2            |  2.1240685743702414  |  0.0 0.5\n",
      "2 33       |  3 0            | 33 2            |  2.1352868467434973  |  0.0 0.5\n",
      "2 34       |  3 0            | 34 2            |  2.1460151746791  |  0.0 0.5\n",
      "2 35       |  3 0            | 35 2            |  2.1562889599540753  |  0.0 0.5\n",
      "2 36       |  3 0            | 36 2            |  2.166140113012581  |  0.0 0.5\n",
      "2 37       |  3 0            | 37 2            |  2.1755974833819067  |  0.0 0.5\n",
      "2 38       |  3 0            | 38 2            |  2.1846872270362425  |  0.0 0.5\n",
      "2 39       |  3 0            | 39 2            |  2.193433121327395  |  0.0 0.5\n",
      "2 40       |  3 0            | 40 2            |  2.201856836092418  |  0.0 0.5\n",
      "----\n",
      "3 5       |  2 1            | 5 3            |  0.14893874193073842  |  0.0 0.5\n",
      "3 6       |  2 1            | 6 3            |  0.1946864494801126  |  0.0 0.5\n",
      "3 7       |  2 0            | 7 3            |  0.34563504386299115  |  0.0 0.5\n",
      "3 8       |  2 0            | 8 3            |  0.38893968722823047  |  0.0 0.5\n",
      "3 9       |  2 0            | 9 3            |  0.42483519526651037  |  0.0 0.5\n",
      "3 10       |  2 0            | 10 3            |  0.45520083726678706  |  0.0 0.5\n",
      "3 11       |  2 0            | 11 3            |  0.48131521093822016  |  0.0 0.5\n",
      "3 12       |  2 0            | 12 3            |  0.5040810691085937  |  0.0 0.5\n",
      "3 13       |  2 0            | 13 3            |  0.5241555997907312  |  0.0 0.5\n",
      "3 14       |  2 0            | 14 3            |  0.5420296742201742  |  0.0 0.5\n",
      "3 15       |  2 0            | 15 3            |  0.5580780478655001  |  0.0 0.5\n",
      "3 16       |  2 0            | 16 3            |  0.5725922745157845  |  0.0 0.5\n",
      "3 17       |  2 0            | 17 3            |  0.5858029341202595  |  0.0 0.5\n",
      "3 18       |  2 0            | 18 3            |  0.5978950347409011  |  0.0 0.5\n",
      "3 19       |  2 0            | 19 3            |  0.6090189281293164  |  0.0 0.5\n",
      "3 20       |  2 0            | 20 3            |  0.6192982015674531  |  0.0 0.5\n",
      "3 21       |  2 0            | 21 3            |  0.6288354858476666  |  0.0 0.5\n",
      "3 22       |  2 0            | 22 3            |  0.6377167982635825  |  0.0 0.5\n",
      "3 23       |  2 0            | 23 3            |  0.6460148371100871  |  0.0 0.5\n",
      "3 24       |  2 0            | 24 3            |  0.6537915135600869  |  0.0 0.5\n",
      "3 25       |  2 0            | 25 3            |  0.6610999206487165  |  0.0 0.5\n",
      "3 26       |  2 0            | 26 3            |  0.6679858811906456  |  0.0 0.5\n",
      "3 27       |  2 1            | 27 3            |  0.6744891768388754  |  0.0 0.5\n",
      "3 28       |  2 1            | 28 3            |  0.680644532948655  |  0.0 0.5\n",
      "3 29       |  2 1            | 29 3            |  0.686482414473879  |  0.0 0.5\n",
      "3 30       |  2 1            | 30 3            |  0.6920296742201728  |  0.0 0.5\n",
      "3 31       |  2 1            | 31 3            |  0.6973100847084979  |  0.0 0.5\n",
      "3 32       |  2 0            | 32 3            |  0.7023447775217093  |  0.0 0.5\n",
      "3 33       |  2 0            | 33 3            |  0.70715260853882  |  0.0 0.5\n",
      "3 34       |  2 0            | 34 3            |  0.7117504633683609  |  0.0 0.5\n",
      "3 35       |  2 0            | 35 3            |  0.7161535142004922  |  0.0 0.5\n",
      "3 36       |  2 0            | 36 3            |  0.7203754369398538  |  0.0 0.5\n",
      "3 37       |  2 0            | 37 3            |  0.7244285956695649  |  0.0 0.5\n",
      "3 38       |  2 0            | 38 3            |  0.7283242000928567  |  0.0 0.5\n",
      "3 39       |  2 0            | 39 3            |  0.7320724405033445  |  0.0 0.5\n",
      "3 40       |  2 0            | 40 3            |  0.7356826039740696  |  0.0 0.5\n",
      "----\n",
      "4 1       |  4 3            | 1 4            |  1.952615570695329  |  -0.3165137842490122 0.5784744004968115\n",
      "4 2       |  4 3            | 2 4            |  0.9051775421236705  |  0.0 0.5\n",
      "4 3       |  4 2            | 3 4            |  0.5258850100662222  |  0.0 0.5\n",
      "4 5       |  4 1            | 5 4            |  0.4290386817712708  |  0.0 0.5\n",
      "4 6       |  4 1            | 6 4            |  0.749272634616915  |  0.0 0.5\n",
      "4 7       |  4 0            | 7 4            |  1.0708189567321895  |  0.0 0.5\n",
      "4 8       |  4 0            | 8 4            |  1.2873421735584039  |  0.0 0.5\n",
      "4 9       |  4 0            | 9 4            |  1.4668197137498034  |  0.0 0.5\n",
      "4 10       |  4 0            | 10 4            |  1.6186479237511762  |  0.0 0.5\n",
      "4 11       |  4 0            | 11 4            |  1.7492197921083275  |  0.0 0.5\n",
      "4 12       |  4 0            | 12 4            |  1.8630490829602202  |  0.0 0.5\n",
      "4 13       |  4 0            | 13 4            |  1.96342173637089  |  0.0 0.5\n",
      "4 14       |  4 0            | 14 4            |  2.0527921085181227  |  0.0 0.5\n",
      "4 15       |  4 0            | 15 4            |  2.1330339767447306  |  0.0 0.5\n",
      "4 16       |  4 0            | 16 4            |  2.2056051099961493  |  0.0 0.5\n",
      "4 17       |  4 0            | 17 4            |  2.271658408018549  |  0.0 0.5\n",
      "4 18       |  4 0            | 18 4            |  2.3321189111217357  |  0.0 0.5\n",
      "4 19       |  4 0            | 19 4            |  2.3877383780638297  |  0.0 0.5\n",
      "4 20       |  4 0            | 20 4            |  2.439134745254492  |  0.0 0.5\n",
      "4 21       |  4 0            | 21 4            |  2.4868211666555666  |  0.0 0.5\n",
      "4 22       |  4 0            | 22 4            |  2.53122772873515  |  0.0 0.5\n",
      "4 23       |  4 0            | 23 4            |  2.5727179229676764  |  0.0 0.5\n",
      "4 24       |  4 0            | 24 4            |  2.6116013052176754  |  0.0 0.5\n",
      "4 25       |  4 0            | 25 4            |  2.648143340660834  |  0.0 0.5\n",
      "4 26       |  4 0            | 26 4            |  2.6825731433704796  |  0.0 0.5\n",
      "4 27       |  4 1            | 27 4            |  2.715089621611604  |  0.0 0.5\n",
      "4 28       |  4 1            | 28 4            |  2.74586640216053  |  0.0 0.5\n",
      "4 29       |  4 1            | 29 4            |  2.7750558097866254  |  0.0 0.5\n",
      "4 30       |  4 1            | 30 4            |  2.8027921085181227  |  0.0 0.5\n",
      "4 31       |  4 1            | 31 4            |  2.829194160959716  |  0.0 0.5\n",
      "4 32       |  4 0            | 32 4            |  2.854367625025784  |  0.0 0.5\n",
      "4 33       |  4 0            | 33 4            |  2.8784067801113267  |  0.0 0.5\n",
      "4 34       |  4 0            | 34 4            |  2.9013960542590596  |  0.0 0.5\n",
      "4 35       |  4 0            | 35 4            |  2.9234113084197197  |  0.0 0.5\n",
      "4 36       |  4 0            | 36 4            |  2.9445209221165207  |  0.0 0.5\n",
      "4 37       |  4 0            | 37 4            |  2.9647867157650722  |  0.0 0.5\n",
      "4 38       |  4 0            | 38 4            |  2.98426473788151  |  0.0 0.5\n",
      "4 39       |  4 0            | 39 4            |  3.0030059399339706  |  0.0 0.5\n",
      "4 40       |  4 0            | 40 4            |  3.021056757287589  |  0.0 0.5\n",
      "----\n",
      "5 7       |  1 0            | 7 5            |  0.04074231032229392  |  0.0 0.5\n",
      "5 8       |  1 0            | 8 5            |  0.05517719144404154  |  0.0 0.5\n",
      "5 9       |  1 0            | 9 5            |  0.06714236079013602  |  0.0 0.5\n",
      "5 10       |  1 0            | 10 5            |  0.07726424145689137  |  0.0 0.5\n",
      "5 11       |  1 0            | 11 5            |  0.08596903268070477  |  0.0 0.5\n",
      "5 12       |  1 0            | 12 5            |  0.09355765207082811  |  0.0 0.5\n",
      "5 13       |  1 0            | 13 5            |  0.10024916229820846  |  0.0 0.5\n",
      "5 14       |  1 0            | 14 5            |  0.1062071871080228  |  0.0 0.5\n",
      "5 15       |  1 0            | 15 5            |  0.1115566449897969  |  0.0 0.5\n",
      "5 16       |  1 0            | 16 5            |  0.11639472053989053  |  0.0 0.5\n",
      "5 17       |  1 0            | 17 5            |  0.12079827374138574  |  0.0 0.5\n",
      "5 18       |  1 0            | 18 5            |  0.12482897394826509  |  0.0 0.5\n",
      "5 19       |  1 0            | 19 5            |  0.12853693841107017  |  0.0 0.5\n",
      "5 20       |  1 0            | 20 5            |  0.13196336289044908  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765052024  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 22       |  1 0            | 22 5            |  0.13810289512248985  |  0.0 0.5\n",
      "5 23       |  1 0            | 23 5            |  0.1408689080713259  |  0.0 0.5\n",
      "5 24       |  1 0            | 24 5            |  0.14346113355465917  |  0.0 0.5\n",
      "5 25       |  1 0            | 25 5            |  0.1458972692508702  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 32       |  1 0            | 32 5            |  0.15964555487520116  |  0.0 0.5\n",
      "5 33       |  1 0            | 33 5            |  0.16124816521423568  |  0.0 0.5\n",
      "5 34       |  1 0            | 34 5            |  0.16278078349075287  |  0.0 0.5\n",
      "5 35       |  1 0            | 35 5            |  0.16424846710146213  |  0.0 0.5\n",
      "5 36       |  1 0            | 36 5            |  0.16565577468124815  |  0.0 0.5\n",
      "5 37       |  1 0            | 37 5            |  0.16700682759115182  |  0.0 0.5\n",
      "5 38       |  1 0            | 38 5            |  0.16830536239891458  |  0.0 0.5\n",
      "5 39       |  1 0            | 39 5            |  0.16955477586908074  |  0.0 0.5\n",
      "5 40       |  1 0            | 40 5            |  0.1707581636926534  |  0.0 0.5\n",
      "----\n",
      "6 7       |  1 0            | 7 6            |  0.017868456547603273  |  0.0 0.5\n",
      "6 8       |  1 0            | 8 6            |  0.032303337669350896  |  0.0 0.5\n",
      "6 9       |  1 0            | 9 6            |  0.04426850701544538  |  0.0 0.5\n",
      "6 10       |  1 0            | 10 6            |  0.054390387682200725  |  0.0 0.5\n",
      "6 11       |  1 0            | 11 6            |  0.06309517890601413  |  0.0 0.5\n",
      "6 12       |  1 0            | 12 6            |  0.07068379829613747  |  0.0 0.5\n",
      "6 13       |  1 0            | 13 6            |  0.07737530852351782  |  0.0 0.5\n",
      "6 14       |  1 0            | 14 6            |  0.08333333333333215  |  0.0 0.5\n",
      "6 15       |  1 0            | 15 6            |  0.08868279121510625  |  0.0 0.5\n",
      "6 16       |  1 0            | 16 6            |  0.09352086676519988  |  0.0 0.5\n",
      "6 17       |  1 0            | 17 6            |  0.0979244199666951  |  0.0 0.5\n",
      "6 18       |  1 0            | 18 6            |  0.10195512017357444  |  0.0 0.5\n",
      "6 19       |  1 0            | 19 6            |  0.10566308463637952  |  0.0 0.5\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 23       |  1 0            | 23 6            |  0.11799505429663526  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 32       |  1 0            | 32 6            |  0.1367717011005105  |  0.0 0.5\n",
      "6 33       |  1 0            | 33 6            |  0.13837431143954504  |  0.0 0.5\n",
      "6 34       |  1 0            | 34 6            |  0.13990692971606222  |  0.0 0.5\n",
      "6 35       |  1 0            | 35 6            |  0.14137461332677148  |  0.0 0.5\n",
      "6 36       |  1 0            | 36 6            |  0.1427819209065575  |  0.0 0.5\n",
      "6 37       |  1 0            | 37 6            |  0.14413297381646117  |  0.0 0.5\n",
      "6 38       |  1 0            | 38 6            |  0.14543150862422394  |  0.0 0.5\n",
      "6 39       |  1 0            | 39 6            |  0.1466809220943901  |  0.0 0.5\n",
      "6 40       |  1 0            | 40 6            |  0.14788430991796275  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 34.371557174012835 -- 2 rocky\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.3165137842490122 0.4215255995031885\n",
      "0 2       |  4 3            | 2 0            |  4.0000000000000036  |  0.3165137842490122 0.4215255995031885\n",
      "0 3       |  4 3            | 3 0            |  4.55458753541286  |  0.3165137842490122 0.4215255995031885\n",
      "0 4       |  4 3            | 4 0            |  4.9051775421236705  |  0.3165137842490122 0.4215255995031885\n",
      "0 5       |  4 3            | 5 0            |  5.150342503135828  |  0.3165137842490122 0.4215255995031885\n",
      "0 6       |  4 3            | 6 0            |  5.333333333333336  |  0.3165137842490122 0.4215255995031885\n",
      "0 7       |  4 1            | 7 0            |  9.583491724999803  |  0.3165137842490122 0.4215255995031885\n",
      "0 8       |  4 1            | 8 0            |  9.78558006070427  |  0.3165137842490122 0.4215255995031885\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549575  |  0.3165137842490122 0.4215255995031885\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233057  |  0.3165137842490122 0.4215255995031885\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590208  |  0.3165137842490122 0.4215255995031885\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442101  |  0.3165137842490122 0.4215255995031885\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852774  |  0.3165137842490122 0.4215255995031885\n",
      "0 14       |  4 0            | 14 0            |  11.250000000000004  |  0.3165137842490122 0.4215255995031885\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226615  |  0.3165137842490122 0.4215255995031885\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478034  |  0.3165137842490122 0.4215255995031885\n",
      "0 17       |  4 0            | 17 0            |  11.46886629950043  |  0.3165137842490122 0.4215255995031885\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603617  |  0.3165137842490122 0.4215255995031885\n",
      "0 19       |  4 0            | 19 0            |  11.58494626954571  |  0.3165137842490122 0.4215255995031885\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736373  |  0.3165137842490122 0.4215255995031885\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137451  |  0.3165137842490122 0.4215255995031885\n",
      "0 22       |  4 0            | 22 0            |  11.72843562021703  |  0.3165137842490122 0.4215255995031885\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449557  |  0.3165137842490122 0.4215255995031885\n",
      "0 24       |  4 0            | 24 0            |  11.80880919669956  |  0.3165137842490122 0.4215255995031885\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142718  |  0.3165137842490122 0.4215255995031885\n",
      "0 26       |  4 1            | 26 0            |  11.879781034852364  |  0.3165137842490122 0.4215255995031885\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093488  |  0.3165137842490122 0.4215255995031885\n",
      "0 28       |  4 1            | 28 0            |  11.943074293642415  |  0.3165137842490122 0.4215255995031885\n",
      "0 29       |  4 1            | 29 0            |  11.972263701268506  |  0.3165137842490122 0.4215255995031885\n",
      "0 30       |  4 1            | 30 0            |  12.000000000000004  |  0.3165137842490122 0.4215255995031885\n",
      "0 31       |  4 1            | 31 0            |  12.026402052441597  |  0.3165137842490122 0.4215255995031885\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507665  |  0.3165137842490122 0.4215255995031885\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593211  |  0.3165137842490122 0.4215255995031885\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740944  |  0.3165137842490122 0.4215255995031885\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901604  |  0.3165137842490122 0.4215255995031885\n",
      "0 36       |  4 1            | 36 0            |  12.141728813598405  |  0.3165137842490122 0.4215255995031885\n",
      "0 37       |  4 0            | 37 0            |  12.161994607246957  |  0.3165137842490122 0.4215255995031885\n",
      "0 38       |  4 1            | 38 0            |  12.181472629363391  |  0.3165137842490122 0.4215255995031885\n",
      "0 39       |  4 0            | 39 0            |  12.200213831415855  |  0.3165137842490122 0.4215255995031885\n",
      "0 40       |  4 0            | 40 0            |  12.218264648769473  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "1 7       |  3 1            | 7 1            |  1.8927892607143733  |  0.0 0.5\n",
      "1 8       |  3 1            | 8 1            |  1.979398547444859  |  0.0 0.5\n",
      "1 9       |  3 1            | 9 1            |  2.051189563521419  |  0.0 0.5\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442295  |  0.0 0.5\n",
      "1 11       |  3 0            | 11 1            |  2.5248411940089674  |  0.0 0.5\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398486  |  0.0 0.5\n",
      "1 13       |  3 0            | 13 1            |  2.6248021013315004  |  0.0 0.5\n",
      "1 14       |  3 0            | 14 1            |  2.666508275000208  |  0.0 0.5\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.0 0.5\n",
      "1 16       |  3 0            | 16 1            |  2.737821009023289  |  0.0 0.5\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.0 0.5\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.0 0.5\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.0 0.5\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.0 0.5\n",
      "1 21       |  3 0            | 21 1            |  2.869055168797683  |  0.0 0.5\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.0 0.5\n",
      "1 23       |  3 0            | 23 1            |  2.909140321743333  |  0.0 0.5\n",
      "1 24       |  3 0            | 24 1            |  2.927285900126666  |  0.0 0.5\n",
      "1 25       |  3 0            | 25 1            |  2.9443388500001397  |  0.0 0.5\n",
      "1 26       |  3 1            | 26 1            |  2.960406091264641  |  0.0 0.5\n",
      "1 27       |  3 0            | 27 1            |  2.9755804477771655  |  0.0 0.5\n",
      "1 28       |  3 1            | 28 1            |  2.9899429453666606  |  0.0 0.5\n",
      "1 29       |  3 1            | 29 1            |  3.0035646689255096  |  0.0 0.5\n",
      "1 30       |  3 1            | 30 1            |  3.0165082750002092  |  0.0 0.5\n",
      "1 31       |  3 1            | 31 1            |  3.0288292328062845  |  0.0 0.5\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704493  |  0.0 0.5\n",
      "1 33       |  3 0            | 33 1            |  3.051795121743705  |  0.0 0.5\n",
      "1 34       |  3 0            | 34 1            |  3.0625234496793077  |  0.0 0.5\n",
      "1 35       |  3 0            | 35 1            |  3.072797234954283  |  0.0 0.5\n",
      "1 36       |  3 1            | 36 1            |  3.082648388012789  |  0.0 0.5\n",
      "1 37       |  3 0            | 37 1            |  3.0921057583821145  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 38       |  3 1            | 38 1            |  3.1011955020364503  |  0.0 0.5\n",
      "1 39       |  3 0            | 39 1            |  3.109941396327603  |  0.0 0.5\n",
      "1 40       |  3 0            | 40 1            |  3.1183651110926256  |  0.0 0.5\n",
      "----\n",
      "2 7       |  3 1            | 7 2            |  1.1072107392856196  |  0.0 0.5\n",
      "2 8       |  3 1            | 8 2            |  1.1938200260161125  |  0.0 0.5\n",
      "2 9       |  3 1            | 9 2            |  1.2656110420926723  |  0.0 0.5\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420871  |  0.0 0.5\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087596  |  0.0 0.5\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396408  |  0.0 0.5\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.0 0.5\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724151  |  0.0 0.5\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 0            | 17 2            |  1.85213760643353  |  0.0 0.5\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816818  |  0.0 0.5\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213245  |  0.0 0.5\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769698  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012765  |  0.0 0.5\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 1            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "2 28       |  3 1            | 28 2            |  2.073434670366453  |  0.0 0.5\n",
      "2 29       |  3 1            | 29 2            |  2.0870563939253017  |  0.0 0.5\n",
      "2 30       |  3 1            | 30 2            |  2.1000000000000014  |  0.0 0.5\n",
      "2 31       |  3 1            | 31 2            |  2.1123209578060766  |  0.0 0.5\n",
      "2 32       |  3 0            | 32 2            |  2.1240685743702414  |  0.0 0.5\n",
      "2 33       |  3 0            | 33 2            |  2.1352868467434973  |  0.0 0.5\n",
      "2 34       |  3 0            | 34 2            |  2.1460151746791  |  0.0 0.5\n",
      "2 35       |  3 0            | 35 2            |  2.1562889599540753  |  0.0 0.5\n",
      "2 36       |  3 1            | 36 2            |  2.166140113012581  |  0.0 0.5\n",
      "2 37       |  3 0            | 37 2            |  2.1755974833819067  |  0.0 0.5\n",
      "2 38       |  3 1            | 38 2            |  2.1846872270362425  |  0.0 0.5\n",
      "2 39       |  3 0            | 39 2            |  2.193433121327395  |  0.0 0.5\n",
      "2 40       |  3 0            | 40 2            |  2.201856836092418  |  0.0 0.5\n",
      "----\n",
      "3 7       |  3 1            | 7 3            |  0.6912700877259823  |  0.0 0.5\n",
      "3 8       |  3 1            | 8 3            |  0.777879374456468  |  0.0 0.5\n",
      "3 9       |  3 1            | 9 3            |  0.849670390533035  |  0.0 0.5\n",
      "3 10       |  3 0            | 10 3            |  1.0621352869558436  |  0.0 0.5\n",
      "3 11       |  3 0            | 11 3            |  1.123068825522516  |  0.0 0.5\n",
      "3 12       |  3 0            | 12 3            |  1.1761891612533972  |  0.0 0.5\n",
      "3 13       |  3 0            | 13 3            |  1.223029732845042  |  0.0 0.5\n",
      "3 14       |  3 0            | 14 3            |  1.2647359065137493  |  0.0 0.5\n",
      "3 15       |  3 0            | 15 3            |  1.3021821116861716  |  0.0 0.5\n",
      "3 16       |  3 0            | 16 3            |  1.3360486405368306  |  0.0 0.5\n",
      "3 17       |  3 0            | 17 3            |  1.3668735129472864  |  0.0 0.5\n",
      "3 18       |  3 0            | 18 3            |  1.3950884143954383  |  0.0 0.5\n",
      "3 19       |  3 0            | 19 3            |  1.421044165635081  |  0.0 0.5\n",
      "3 20       |  3 0            | 20 3            |  1.4450291369907262  |  0.0 0.5\n",
      "3 21       |  3 0            | 21 3            |  1.4672828003112244  |  0.0 0.5\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.0 0.5\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568747  |  0.0 0.5\n",
      "3 24       |  3 0            | 24 3            |  1.5255135316402075  |  0.0 0.5\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136813  |  0.0 0.5\n",
      "3 26       |  3 1            | 26 3            |  1.5586337227781826  |  0.0 0.5\n",
      "3 27       |  3 0            | 27 3            |  1.573808079290707  |  0.0 0.5\n",
      "3 28       |  3 1            | 28 3            |  1.5881705768802092  |  0.0 0.5\n",
      "3 29       |  3 1            | 29 3            |  1.601792300439051  |  0.0 0.5\n",
      "3 30       |  3 1            | 30 3            |  1.6147359065137508  |  0.0 0.5\n",
      "3 31       |  3 1            | 31 3            |  1.627056864319826  |  0.0 0.5\n",
      "3 32       |  3 0            | 32 3            |  1.6388044808839908  |  0.0 0.5\n",
      "3 33       |  3 0            | 33 3            |  1.6500227532572467  |  0.0 0.5\n",
      "3 34       |  3 0            | 34 3            |  1.6607510811928563  |  0.0 0.5\n",
      "3 35       |  3 0            | 35 3            |  1.6710248664678318  |  0.0 0.5\n",
      "3 36       |  3 1            | 36 3            |  1.6808760195263375  |  0.0 0.5\n",
      "3 37       |  3 0            | 37 3            |  1.6903333898956632  |  0.0 0.5\n",
      "3 38       |  3 1            | 38 3            |  1.699423133549999  |  0.0 0.5\n",
      "3 39       |  3 0            | 39 3            |  1.7081690278411443  |  0.0 0.5\n",
      "3 40       |  3 0            | 40 3            |  1.7165927426061671  |  0.0 0.5\n",
      "----\n",
      "4 7       |  3 1            | 7 4            |  0.42832758269287297  |  0.0 0.5\n",
      "4 8       |  3 1            | 8 4            |  0.5149368694233658  |  0.0 0.5\n",
      "4 9       |  3 1            | 9 4            |  0.5867278854999256  |  0.0 0.5\n",
      "4 10       |  3 0            | 10 4            |  0.7553690310838803  |  0.0 0.5\n",
      "4 11       |  3 0            | 11 4            |  0.8163025696505528  |  0.0 0.5\n",
      "4 12       |  3 0            | 12 4            |  0.869422905381434  |  0.0 0.5\n",
      "4 13       |  3 0            | 13 4            |  0.9162634769730857  |  0.0 0.5\n",
      "4 14       |  3 0            | 14 4            |  0.9579696506417932  |  0.0 0.5\n",
      "4 15       |  3 0            | 15 4            |  0.9954158558142083  |  0.0 0.5\n",
      "4 16       |  3 0            | 16 4            |  1.0292823846648744  |  0.0 0.5\n",
      "4 17       |  3 0            | 17 4            |  1.0601072570753232  |  0.0 0.5\n",
      "4 18       |  3 0            | 18 4            |  1.088322158523475  |  0.0 0.5\n",
      "4 19       |  3 0            | 19 4            |  1.1142779097631177  |  0.0 0.5\n",
      "4 20       |  3 0            | 20 4            |  1.138262881118763  |  0.0 0.5\n",
      "4 21       |  3 0            | 21 4            |  1.1605165444392682  |  0.0 0.5\n",
      "4 22       |  3 0            | 22 4            |  1.1812396067430697  |  0.0 0.5\n",
      "4 23       |  3 0            | 23 4            |  1.2006016973849185  |  0.0 0.5\n",
      "4 24       |  3 0            | 24 4            |  1.2187472757682514  |  0.0 0.5\n",
      "4 25       |  3 0            | 25 4            |  1.235800225641725  |  0.0 0.5\n",
      "4 26       |  3 1            | 26 4            |  1.2518674669062264  |  0.0 0.5\n",
      "4 27       |  3 0            | 27 4            |  1.2670418234187508  |  0.0 0.5\n",
      "4 28       |  3 1            | 28 4            |  1.281404321008246  |  0.0 0.5\n",
      "4 29       |  3 1            | 29 4            |  1.295026044567095  |  0.0 0.5\n",
      "4 30       |  3 1            | 30 4            |  1.3079696506417946  |  0.0 0.5\n",
      "4 31       |  3 1            | 31 4            |  1.3202906084478698  |  0.0 0.5\n",
      "4 32       |  3 0            | 32 4            |  1.3320382250120346  |  0.0 0.5\n",
      "4 33       |  3 0            | 33 4            |  1.3432564973852905  |  0.0 0.5\n",
      "4 34       |  3 0            | 34 4            |  1.353984825320893  |  0.0 0.5\n",
      "4 35       |  3 0            | 35 4            |  1.3642586105958685  |  0.0 0.5\n",
      "4 36       |  3 1            | 36 4            |  1.3741097636543742  |  0.0 0.5\n",
      "4 37       |  3 0            | 37 4            |  1.3835671340237  |  0.0 0.5\n",
      "4 38       |  3 1            | 38 4            |  1.3926568776780357  |  0.0 0.5\n",
      "4 39       |  3 0            | 39 4            |  1.4014027719691882  |  0.0 0.5\n",
      "4 40       |  3 0            | 40 4            |  1.409826486734211  |  0.0 0.5\n",
      "----\n",
      "5 7       |  3 1            | 7 5            |  0.2444538619337635  |  0.0 0.5\n",
      "5 8       |  3 1            | 8 5            |  0.33106314866424924  |  0.0 0.5\n",
      "5 9       |  3 1            | 9 5            |  0.40285416474081615  |  0.0 0.5\n",
      "5 10       |  3 0            | 10 5            |  0.5408496901982502  |  0.0 0.5\n",
      "5 11       |  3 0            | 11 5            |  0.6017832287649227  |  0.0 0.5\n",
      "5 12       |  3 0            | 12 5            |  0.6549035644958039  |  0.0 0.5\n",
      "5 13       |  3 0            | 13 5            |  0.7017441360874486  |  0.0 0.5\n",
      "5 14       |  3 0            | 14 5            |  0.743450309756156  |  0.0 0.5\n",
      "5 15       |  3 0            | 15 5            |  0.7808965149285783  |  0.0 0.5\n",
      "5 16       |  3 0            | 16 5            |  0.8147630437792373  |  0.0 0.5\n",
      "5 17       |  3 0            | 17 5            |  0.8455879161896931  |  0.0 0.5\n",
      "5 18       |  3 0            | 18 5            |  0.873802817637845  |  0.0 0.5\n",
      "5 19       |  3 0            | 19 5            |  0.8997585688774876  |  0.0 0.5\n",
      "5 20       |  3 0            | 20 5            |  0.9237435402331329  |  0.0 0.5\n",
      "5 21       |  3 0            | 21 5            |  0.945997203553631  |  0.0 0.5\n",
      "5 22       |  3 0            | 22 5            |  0.9667202658574396  |  0.0 0.5\n",
      "5 23       |  3 0            | 23 5            |  0.9860823564992813  |  0.0 0.5\n",
      "5 24       |  3 0            | 24 5            |  1.0042279348826142  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25       |  3 0            | 25 5            |  1.021280884756088  |  0.0 0.5\n",
      "5 26       |  3 1            | 26 5            |  1.0373481260205892  |  0.0 0.5\n",
      "5 27       |  3 0            | 27 5            |  1.0525224825331136  |  0.0 0.5\n",
      "5 28       |  3 1            | 28 5            |  1.066884980122616  |  0.0 0.5\n",
      "5 29       |  3 1            | 29 5            |  1.0805067036814577  |  0.0 0.5\n",
      "5 30       |  3 1            | 30 5            |  1.0934503097561574  |  0.0 0.5\n",
      "5 31       |  3 1            | 31 5            |  1.1057712675622327  |  0.0 0.5\n",
      "5 32       |  3 0            | 32 5            |  1.1175188841263974  |  0.0 0.5\n",
      "5 33       |  3 0            | 33 5            |  1.1287371564996533  |  0.0 0.5\n",
      "5 34       |  3 0            | 34 5            |  1.139465484435263  |  0.0 0.5\n",
      "5 35       |  3 0            | 35 5            |  1.1497392697102384  |  0.0 0.5\n",
      "5 36       |  3 1            | 36 5            |  1.1595904227687441  |  0.0 0.5\n",
      "5 37       |  3 0            | 37 5            |  1.1690477931380698  |  0.0 0.5\n",
      "5 38       |  3 1            | 38 5            |  1.1781375367924056  |  0.0 0.5\n",
      "5 39       |  3 0            | 39 5            |  1.186883431083551  |  0.0 0.5\n",
      "5 40       |  3 0            | 40 5            |  1.1953071458485738  |  0.0 0.5\n",
      "----\n",
      "6 7       |  3 1            | 7 6            |  0.10721073928562674  |  0.0 0.5\n",
      "6 8       |  3 1            | 8 6            |  0.19382002601611248  |  0.0 0.5\n",
      "6 9       |  3 1            | 9 6            |  0.2656110420926723  |  0.0 0.5\n",
      "6 10       |  3 0            | 10 6            |  0.38073271377542994  |  0.0 0.5\n",
      "6 11       |  3 0            | 11 6            |  0.44166625234209533  |  0.0 0.5\n",
      "6 12       |  3 0            | 12 6            |  0.4947865880729836  |  0.0 0.5\n",
      "6 13       |  3 0            | 13 6            |  0.5416271596646283  |  0.0 0.5\n",
      "6 14       |  3 0            | 14 6            |  0.5833333333333357  |  0.0 0.5\n",
      "6 15       |  3 0            | 15 6            |  0.6207795385057508  |  0.0 0.5\n",
      "6 16       |  3 0            | 16 6            |  0.654646067356417  |  0.0 0.5\n",
      "6 17       |  3 0            | 17 6            |  0.6854709397668657  |  0.0 0.5\n",
      "6 18       |  3 0            | 18 6            |  0.7136858412150247  |  0.0 0.5\n",
      "6 19       |  3 0            | 19 6            |  0.7396415924546673  |  0.0 0.5\n",
      "6 20       |  3 0            | 20 6            |  0.7636265638103055  |  0.0 0.5\n",
      "6 21       |  3 0            | 21 6            |  0.7858802271308107  |  0.0 0.5\n",
      "6 22       |  3 0            | 22 6            |  0.8066032894346122  |  0.0 0.5\n",
      "6 23       |  3 0            | 23 6            |  0.825965380076461  |  0.0 0.5\n",
      "6 24       |  3 0            | 24 6            |  0.8441109584597939  |  0.0 0.5\n",
      "6 25       |  3 0            | 25 6            |  0.8611639083332676  |  0.0 0.5\n",
      "6 26       |  3 1            | 26 6            |  0.8772311495977689  |  0.0 0.5\n",
      "6 27       |  3 0            | 27 6            |  0.8924055061102933  |  0.0 0.5\n",
      "6 28       |  3 1            | 28 6            |  0.9067680036997956  |  0.0 0.5\n",
      "6 29       |  3 1            | 29 6            |  0.9203897272586374  |  0.0 0.5\n",
      "6 30       |  3 1            | 30 6            |  0.9333333333333371  |  0.0 0.5\n",
      "6 31       |  3 1            | 31 6            |  0.9456542911394124  |  0.0 0.5\n",
      "6 32       |  3 0            | 32 6            |  0.9574019077035771  |  0.0 0.5\n",
      "6 33       |  3 0            | 33 6            |  0.968620180076833  |  0.0 0.5\n",
      "6 34       |  3 0            | 34 6            |  0.9793485080124427  |  0.0 0.5\n",
      "6 35       |  3 0            | 35 6            |  0.9896222932874181  |  0.0 0.5\n",
      "6 36       |  3 1            | 36 6            |  0.9994734463459238  |  0.0 0.5\n",
      "6 37       |  3 0            | 37 6            |  1.0089308167152424  |  0.0 0.5\n",
      "6 38       |  3 1            | 38 6            |  1.0180205603695853  |  0.0 0.5\n",
      "6 39       |  3 0            | 39 6            |  1.0267664546607307  |  0.0 0.5\n",
      "6 40       |  3 0            | 40 6            |  1.0351901694257535  |  0.0 0.5\n",
      "----\n",
      "7 10       |  1 0            | 10 7            |  0.0365219311345939  |  0.0 0.5\n",
      "7 11       |  1 0            | 11 7            |  0.0452267223584073  |  0.0 0.5\n",
      "7 12       |  1 0            | 12 7            |  0.052815341748534195  |  0.0 0.5\n",
      "7 13       |  1 0            | 13 7            |  0.05950685197591099  |  0.0 0.5\n",
      "7 14       |  1 0            | 14 7            |  0.06546487678572532  |  0.0 0.5\n",
      "7 15       |  1 0            | 15 7            |  0.07081433466749587  |  0.0 0.5\n",
      "7 16       |  1 0            | 16 7            |  0.07565241021759306  |  0.0 0.5\n",
      "7 17       |  1 0            | 17 7            |  0.08005596341908472  |  0.0 0.5\n",
      "7 18       |  1 0            | 18 7            |  0.08408666362596762  |  0.0 0.5\n",
      "7 19       |  1 0            | 19 7            |  0.0877946280887727  |  0.0 0.5\n",
      "7 20       |  1 0            | 20 7            |  0.0912210525681516  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822277  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019238  |  0.0 0.5\n",
      "7 23       |  1 0            | 23 7            |  0.10012659774903199  |  0.0 0.5\n",
      "7 24       |  1 0            | 24 7            |  0.10271882323236525  |  0.0 0.5\n",
      "7 25       |  1 0            | 25 7            |  0.10515495892857274  |  0.0 0.5\n",
      "7 27       |  1 0            | 27 7            |  0.10961804432528766  |  0.0 0.5\n",
      "7 32       |  1 0            | 32 7            |  0.11890324455290369  |  0.0 0.5\n",
      "7 33       |  1 0            | 33 7            |  0.12050585489193821  |  0.0 0.5\n",
      "7 34       |  1 0            | 34 7            |  0.12203847316845184  |  0.0 0.5\n",
      "7 35       |  1 0            | 35 7            |  0.12350615677916466  |  0.0 0.5\n",
      "7 37       |  1 0            | 37 7            |  0.1262645172688579  |  0.0 0.5\n",
      "7 39       |  1 0            | 39 7            |  0.12881246554677972  |  0.0 0.5\n",
      "7 40       |  1 0            | 40 7            |  0.13001585337035948  |  0.0 0.5\n",
      "----\n",
      "8 10       |  1 0            | 10 8            |  0.02208705001284983  |  0.0 0.5\n",
      "8 11       |  1 0            | 11 8            |  0.03079184123666323  |  0.0 0.5\n",
      "8 12       |  1 0            | 12 8            |  0.038380460626790125  |  0.0 0.5\n",
      "8 13       |  1 0            | 13 8            |  0.04507197085416692  |  0.0 0.5\n",
      "8 14       |  1 0            | 14 8            |  0.051029995663981254  |  0.0 0.5\n",
      "8 15       |  1 0            | 15 8            |  0.0563794535457518  |  0.0 0.5\n",
      "8 16       |  1 0            | 16 8            |  0.06121752909584899  |  0.0 0.5\n",
      "8 17       |  1 0            | 17 8            |  0.06562108229734065  |  0.0 0.5\n",
      "8 18       |  1 0            | 18 8            |  0.06965178250422355  |  0.0 0.5\n",
      "8 19       |  1 0            | 19 8            |  0.07335974696702863  |  0.0 0.5\n",
      "8 20       |  1 0            | 20 8            |  0.07678617144640754  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.0799652662064787  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367844831  |  0.0 0.5\n",
      "8 23       |  1 0            | 23 8            |  0.08569171662728792  |  0.0 0.5\n",
      "8 24       |  1 0            | 24 8            |  0.08828394211062118  |  0.0 0.5\n",
      "8 25       |  1 0            | 25 8            |  0.09072007780682867  |  0.0 0.5\n",
      "8 27       |  1 0            | 27 8            |  0.09518316320354359  |  0.0 0.5\n",
      "8 32       |  1 0            | 32 8            |  0.10446836343115962  |  0.0 0.5\n",
      "8 33       |  1 0            | 33 8            |  0.10607097377019414  |  0.0 0.5\n",
      "8 34       |  1 0            | 34 8            |  0.10760359204670777  |  0.0 0.5\n",
      "8 35       |  1 0            | 35 8            |  0.10907127565742059  |  0.0 0.5\n",
      "8 37       |  1 0            | 37 8            |  0.11182963614711383  |  0.0 0.5\n",
      "8 39       |  1 0            | 39 8            |  0.11437758442503565  |  0.0 0.5\n",
      "8 40       |  1 0            | 40 8            |  0.11558097224861541  |  0.0 0.5\n",
      "----\n",
      "9 10       |  1 0            | 10 9            |  0.010121880666758898  |  0.0 0.5\n",
      "9 11       |  1 0            | 11 9            |  0.0188266718905723  |  0.0 0.5\n",
      "9 12       |  1 0            | 12 9            |  0.026415291280699194  |  0.0 0.5\n",
      "9 13       |  1 0            | 13 9            |  0.03310680150807599  |  0.0 0.5\n",
      "9 14       |  1 0            | 14 9            |  0.03906482631789032  |  0.0 0.5\n",
      "9 15       |  1 0            | 15 9            |  0.04441428419966087  |  0.0 0.5\n",
      "9 16       |  1 0            | 16 9            |  0.04925235974975806  |  0.0 0.5\n",
      "9 17       |  1 0            | 17 9            |  0.05365591295124972  |  0.0 0.5\n",
      "9 18       |  1 0            | 18 9            |  0.057686613158132616  |  0.0 0.5\n",
      "9 19       |  1 0            | 19 9            |  0.061394577620937696  |  0.0 0.5\n",
      "9 20       |  1 0            | 20 9            |  0.0648210021003166  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038777  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235738  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728119699  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276453025  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 25       |  1 0            | 25 9            |  0.07875490846073774  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745265  |  0.0 0.5\n",
      "9 32       |  1 0            | 32 9            |  0.09250319408506869  |  0.0 0.5\n",
      "9 33       |  1 0            | 33 9            |  0.09410580442410321  |  0.0 0.5\n",
      "9 34       |  1 0            | 34 9            |  0.09563842270061684  |  0.0 0.5\n",
      "9 35       |  1 0            | 35 9            |  0.09710610631132965  |  0.0 0.5\n",
      "9 37       |  1 0            | 37 9            |  0.0998644668010229  |  0.0 0.5\n",
      "9 39       |  1 0            | 39 9            |  0.10241241507894472  |  0.0 0.5\n",
      "9 40       |  1 0            | 40 9            |  0.10361580290252448  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 4.4165082750002025 -- 3 war games\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "----\n",
      "1 0       |  3 0            | 0 1            |  2.5834917249997975  |  -0.3407066065980212 0.5843621559086332\n",
      "1 2       |  3 0            | 2 1            |  0.9165082750002025  |  0.0 0.5\n",
      "1 3       |  3 0            | 3 1            |  1.401772368486451  |  0.0 0.5\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.0 0.5\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440474  |  0.0 0.5\n",
      "1 6       |  3 0            | 6 1            |  2.0831749416668695  |  0.0 0.5\n",
      "1 7       |  3 0            | 7 1            |  2.2082541375001012  |  0.0 0.5\n",
      "1 8       |  3 0            | 8 1            |  2.309298305352334  |  0.0 0.5\n",
      "1 9       |  3 0            | 9 1            |  2.393054490774987  |  0.0 0.5\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442293  |  0.0 0.5\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398477  |  0.0 0.5\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331494  |  0.0 0.5\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002025  |  0.0 0.5\n",
      "1 15       |  3 0            | 15 1            |  2.7039544801726203  |  0.0 0.5\n",
      "1 16       |  3 0            | 16 1            |  2.737821009023282  |  0.0 0.5\n",
      "1 17       |  3 0            | 17 1            |  2.7686458814337347  |  0.0 0.5\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818883  |  0.0 0.5\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215314  |  0.0 0.5\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771745  |  0.0 0.5\n",
      "1 21       |  3 0            | 21 1            |  2.869055168797676  |  0.0 0.5\n",
      "1 22       |  3 1            | 22 1            |  2.8897782311014817  |  0.0 0.5\n",
      "1 23       |  3 1            | 23 1            |  2.909140321743327  |  0.0 0.5\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266602  |  0.0 0.5\n",
      "1 25       |  3 1            | 25 1            |  2.9443388500001353  |  0.0 0.5\n",
      "1 26       |  3 1            | 26 1            |  2.960406091264636  |  0.0 0.5\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777161  |  0.0 0.5\n",
      "1 28       |  3 0            | 28 1            |  2.989942945366659  |  0.0 0.5\n",
      "1 29       |  3 0            | 29 1            |  3.0035646689255033  |  0.0 0.5\n",
      "1 30       |  3 0            | 30 1            |  3.016508275000202  |  0.0 0.5\n",
      "1 31       |  3 0            | 31 1            |  3.0288292328062787  |  0.0 0.5\n",
      "1 32       |  3 0            | 32 1            |  3.040576849370444  |  0.0 0.5\n",
      "1 33       |  3 0            | 33 1            |  3.051795121743698  |  0.0 0.5\n",
      "1 34       |  3 0            | 34 1            |  3.062523449679307  |  0.0 0.5\n",
      "1 35       |  3 0            | 35 1            |  3.0727972349542814  |  0.0 0.5\n",
      "1 36       |  3 0            | 36 1            |  3.082648388012789  |  0.0 0.5\n",
      "1 37       |  3 0            | 37 1            |  3.0921057583821123  |  0.0 0.5\n",
      "1 38       |  3 0            | 38 1            |  3.1011955020364494  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "11 1       |  4 3            | 1 11            |  2.5248411940089643  |  0.0 0.5\n",
      "DONE 11,11\n",
      "DCG 29.76008101563904 -- 4 crocodile dundee\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.009185460609227425 0.4977036509934318\n",
      "0 3       |  4 1            | 3 0            |  7.970528186972501  |  0.033378282958236416 0.4916562039047883\n",
      "0 4       |  4 1            | 4 0            |  8.58406069871642  |  0.033378282958236416 0.4916562039047883\n",
      "0 5       |  4 1            | 5 0            |  9.013099380487692  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 1            | 6 0            |  9.333333333333332  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549567  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 1            | 10 0            |  10.815855815233057  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590208  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 1            | 13 0            |  11.16062962785277  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 1            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 1            | 15 0            |  11.330241868226615  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.58494626954571  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736373  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137448  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449557  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699556  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142718  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  4 3            | 2 1            |  1.047438028571662  |  0.009185460609227425 0.4977036509934318\n",
      "1 3       |  4 1            | 3 1            |  2.8035447369729027  |  0.033378282958236416 0.4916562039047883\n",
      "1 4       |  4 1            | 4 1            |  3.417077248716822  |  0.033378282958236416 0.4916562039047883\n",
      "1 5       |  4 1            | 5 1            |  3.8461159304881  |  0.34989206720724864 0.4134085947484186\n",
      "1 6       |  4 1            | 6 1            |  4.166349883333741  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  4 0            | 7 1            |  4.731973151785937  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  4 0            | 8 1            |  4.9484963686121475  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  4 1            | 9 1            |  4.786108981549976  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  4 1            | 10 1            |  5.279802118804916  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  4 0            | 11 1            |  5.4103739871620675  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  4 0            | 12 1            |  5.524203278013964  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  4 1            | 13 1            |  5.62457593142463  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  4 1            | 14 1            |  5.713946303571866  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  4 1            | 15 1            |  5.794188171798474  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  4 0            | 16 1            |  5.866759305049889  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  4 0            | 17 1            |  5.932812603072293  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  4 0            | 18 1            |  5.993273106175479  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  4 0            | 19 1            |  6.04889257311757  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  4 0            | 20 1            |  6.100288940308232  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  4 0            | 21 1            |  6.147975361709307  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  4 0            | 22 1            |  6.1923819237888935  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  4 0            | 23 1            |  6.2338721180214165  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  4 0            | 24 1            |  6.2727555002714155  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  4 0            | 25 1            |  6.3092975357145775  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  4 0            | 26 1            |  6.343727338424223  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  4 0            | 27 1            |  6.376243816665351  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "2 3       |  3 1            | 3 2            |  0.41594065155964444  |  0.02419282234900899 0.49395208939300733\n",
      "2 4       |  3 1            | 4 2            |  0.6788831565927538  |  0.02419282234900899 0.49395208939300733\n",
      "2 5       |  3 1            | 5 2            |  0.8627568773518668  |  0.3407066065980212 0.41563784409136695\n",
      "2 6       |  3 1            | 6 2            |  1.0000000000000036  |  0.3407066065980212 0.41563784409136695\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624999014  |  0.3407066065980212 0.41563784409136695\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.3407066065980212 0.41563784409136695\n",
      "2 9       |  3 1            | 9 2            |  1.2656110420926758  |  0.3407066065980212 0.41563784409136695\n",
      "2 10       |  3 1            | 10 2            |  1.5473993804420942  |  0.3407066065980212 0.41563784409136695\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087667  |  0.3407066065980212 0.41563784409136695\n",
      "2 12       |  3 0            | 12 2            |  1.661453254739648  |  0.3407066065980212 0.41563784409136695\n",
      "2 13       |  3 1            | 13 2            |  1.7082938263312926  |  0.3407066065980212 0.41563784409136695\n",
      "2 14       |  3 1            | 14 2            |  1.75  |  0.3407066065980212 0.41563784409136695\n",
      "2 15       |  3 1            | 15 2            |  1.7874462051724223  |  0.3407066065980212 0.41563784409136695\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.3407066065980212 0.41563784409136695\n",
      "2 17       |  3 0            | 17 2            |  1.852137606433537  |  0.3407066065980212 0.41563784409136695\n",
      "2 18       |  3 0            | 18 2            |  1.880352507881689  |  0.3407066065980212 0.41563784409136695\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213316  |  0.3407066065980212 0.41563784409136695\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769769  |  0.3407066065980212 0.41563784409136695\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.3407066065980212 0.41563784409136695\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012836  |  0.3407066065980212 0.41563784409136695\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.3407066065980212 0.41563784409136695\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.3407066065980212 0.41563784409136695\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.3407066065980212 0.41563784409136695\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.3407066065980212 0.41563784409136695\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "3 7       |  1 0            | 7 3            |  0.11521168128766845  |  0.3165137842490122 0.4215255995031885\n",
      "3 8       |  1 0            | 8 3            |  0.12964656240941252  |  0.3165137842490122 0.4215255995031885\n",
      "3 11       |  1 0            | 11 3            |  0.16043840364607576  |  0.3165137842490122 0.4215255995031885\n",
      "3 12       |  1 0            | 12 3            |  0.16802702303620265  |  0.3165137842490122 0.4215255995031885\n",
      "3 16       |  1 0            | 16 3            |  0.1908640915052615  |  0.3165137842490122 0.4215255995031885\n",
      "3 17       |  1 0            | 17 3            |  0.19526764470676028  |  0.3165137842490122 0.4215255995031885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 18       |  1 0            | 18 3            |  0.19929834491363607  |  0.3165137842490122 0.4215255995031885\n",
      "3 19       |  1 0            | 19 3            |  0.20300630937644115  |  0.3165137842490122 0.4215255995031885\n",
      "3 20       |  1 0            | 20 3            |  0.20643273385582006  |  0.3165137842490122 0.4215255995031885\n",
      "3 21       |  1 0            | 21 3            |  0.20961182861589123  |  0.3165137842490122 0.4215255995031885\n",
      "3 22       |  1 0            | 22 3            |  0.21257226608786084  |  0.3165137842490122 0.4215255995031885\n",
      "3 23       |  1 0            | 23 3            |  0.21533827903670044  |  0.3165137842490122 0.4215255995031885\n",
      "3 24       |  1 0            | 24 3            |  0.2179305045200337  |  0.3165137842490122 0.4215255995031885\n",
      "3 25       |  1 0            | 25 3            |  0.2203666402162412  |  0.3165137842490122 0.4215255995031885\n",
      "3 26       |  1 0            | 26 3            |  0.22266196039688424  |  0.3165137842490122 0.4215255995031885\n",
      "3 27       |  1 0            | 27 3            |  0.22482972561296322  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "4 7       |  1 0            | 7 4            |  0.07138793044881453  |  0.3165137842490122 0.4215255995031885\n",
      "4 8       |  1 0            | 8 4            |  0.08582281157056215  |  0.3165137842490122 0.4215255995031885\n",
      "4 11       |  1 0            | 11 4            |  0.11661465280722538  |  0.3165137842490122 0.4215255995031885\n",
      "4 12       |  1 0            | 12 4            |  0.12420327219734872  |  0.3165137842490122 0.4215255995031885\n",
      "4 16       |  1 0            | 16 4            |  0.14704034066641114  |  0.3165137842490122 0.4215255995031885\n",
      "4 17       |  1 0            | 17 4            |  0.15144389386790635  |  0.3165137842490122 0.4215255995031885\n",
      "4 18       |  1 0            | 18 4            |  0.1554745940747857  |  0.3165137842490122 0.4215255995031885\n",
      "4 19       |  1 0            | 19 4            |  0.15918255853759078  |  0.3165137842490122 0.4215255995031885\n",
      "4 20       |  1 0            | 20 4            |  0.1626089830169697  |  0.3165137842490122 0.4215255995031885\n",
      "4 21       |  1 0            | 21 4            |  0.16578807777704085  |  0.3165137842490122 0.4215255995031885\n",
      "4 22       |  1 0            | 22 4            |  0.16874851524901047  |  0.3165137842490122 0.4215255995031885\n",
      "4 23       |  1 0            | 23 4            |  0.17151452819784652  |  0.3165137842490122 0.4215255995031885\n",
      "4 24       |  1 0            | 24 4            |  0.17410675368117978  |  0.3165137842490122 0.4215255995031885\n",
      "4 25       |  1 0            | 25 4            |  0.17654288937739082  |  0.3165137842490122 0.4215255995031885\n",
      "4 26       |  1 0            | 26 4            |  0.17883820955803387  |  0.3165137842490122 0.4215255995031885\n",
      "4 27       |  1 0            | 27 4            |  0.1810059747741093  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "5 7       |  1 0            | 7 5            |  0.04074231032229392  |  0.0 0.5\n",
      "5 8       |  1 0            | 8 5            |  0.05517719144404154  |  0.0 0.5\n",
      "5 11       |  1 0            | 11 5            |  0.08596903268070477  |  0.0 0.5\n",
      "5 12       |  1 0            | 12 5            |  0.09355765207082811  |  0.0 0.5\n",
      "5 16       |  1 0            | 16 5            |  0.11639472053989053  |  0.0 0.5\n",
      "5 17       |  1 0            | 17 5            |  0.12079827374138574  |  0.0 0.5\n",
      "5 18       |  1 0            | 18 5            |  0.12482897394826509  |  0.0 0.5\n",
      "5 19       |  1 0            | 19 5            |  0.12853693841107017  |  0.0 0.5\n",
      "5 20       |  1 0            | 20 5            |  0.13196336289044908  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765052024  |  0.0 0.5\n",
      "5 22       |  1 0            | 22 5            |  0.13810289512248985  |  0.0 0.5\n",
      "5 23       |  1 0            | 23 5            |  0.1408689080713259  |  0.0 0.5\n",
      "5 24       |  1 0            | 24 5            |  0.14346113355465917  |  0.0 0.5\n",
      "5 25       |  1 0            | 25 5            |  0.1458972692508702  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 27       |  1 0            | 27 5            |  0.15036035464758868  |  0.0 0.5\n",
      "----\n",
      "6 7       |  1 0            | 7 6            |  0.017868456547603273  |  0.0 0.5\n",
      "6 8       |  1 0            | 8 6            |  0.032303337669350896  |  0.0 0.5\n",
      "6 11       |  1 0            | 11 6            |  0.06309517890601413  |  0.0 0.5\n",
      "6 12       |  1 0            | 12 6            |  0.07068379829613747  |  0.0 0.5\n",
      "6 16       |  1 0            | 16 6            |  0.09352086676519988  |  0.0 0.5\n",
      "6 17       |  1 0            | 17 6            |  0.0979244199666951  |  0.0 0.5\n",
      "6 18       |  1 0            | 18 6            |  0.10195512017357444  |  0.0 0.5\n",
      "6 19       |  1 0            | 19 6            |  0.10566308463637952  |  0.0 0.5\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 23       |  1 0            | 23 6            |  0.11799505429663526  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 27       |  1 0            | 27 6            |  0.12748650087289803  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "9 7       |  1 0            | 7 9            |  0.026400050467842107  |  0.0 0.5\n",
      "9 8       |  1 0            | 8 9            |  0.011965169346094484  |  0.0 0.5\n",
      "9 11       |  1 0            | 11 9            |  0.018826671890568747  |  0.0 0.5\n",
      "9 12       |  1 0            | 12 9            |  0.026415291280692088  |  0.0 0.5\n",
      "9 16       |  1 0            | 16 9            |  0.049252359749754504  |  0.0 0.5\n",
      "9 17       |  1 0            | 17 9            |  0.05365591295124972  |  0.0 0.5\n",
      "9 18       |  1 0            | 18 9            |  0.05768661315812906  |  0.0 0.5\n",
      "9 19       |  1 0            | 19 9            |  0.06139457762093414  |  0.0 0.5\n",
      "9 20       |  1 0            | 20 9            |  0.06482100210031305  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235383  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728118988  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276452315  |  0.0 0.5\n",
      "9 25       |  1 0            | 25 9            |  0.07875490846073419  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137723  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745265  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 24.208537949220382 -- 5 matrix\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.02419282234900899 0.49395208939300733\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.02419282234900899 0.49395208939300733\n",
      "0 3       |  4 2            | 3 0            |  6.831881303119285  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040283  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231682  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590203  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442096  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736368  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 1            | 23 0            |  11.769925814449552  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852359  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 3       |  3 2            | 3 1            |  0.8010127819922559  |  0.3165137842490122 0.4215255995031885\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.3165137842490122 0.4215255995031885\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.3165137842490122 0.4215255995031885\n",
      "1 6       |  3 0            | 6 1            |  2.083174941666872  |  0.3165137842490122 0.4215255995031885\n",
      "1 7       |  3 0            | 7 1            |  2.208254137500102  |  0.3165137842490122 0.4215255995031885\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.3165137842490122 0.4215255995031885\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749898  |  0.3165137842490122 0.4215255995031885\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442295  |  0.3165137842490122 0.4215255995031885\n",
      "1 11       |  3 0            | 11 1            |  2.5248411940089674  |  0.3165137842490122 0.4215255995031885\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398486  |  0.3165137842490122 0.4215255995031885\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.3165137842490122 0.4215255995031885\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.3165137842490122 0.4215255995031885\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.3165137842490122 0.4215255995031885\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.3165137842490122 0.4215255995031885\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.3165137842490122 0.4215255995031885\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.3165137842490122 0.4215255995031885\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.3165137842490122 0.4215255995031885\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.3165137842490122 0.4215255995031885\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.3165137842490122 0.4215255995031885\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.3165137842490122 0.4215255995031885\n",
      "1 23       |  3 1            | 23 1            |  2.9091403217433296  |  0.3165137842490122 0.4215255995031885\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.3165137842490122 0.4215255995031885\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.3165137842490122 0.4215255995031885\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.3165137842490122 0.4215255995031885\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.3165137842490122 0.4215255995031885\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666606  |  0.3165137842490122 0.4215255995031885\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.3165137842490122 0.4215255995031885\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.3165137842490122 0.4215255995031885\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.3165137842490122 0.4215255995031885\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "2 3       |  3 2            | 3 2            |  0.2772937677064249  |  0.3165137842490122 0.4215255995031885\n",
      "2 4       |  3 0            | 4 2            |  0.7920303493582068  |  0.3165137842490122 0.4215255995031885\n",
      "2 5       |  3 0            | 5 2            |  1.006549690243844  |  0.3165137842490122 0.4215255995031885\n",
      "2 6       |  3 0            | 6 2            |  1.1666666666666679  |  0.3165137842490122 0.4215255995031885\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624998979  |  0.3165137842490122 0.4215255995031885\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.3165137842490122 0.4215255995031885\n",
      "2 9       |  3 0            | 9 2            |  1.4765462157747855  |  0.3165137842490122 0.4215255995031885\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420907  |  0.3165137842490122 0.4215255995031885\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087632  |  0.3165137842490122 0.4215255995031885\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396443  |  0.3165137842490122 0.4215255995031885\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.3165137842490122 0.4215255995031885\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.3165137842490122 0.4215255995031885\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724187  |  0.3165137842490122 0.4215255995031885\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.3165137842490122 0.4215255995031885\n",
      "2 17       |  3 0            | 17 2            |  1.8521376064335335  |  0.3165137842490122 0.4215255995031885\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816854  |  0.3165137842490122 0.4215255995031885\n",
      "2 19       |  3 0            | 19 2            |  1.906308259121328  |  0.3165137842490122 0.4215255995031885\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769733  |  0.3165137842490122 0.4215255995031885\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.3165137842490122 0.4215255995031885\n",
      "2 22       |  3 0            | 22 2            |  1.97326995610128  |  0.3165137842490122 0.4215255995031885\n",
      "2 23       |  3 1            | 23 2            |  1.9926320467431253  |  0.3165137842490122 0.4215255995031885\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.3165137842490122 0.4215255995031885\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.3165137842490122 0.4215255995031885\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.3165137842490122 0.4215255995031885\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.3165137842490122 0.4215255995031885\n",
      "2 28       |  3 0            | 28 2            |  2.0734346703664563  |  0.3165137842490122 0.4215255995031885\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.3165137842490122 0.4215255995031885\n",
      "2 30       |  3 0            | 30 2            |  2.1000000000000014  |  0.3165137842490122 0.4215255995031885\n",
      "2 31       |  3 0            | 31 2            |  2.1123209578060766  |  0.3165137842490122 0.4215255995031885\n",
      "2 32       |  3 0            | 32 2            |  2.1240685743702414  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "3 4       |  2 0            | 4 3            |  0.13147125251655112  |  0.0 0.5\n",
      "3 5       |  2 0            | 5 3            |  0.22340811289611295  |  0.0 0.5\n",
      "3 6       |  2 0            | 6 3            |  0.2920296742201778  |  0.0 0.5\n",
      "3 7       |  2 0            | 7 3            |  0.34563504386299115  |  0.0 0.5\n",
      "3 8       |  2 0            | 8 3            |  0.388939687228234  |  0.0 0.5\n",
      "3 9       |  2 0            | 9 3            |  0.4248351952665139  |  0.0 0.5\n",
      "3 10       |  2 0            | 10 3            |  0.45520083726678706  |  0.0 0.5\n",
      "3 11       |  2 0            | 11 3            |  0.48131521093822016  |  0.0 0.5\n",
      "3 12       |  2 0            | 12 3            |  0.5040810691085973  |  0.0 0.5\n",
      "3 13       |  2 0            | 13 3            |  0.5241555997907312  |  0.0 0.5\n",
      "3 14       |  2 0            | 14 3            |  0.5420296742201778  |  0.0 0.5\n",
      "3 15       |  2 0            | 15 3            |  0.5580780478655001  |  0.0 0.5\n",
      "3 16       |  2 0            | 16 3            |  0.5725922745157845  |  0.0 0.5\n",
      "3 17       |  2 0            | 17 3            |  0.5858029341202631  |  0.0 0.5\n",
      "3 18       |  2 0            | 18 3            |  0.5978950347409011  |  0.0 0.5\n",
      "3 19       |  2 0            | 19 3            |  0.6090189281293199  |  0.0 0.5\n",
      "3 20       |  2 0            | 20 3            |  0.6192982015674531  |  0.0 0.5\n",
      "3 21       |  2 0            | 21 3            |  0.6288354858476666  |  0.0 0.5\n",
      "3 22       |  2 0            | 22 3            |  0.6377167982635825  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 23       |  2 1            | 23 3            |  0.6460148371100871  |  0.0 0.5\n",
      "3 24       |  2 0            | 24 3            |  0.6537915135600869  |  0.0 0.5\n",
      "3 25       |  2 0            | 25 3            |  0.66109992064872  |  0.0 0.5\n",
      "3 26       |  2 0            | 26 3            |  0.6679858811906492  |  0.0 0.5\n",
      "3 27       |  2 0            | 27 3            |  0.6744891768388754  |  0.0 0.5\n",
      "3 28       |  2 0            | 28 3            |  0.6806445329486586  |  0.0 0.5\n",
      "3 29       |  2 0            | 29 3            |  0.686482414473879  |  0.0 0.5\n",
      "3 30       |  2 0            | 30 3            |  0.6920296742201764  |  0.0 0.5\n",
      "3 31       |  2 0            | 31 3            |  0.6973100847084979  |  0.0 0.5\n",
      "3 32       |  2 0            | 32 3            |  0.7023447775217093  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 18.543559338088343 -- 6 contact\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 1            | 1 0            |  5.16698344999959  |  0.3407066065980212 0.41563784409136695\n",
      "0 2       |  4 1            | 2 0            |  6.999999999999995  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 1            | 3 0            |  7.970528186972492  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 1            | 4 0            |  8.584060698716414  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 1            | 5 0            |  9.013099380487684  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 1            | 6 0            |  9.33333333333333  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 1            | 7 0            |  9.583491724999794  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 1            | 8 0            |  9.78558006070426  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549567  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 1            | 10 0            |  10.81585581523305  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 1            | 11 0            |  10.946427683590201  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 1            | 12 0            |  11.060256974442094  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 1            | 13 0            |  11.160629627852767  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.249999999999998  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226608  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478027  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500425  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603611  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545704  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 1            | 20 0            |  11.636342636736366  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137442  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217025  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 1            | 23 0            |  11.76992581444955  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 1            | 24 0            |  11.808809196699551  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 1            | 25 0            |  11.845351232142711  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 1            | 27 0            |  11.912297513093481  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 1            | 28 0            |  11.943074293642406  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268501  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  11.999999999999998  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.02640205244159  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.05157551650766  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593204  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.3407066065980212 0.41563784409136695\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901597  |  0.3407066065980212 0.41563784409136695\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598398  |  0.3407066065980212 0.41563784409136695\n",
      "0 37       |  4 0            | 37 0            |  12.161994607246948  |  0.3407066065980212 0.41563784409136695\n",
      "0 38       |  4 0            | 38 0            |  12.181472629363384  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 14       |  1 0            | 14 1            |  0.38092975357145775  |  0.0 0.5\n",
      "1 15       |  1 0            | 15 1            |  0.3862792114532283  |  0.0 0.5\n",
      "1 16       |  1 0            | 16 1            |  0.3911172870033255  |  0.0 0.5\n",
      "1 17       |  1 0            | 17 1            |  0.39552084020481715  |  0.0 0.5\n",
      "1 18       |  1 0            | 18 1            |  0.39955154041170005  |  0.0 0.5\n",
      "1 19       |  1 0            | 19 1            |  0.4032595048745051  |  0.0 0.5\n",
      "1 21       |  1 0            | 21 1            |  0.4098650241139552  |  0.0 0.5\n",
      "1 22       |  1 0            | 22 1            |  0.4128254615859248  |  0.0 0.5\n",
      "1 26       |  1 0            | 26 1            |  0.4229151558949482  |  0.0 0.5\n",
      "1 29       |  1 0            | 29 1            |  0.429080666989357  |  0.0 0.5\n",
      "1 30       |  1 0            | 30 1            |  0.4309297535714549  |  0.0 0.5\n",
      "1 31       |  1 0            | 31 1            |  0.43268989040089423  |  0.0 0.5\n",
      "1 32       |  1 0            | 32 1            |  0.4343681213386361  |  0.0 0.5\n",
      "1 33       |  1 0            | 33 1            |  0.43597073167767064  |  0.0 0.5\n",
      "1 34       |  1 0            | 34 1            |  0.4375033499541843  |  0.0 0.5\n",
      "1 35       |  1 0            | 35 1            |  0.4389710335648971  |  0.0 0.5\n",
      "1 36       |  1 0            | 36 1            |  0.44037834114468666  |  0.0 0.5\n",
      "1 37       |  1 0            | 37 1            |  0.44172939405459033  |  0.0 0.5\n",
      "1 38       |  1 0            | 38 1            |  0.44302792886234954  |  0.0 0.5\n",
      "----\n",
      "2 14       |  1 0            | 14 2            |  0.25  |  0.0 0.5\n",
      "2 15       |  1 0            | 15 2            |  0.25534945788177055  |  0.0 0.5\n",
      "2 16       |  1 0            | 16 2            |  0.26018753343186773  |  0.0 0.5\n",
      "2 17       |  1 0            | 17 2            |  0.2645910866333594  |  0.0 0.5\n",
      "2 18       |  1 0            | 18 2            |  0.2686217868402423  |  0.0 0.5\n",
      "2 19       |  1 0            | 19 2            |  0.2723297513030474  |  0.0 0.5\n",
      "2 21       |  1 0            | 21 2            |  0.27893527054249745  |  0.0 0.5\n",
      "2 22       |  1 0            | 22 2            |  0.28189570801446706  |  0.0 0.5\n",
      "2 26       |  1 0            | 26 2            |  0.29198540232349046  |  0.0 0.5\n",
      "2 29       |  1 0            | 29 2            |  0.29815091341789923  |  0.0 0.5\n",
      "2 30       |  1 0            | 30 2            |  0.29999999999999716  |  0.0 0.5\n",
      "2 31       |  1 0            | 31 2            |  0.3017601368294365  |  0.0 0.5\n",
      "2 32       |  1 0            | 32 2            |  0.30343836776717836  |  0.0 0.5\n",
      "2 33       |  1 0            | 33 2            |  0.3050409781062129  |  0.0 0.5\n",
      "2 34       |  1 0            | 34 2            |  0.3065735963827265  |  0.0 0.5\n",
      "2 35       |  1 0            | 35 2            |  0.30804127999343933  |  0.0 0.5\n",
      "2 36       |  1 0            | 36 2            |  0.3094485875732289  |  0.0 0.5\n",
      "2 37       |  1 0            | 37 2            |  0.3107996404831326  |  0.0 0.5\n",
      "2 38       |  1 0            | 38 2            |  0.3120981752908918  |  0.0 0.5\n",
      "----\n",
      "3 14       |  1 0            | 14 3            |  0.18067655807339378  |  0.0 0.5\n",
      "3 15       |  1 0            | 15 3            |  0.18602601595516433  |  0.0 0.5\n",
      "3 16       |  1 0            | 16 3            |  0.1908640915052615  |  0.0 0.5\n",
      "3 17       |  1 0            | 17 3            |  0.19526764470675317  |  0.0 0.5\n",
      "3 18       |  1 0            | 18 3            |  0.19929834491363607  |  0.0 0.5\n",
      "3 19       |  1 0            | 19 3            |  0.20300630937644115  |  0.0 0.5\n",
      "3 21       |  1 0            | 21 3            |  0.20961182861589123  |  0.0 0.5\n",
      "3 22       |  1 0            | 22 3            |  0.21257226608786084  |  0.0 0.5\n",
      "3 26       |  1 0            | 26 3            |  0.22266196039688424  |  0.0 0.5\n",
      "3 29       |  1 0            | 29 3            |  0.228827471491293  |  0.0 0.5\n",
      "3 30       |  1 0            | 30 3            |  0.23067655807339094  |  0.0 0.5\n",
      "3 31       |  1 0            | 31 3            |  0.23243669490283025  |  0.0 0.5\n",
      "3 32       |  1 0            | 32 3            |  0.23411492584057214  |  0.0 0.5\n",
      "3 33       |  1 0            | 33 3            |  0.23571753617960667  |  0.0 0.5\n",
      "3 34       |  1 0            | 34 3            |  0.2372501544561203  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 35       |  1 0            | 35 3            |  0.2387178380668331  |  0.0 0.5\n",
      "3 36       |  1 0            | 36 3            |  0.24012514564661558  |  0.0 0.5\n",
      "3 37       |  1 0            | 37 3            |  0.24147619855651925  |  0.0 0.5\n",
      "3 38       |  1 0            | 38 3            |  0.24277473336428557  |  0.0 0.5\n",
      "----\n",
      "4 14       |  1 0            | 14 4            |  0.13685280723453985  |  0.0 0.5\n",
      "4 15       |  1 0            | 15 4            |  0.14220226511631395  |  0.0 0.5\n",
      "4 16       |  1 0            | 16 4            |  0.1470403406664076  |  0.0 0.5\n",
      "4 17       |  1 0            | 17 4            |  0.1514438938679028  |  0.0 0.5\n",
      "4 18       |  1 0            | 18 4            |  0.15547459407478215  |  0.0 0.5\n",
      "4 19       |  1 0            | 19 4            |  0.15918255853758723  |  0.0 0.5\n",
      "4 21       |  1 0            | 21 4            |  0.1657880777770373  |  0.0 0.5\n",
      "4 22       |  1 0            | 22 4            |  0.16874851524900691  |  0.0 0.5\n",
      "4 26       |  1 0            | 26 4            |  0.17883820955803031  |  0.0 0.5\n",
      "4 29       |  1 0            | 29 4            |  0.18500372065243909  |  0.0 0.5\n",
      "4 30       |  1 0            | 30 4            |  0.18685280723454056  |  0.0 0.5\n",
      "4 31       |  1 0            | 31 4            |  0.18861294406397988  |  0.0 0.5\n",
      "4 32       |  1 0            | 32 4            |  0.19029117500171822  |  0.0 0.5\n",
      "4 33       |  1 0            | 33 4            |  0.19189378534075274  |  0.0 0.5\n",
      "4 34       |  1 0            | 34 4            |  0.19342640361726993  |  0.0 0.5\n",
      "4 35       |  1 0            | 35 4            |  0.19489408722797918  |  0.0 0.5\n",
      "4 36       |  1 0            | 36 4            |  0.1963013948077652  |  0.0 0.5\n",
      "4 37       |  1 0            | 37 4            |  0.19765244771766888  |  0.0 0.5\n",
      "4 38       |  1 0            | 38 4            |  0.19895098252543164  |  0.0 0.5\n",
      "----\n",
      "5 14       |  1 0            | 14 5            |  0.1062071871080228  |  0.0 0.5\n",
      "5 15       |  1 0            | 15 5            |  0.1115566449897969  |  0.0 0.5\n",
      "5 16       |  1 0            | 16 5            |  0.11639472053989053  |  0.0 0.5\n",
      "5 17       |  1 0            | 17 5            |  0.12079827374138574  |  0.0 0.5\n",
      "5 18       |  1 0            | 18 5            |  0.12482897394826509  |  0.0 0.5\n",
      "5 19       |  1 0            | 19 5            |  0.12853693841107017  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765052024  |  0.0 0.5\n",
      "5 22       |  1 0            | 22 5            |  0.13810289512248985  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 29       |  1 0            | 29 5            |  0.15435810052592203  |  0.0 0.5\n",
      "5 30       |  1 0            | 30 5            |  0.1562071871080235  |  0.0 0.5\n",
      "5 31       |  1 0            | 31 5            |  0.15796732393746282  |  0.0 0.5\n",
      "5 32       |  1 0            | 32 5            |  0.15964555487520116  |  0.0 0.5\n",
      "5 33       |  1 0            | 33 5            |  0.16124816521423568  |  0.0 0.5\n",
      "5 34       |  1 0            | 34 5            |  0.16278078349075287  |  0.0 0.5\n",
      "5 35       |  1 0            | 35 5            |  0.16424846710146213  |  0.0 0.5\n",
      "5 36       |  1 0            | 36 5            |  0.16565577468124815  |  0.0 0.5\n",
      "5 37       |  1 0            | 37 5            |  0.16700682759115182  |  0.0 0.5\n",
      "5 38       |  1 0            | 38 5            |  0.16830536239891458  |  0.0 0.5\n",
      "----\n",
      "6 14       |  1 0            | 14 6            |  0.08333333333333215  |  0.0 0.5\n",
      "6 15       |  1 0            | 15 6            |  0.08868279121510625  |  0.0 0.5\n",
      "6 16       |  1 0            | 16 6            |  0.09352086676519988  |  0.0 0.5\n",
      "6 17       |  1 0            | 17 6            |  0.0979244199666951  |  0.0 0.5\n",
      "6 18       |  1 0            | 18 6            |  0.10195512017357444  |  0.0 0.5\n",
      "6 19       |  1 0            | 19 6            |  0.10566308463637952  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 29       |  1 0            | 29 6            |  0.13148424675123138  |  0.0 0.5\n",
      "6 30       |  1 0            | 30 6            |  0.13333333333333286  |  0.0 0.5\n",
      "6 31       |  1 0            | 31 6            |  0.13509347016277218  |  0.0 0.5\n",
      "6 32       |  1 0            | 32 6            |  0.1367717011005105  |  0.0 0.5\n",
      "6 33       |  1 0            | 33 6            |  0.13837431143954504  |  0.0 0.5\n",
      "6 34       |  1 0            | 34 6            |  0.13990692971606222  |  0.0 0.5\n",
      "6 35       |  1 0            | 35 6            |  0.14137461332677148  |  0.0 0.5\n",
      "6 36       |  1 0            | 36 6            |  0.1427819209065575  |  0.0 0.5\n",
      "6 37       |  1 0            | 37 6            |  0.14413297381646117  |  0.0 0.5\n",
      "6 38       |  1 0            | 38 6            |  0.14543150862422394  |  0.0 0.5\n",
      "----\n",
      "7 14       |  1 0            | 14 7            |  0.06546487678572888  |  0.0 0.5\n",
      "7 15       |  1 0            | 15 7            |  0.07081433466750298  |  0.0 0.5\n",
      "7 16       |  1 0            | 16 7            |  0.07565241021759661  |  0.0 0.5\n",
      "7 17       |  1 0            | 17 7            |  0.08005596341909182  |  0.0 0.5\n",
      "7 18       |  1 0            | 18 7            |  0.08408666362597117  |  0.0 0.5\n",
      "7 19       |  1 0            | 19 7            |  0.08779462808877625  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822632  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019594  |  0.0 0.5\n",
      "7 26       |  1 0            | 26 7            |  0.10745027910921934  |  0.0 0.5\n",
      "7 29       |  1 0            | 29 7            |  0.11361579020362811  |  0.0 0.5\n",
      "7 30       |  1 0            | 30 7            |  0.11546487678572959  |  0.0 0.5\n",
      "7 31       |  1 0            | 31 7            |  0.1172250136151689  |  0.0 0.5\n",
      "7 32       |  1 0            | 32 7            |  0.11890324455290724  |  0.0 0.5\n",
      "7 33       |  1 0            | 33 7            |  0.12050585489194177  |  0.0 0.5\n",
      "7 34       |  1 0            | 34 7            |  0.12203847316845895  |  0.0 0.5\n",
      "7 35       |  1 0            | 35 7            |  0.12350615677916821  |  0.0 0.5\n",
      "7 36       |  1 0            | 36 7            |  0.12491346435895423  |  0.0 0.5\n",
      "7 37       |  1 0            | 37 7            |  0.1262645172688579  |  0.0 0.5\n",
      "7 38       |  1 0            | 38 7            |  0.12756305207662066  |  0.0 0.5\n",
      "----\n",
      "8 14       |  1 0            | 14 8            |  0.051029995663981254  |  0.0 0.5\n",
      "8 15       |  1 0            | 15 8            |  0.056379453545755354  |  0.0 0.5\n",
      "8 16       |  1 0            | 16 8            |  0.06121752909584899  |  0.0 0.5\n",
      "8 17       |  1 0            | 17 8            |  0.0656210822973442  |  0.0 0.5\n",
      "8 18       |  1 0            | 18 8            |  0.06965178250422355  |  0.0 0.5\n",
      "8 19       |  1 0            | 19 8            |  0.07335974696702863  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.0799652662064787  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367844831  |  0.0 0.5\n",
      "8 26       |  1 0            | 26 8            |  0.09301539798747172  |  0.0 0.5\n",
      "8 29       |  1 0            | 29 8            |  0.09918090908188049  |  0.0 0.5\n",
      "8 30       |  1 0            | 30 8            |  0.10102999566398196  |  0.0 0.5\n",
      "8 31       |  1 0            | 31 8            |  0.10279013249342128  |  0.0 0.5\n",
      "8 32       |  1 0            | 32 8            |  0.10446836343115962  |  0.0 0.5\n",
      "8 33       |  1 0            | 33 8            |  0.10607097377019414  |  0.0 0.5\n",
      "8 34       |  1 0            | 34 8            |  0.10760359204671133  |  0.0 0.5\n",
      "8 35       |  1 0            | 35 8            |  0.10907127565742059  |  0.0 0.5\n",
      "8 36       |  1 0            | 36 8            |  0.1104785832372066  |  0.0 0.5\n",
      "8 37       |  1 0            | 37 8            |  0.11182963614711028  |  0.0 0.5\n",
      "8 38       |  1 0            | 38 8            |  0.11312817095487304  |  0.0 0.5\n",
      "----\n",
      "9 14       |  1 0            | 14 9            |  0.03906482631788677  |  0.0 0.5\n",
      "9 15       |  1 0            | 15 9            |  0.04441428419966087  |  0.0 0.5\n",
      "9 16       |  1 0            | 16 9            |  0.049252359749754504  |  0.0 0.5\n",
      "9 17       |  1 0            | 17 9            |  0.05365591295124972  |  0.0 0.5\n",
      "9 18       |  1 0            | 18 9            |  0.05768661315812906  |  0.0 0.5\n",
      "9 19       |  1 0            | 19 9            |  0.06139457762093414  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235383  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137723  |  0.0 0.5\n",
      "9 29       |  1 0            | 29 9            |  0.087215739735786  |  0.0 0.5\n",
      "9 30       |  1 0            | 30 9            |  0.08906482631788748  |  0.0 0.5\n",
      "9 31       |  1 0            | 31 9            |  0.0908249631473268  |  0.0 0.5\n",
      "9 32       |  1 0            | 32 9            |  0.09250319408506513  |  0.0 0.5\n",
      "9 33       |  1 0            | 33 9            |  0.09410580442409966  |  0.0 0.5\n",
      "9 34       |  1 0            | 34 9            |  0.09563842270061684  |  0.0 0.5\n",
      "9 35       |  1 0            | 35 9            |  0.0971061063113261  |  0.0 0.5\n",
      "9 36       |  1 0            | 36 9            |  0.09851341389111212  |  0.0 0.5\n",
      "9 37       |  1 0            | 37 9            |  0.0998644668010158  |  0.0 0.5\n",
      "9 38       |  1 0            | 38 9            |  0.10116300160877856  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 7 space jam\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.34989206720724864 0.4134085947484186\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 1            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 1            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 1            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 1            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 23.506603096982072 -- 8 battlestar galactica\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.0 0.5\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.0 0.5\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 1            | 8 0            |  9.785580060704264  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549571  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 1            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 1            | 11 0            |  10.946427683590203  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 1            | 12 0            |  11.060256974442096  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736368  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852359  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740939  |  0.34989206720724864 0.4134085947484186\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901599  |  0.34989206720724864 0.4134085947484186\n",
      "0 36       |  4 0            | 36 0            |  12.1417288135984  |  0.34989206720724864 0.4134085947484186\n",
      "0 37       |  4 0            | 37 0            |  12.16199460724695  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 3       |  3 0            | 3 1            |  1.4017723684864514  |  0.34989206720724864 0.4134085947484186\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.34989206720724864 0.4134085947484186\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.34989206720724864 0.4134085947484186\n",
      "1 6       |  3 0            | 6 1            |  2.083174941666872  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  3 0            | 7 1            |  2.208254137500102  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  3 1            | 8 1            |  1.979398547444859  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  3 1            | 9 1            |  2.051189563521419  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  3 1            | 10 1            |  2.463907655442295  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  3 1            | 11 1            |  2.5248411940089674  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  3 1            | 12 1            |  2.5779615297398486  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.34989206720724864 0.4134085947484186\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666606  |  0.34989206720724864 0.4134085947484186\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.34989206720724864 0.4134085947484186\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.34989206720724864 0.4134085947484186\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.34989206720724864 0.4134085947484186\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.34989206720724864 0.4134085947484186\n",
      "1 33       |  3 0            | 33 1            |  3.0517951217437016  |  0.34989206720724864 0.4134085947484186\n",
      "1 34       |  3 0            | 34 1            |  3.0625234496793077  |  0.34989206720724864 0.4134085947484186\n",
      "1 35       |  3 0            | 35 1            |  3.072797234954283  |  0.34989206720724864 0.4134085947484186\n",
      "1 36       |  3 0            | 36 1            |  3.082648388012789  |  0.34989206720724864 0.4134085947484186\n",
      "1 37       |  3 0            | 37 1            |  3.0921057583821145  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "2 3       |  3 0            | 3 2            |  0.4852640934862471  |  0.34989206720724864 0.4134085947484186\n",
      "2 4       |  3 0            | 4 2            |  0.7920303493582068  |  0.34989206720724864 0.4134085947484186\n",
      "2 5       |  3 0            | 5 2            |  1.006549690243844  |  0.34989206720724864 0.4134085947484186\n",
      "2 6       |  3 0            | 6 2            |  1.1666666666666679  |  0.34989206720724864 0.4134085947484186\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624998979  |  0.34989206720724864 0.4134085947484186\n",
      "2 8       |  3 1            | 8 2            |  1.1938200260161125  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 9       |  3 1            | 9 2            |  1.2656110420926723  |  0.34989206720724864 0.4134085947484186\n",
      "2 10       |  3 1            | 10 2            |  1.5473993804420907  |  0.34989206720724864 0.4134085947484186\n",
      "2 11       |  3 1            | 11 2            |  1.6083329190087632  |  0.34989206720724864 0.4134085947484186\n",
      "2 12       |  3 1            | 12 2            |  1.6614532547396443  |  0.34989206720724864 0.4134085947484186\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.34989206720724864 0.4134085947484186\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.34989206720724864 0.4134085947484186\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724187  |  0.34989206720724864 0.4134085947484186\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.34989206720724864 0.4134085947484186\n",
      "2 17       |  3 0            | 17 2            |  1.8521376064335335  |  0.34989206720724864 0.4134085947484186\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816854  |  0.34989206720724864 0.4134085947484186\n",
      "2 19       |  3 0            | 19 2            |  1.906308259121328  |  0.34989206720724864 0.4134085947484186\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769733  |  0.34989206720724864 0.4134085947484186\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.34989206720724864 0.4134085947484186\n",
      "2 22       |  3 0            | 22 2            |  1.97326995610128  |  0.34989206720724864 0.4134085947484186\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.34989206720724864 0.4134085947484186\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.34989206720724864 0.4134085947484186\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.34989206720724864 0.4134085947484186\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.34989206720724864 0.4134085947484186\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.34989206720724864 0.4134085947484186\n",
      "2 28       |  3 0            | 28 2            |  2.0734346703664563  |  0.34989206720724864 0.4134085947484186\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.34989206720724864 0.4134085947484186\n",
      "2 30       |  3 0            | 30 2            |  2.1000000000000014  |  0.34989206720724864 0.4134085947484186\n",
      "2 31       |  3 0            | 31 2            |  2.1123209578060766  |  0.34989206720724864 0.4134085947484186\n",
      "2 32       |  3 0            | 32 2            |  2.1240685743702414  |  0.34989206720724864 0.4134085947484186\n",
      "2 33       |  3 0            | 33 2            |  2.1352868467434973  |  0.34989206720724864 0.4134085947484186\n",
      "2 34       |  3 0            | 34 2            |  2.1460151746791034  |  0.34989206720724864 0.4134085947484186\n",
      "2 35       |  3 0            | 35 2            |  2.156288959954079  |  0.34989206720724864 0.4134085947484186\n",
      "2 36       |  3 0            | 36 2            |  2.1661401130125846  |  0.34989206720724864 0.4134085947484186\n",
      "2 37       |  3 0            | 37 2            |  2.1755974833819103  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "8 3       |  1 0            | 3 8            |  0.12964656240941252  |  0.0 0.5\n",
      "8 4       |  1 0            | 4 8            |  0.0858228115705586  |  0.0 0.5\n",
      "8 5       |  1 0            | 5 8            |  0.05517719144404154  |  0.0 0.5\n",
      "8 6       |  1 0            | 6 8            |  0.032303337669350896  |  0.0 0.5\n",
      "8 7       |  1 0            | 7 8            |  0.014434881121747623  |  0.0 0.5\n",
      "8 13       |  1 0            | 13 8            |  0.04507197085416692  |  0.0 0.5\n",
      "8 14       |  1 0            | 14 8            |  0.051029995663981254  |  0.0 0.5\n",
      "8 15       |  1 0            | 15 8            |  0.056379453545755354  |  0.0 0.5\n",
      "8 16       |  1 0            | 16 8            |  0.06121752909584899  |  0.0 0.5\n",
      "8 17       |  1 0            | 17 8            |  0.0656210822973442  |  0.0 0.5\n",
      "8 18       |  1 0            | 18 8            |  0.06965178250422355  |  0.0 0.5\n",
      "8 19       |  1 0            | 19 8            |  0.07335974696702863  |  0.0 0.5\n",
      "8 20       |  1 0            | 20 8            |  0.07678617144640754  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.0799652662064787  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367844831  |  0.0 0.5\n",
      "8 23       |  1 0            | 23 8            |  0.08569171662728436  |  0.0 0.5\n",
      "8 24       |  1 0            | 24 8            |  0.08828394211061763  |  0.0 0.5\n",
      "8 25       |  1 0            | 25 8            |  0.09072007780682867  |  0.0 0.5\n",
      "8 26       |  1 0            | 26 8            |  0.09301539798747172  |  0.0 0.5\n",
      "8 27       |  1 0            | 27 8            |  0.09518316320354714  |  0.0 0.5\n",
      "8 28       |  1 0            | 28 8            |  0.09723494857347603  |  0.0 0.5\n",
      "8 29       |  1 0            | 29 8            |  0.09918090908188049  |  0.0 0.5\n",
      "8 30       |  1 0            | 30 8            |  0.10102999566398196  |  0.0 0.5\n",
      "8 31       |  1 0            | 31 8            |  0.10279013249342128  |  0.0 0.5\n",
      "8 32       |  1 0            | 32 8            |  0.10446836343115962  |  0.0 0.5\n",
      "8 33       |  1 0            | 33 8            |  0.10607097377019414  |  0.0 0.5\n",
      "8 34       |  1 0            | 34 8            |  0.10760359204671133  |  0.0 0.5\n",
      "8 35       |  1 0            | 35 8            |  0.10907127565742059  |  0.0 0.5\n",
      "8 36       |  1 0            | 36 8            |  0.1104785832372066  |  0.0 0.5\n",
      "8 37       |  1 0            | 37 8            |  0.11182963614711028  |  0.0 0.5\n",
      "----\n",
      "9 3       |  1 0            | 3 9            |  0.141611731755507  |  0.0 0.5\n",
      "9 4       |  1 0            | 4 9            |  0.09778798091665308  |  0.0 0.5\n",
      "9 5       |  1 0            | 5 9            |  0.06714236079013602  |  0.0 0.5\n",
      "9 6       |  1 0            | 6 9            |  0.04426850701544538  |  0.0 0.5\n",
      "9 7       |  1 0            | 7 9            |  0.026400050467842107  |  0.0 0.5\n",
      "9 13       |  1 0            | 13 9            |  0.033106801508072436  |  0.0 0.5\n",
      "9 14       |  1 0            | 14 9            |  0.03906482631788677  |  0.0 0.5\n",
      "9 15       |  1 0            | 15 9            |  0.04441428419966087  |  0.0 0.5\n",
      "9 16       |  1 0            | 16 9            |  0.049252359749754504  |  0.0 0.5\n",
      "9 17       |  1 0            | 17 9            |  0.05365591295124972  |  0.0 0.5\n",
      "9 18       |  1 0            | 18 9            |  0.05768661315812906  |  0.0 0.5\n",
      "9 19       |  1 0            | 19 9            |  0.06139457762093414  |  0.0 0.5\n",
      "9 20       |  1 0            | 20 9            |  0.06482100210031305  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235383  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728118988  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276452315  |  0.0 0.5\n",
      "9 25       |  1 0            | 25 9            |  0.07875490846073419  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137723  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745265  |  0.0 0.5\n",
      "9 28       |  1 0            | 28 9            |  0.08526977922738155  |  0.0 0.5\n",
      "9 29       |  1 0            | 29 9            |  0.087215739735786  |  0.0 0.5\n",
      "9 30       |  1 0            | 30 9            |  0.08906482631788748  |  0.0 0.5\n",
      "9 31       |  1 0            | 31 9            |  0.0908249631473268  |  0.0 0.5\n",
      "9 32       |  1 0            | 32 9            |  0.09250319408506513  |  0.0 0.5\n",
      "9 33       |  1 0            | 33 9            |  0.09410580442409966  |  0.0 0.5\n",
      "9 34       |  1 0            | 34 9            |  0.09563842270061684  |  0.0 0.5\n",
      "9 35       |  1 0            | 35 9            |  0.0971061063113261  |  0.0 0.5\n",
      "9 36       |  1 0            | 36 9            |  0.09851341389111212  |  0.0 0.5\n",
      "9 37       |  1 0            | 37 9            |  0.0998644668010158  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 9 her\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.0 0.5\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.0 0.5\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.0 0.5\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.0 0.5\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.0 0.5\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.0 0.5\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.0 0.5\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.0 0.5\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.0 0.5\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.0 0.5\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.0 0.5\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.0 0.5\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.0 0.5\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.0 0.5\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.0 0.5\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.0 0.5\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.0 0.5\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.0 0.5\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.0 0.5\n",
      "0 20       |  4 1            | 20 0            |  11.63634263673637  |  0.0 0.5\n",
      "0 21       |  4 1            | 21 0            |  11.684029058137444  |  0.0 0.5\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.0 0.5\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.0 0.5\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.0 0.5\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.0 0.5\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.0 0.5\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.0 0.5\n",
      "0 28       |  4 1            | 28 0            |  11.943074293642407  |  0.0 0.5\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.0 0.5\n",
      "0 30       |  4 2            | 30 0            |  12.0  |  0.0 0.5\n",
      "0 31       |  4 2            | 31 0            |  12.026402052441592  |  0.0 0.5\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.0 0.5\n",
      "0 33       |  4 1            | 33 0            |  12.075614671593206  |  0.0 0.5\n",
      "0 34       |  4 1            | 34 0            |  12.098603945740937  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 21.514735906513753 -- 10 jobs\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428139  |  0.0 0.5\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.3165137842490122 0.4215255995031885\n",
      "0 3       |  4 3            | 3 0            |  4.554587535412857  |  0.3165137842490122 0.4215255995031885\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481877  |  0.3165137842490122 0.4215255995031885\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.3165137842490122 0.4215255995031885\n",
      "0 6       |  4 0            | 6 0            |  10.000000000000002  |  0.3165137842490122 0.4215255995031885\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.3165137842490122 0.4215255995031885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8       |  4 0            | 8 0            |  10.484550065040283  |  0.3165137842490122 0.4215255995031885\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231682  |  0.3165137842490122 0.4215255995031885\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.3165137842490122 0.4215255995031885\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.3165137842490122 0.4215255995031885\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3165137842490122 0.4215255995031885\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852769  |  0.3165137842490122 0.4215255995031885\n",
      "0 14       |  4 3            | 14 0            |  11.250000000000002  |  0.3165137842490122 0.4215255995031885\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226612  |  0.3165137842490122 0.4215255995031885\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.3165137842490122 0.4215255995031885\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500428  |  0.3165137842490122 0.4215255995031885\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603615  |  0.3165137842490122 0.4215255995031885\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545707  |  0.3165137842490122 0.4215255995031885\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.3165137842490122 0.4215255995031885\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137446  |  0.3165137842490122 0.4215255995031885\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217029  |  0.3165137842490122 0.4215255995031885\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.3165137842490122 0.4215255995031885\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699555  |  0.3165137842490122 0.4215255995031885\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.3165137842490122 0.4215255995031885\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852359  |  0.3165137842490122 0.4215255995031885\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.3165137842490122 0.4215255995031885\n",
      "0 28       |  4 0            | 28 0            |  11.94307429364241  |  0.3165137842490122 0.4215255995031885\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268504  |  0.3165137842490122 0.4215255995031885\n",
      "0 30       |  4 0            | 30 0            |  12.000000000000002  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "----\n",
      "2 1       |  3 0            | 1 2            |  0.9165082750002043  |  -0.3165137842490122 0.5784744004968115\n",
      "2 4       |  3 0            | 4 2            |  0.7920303493582068  |  0.0 0.5\n",
      "2 5       |  3 0            | 5 2            |  1.006549690243844  |  0.0 0.5\n",
      "2 6       |  3 0            | 6 2            |  1.1666666666666679  |  0.0 0.5\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624998979  |  0.0 0.5\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.0 0.5\n",
      "2 9       |  3 0            | 9 2            |  1.4765462157747855  |  0.0 0.5\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420907  |  0.0 0.5\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087632  |  0.0 0.5\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396443  |  0.0 0.5\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724187  |  0.0 0.5\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 0            | 17 2            |  1.8521376064335335  |  0.0 0.5\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816854  |  0.0 0.5\n",
      "2 19       |  3 0            | 19 2            |  1.906308259121328  |  0.0 0.5\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769733  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.97326995610128  |  0.0 0.5\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "2 28       |  3 0            | 28 2            |  2.0734346703664563  |  0.0 0.5\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.0 0.5\n",
      "2 30       |  3 0            | 30 2            |  2.1000000000000014  |  0.0 0.5\n",
      "----\n",
      "3 1       |  3 0            | 1 3            |  1.4017723684864514  |  -0.3165137842490122 0.5784744004968115\n",
      "3 4       |  3 0            | 4 3            |  0.3067662558719597  |  0.0 0.5\n",
      "3 5       |  3 0            | 5 3            |  0.5212855967575969  |  0.0 0.5\n",
      "3 6       |  3 0            | 6 3            |  0.6814025731804207  |  0.0 0.5\n",
      "3 7       |  3 0            | 7 3            |  0.8064817690136508  |  0.0 0.5\n",
      "3 8       |  3 0            | 8 3            |  0.9075259368658841  |  0.0 0.5\n",
      "3 9       |  3 0            | 9 3            |  0.9912821222885384  |  0.0 0.5\n",
      "3 10       |  3 0            | 10 3            |  1.0621352869558436  |  0.0 0.5\n",
      "3 11       |  3 0            | 11 3            |  1.123068825522516  |  0.0 0.5\n",
      "3 12       |  3 0            | 12 3            |  1.1761891612533972  |  0.0 0.5\n",
      "3 13       |  3 0            | 13 3            |  1.2230297328450455  |  0.0 0.5\n",
      "3 15       |  3 0            | 15 3            |  1.3021821116861716  |  0.0 0.5\n",
      "3 16       |  3 0            | 16 3            |  1.3360486405368341  |  0.0 0.5\n",
      "3 17       |  3 0            | 17 3            |  1.3668735129472864  |  0.0 0.5\n",
      "3 18       |  3 0            | 18 3            |  1.3950884143954383  |  0.0 0.5\n",
      "3 19       |  3 0            | 19 3            |  1.421044165635081  |  0.0 0.5\n",
      "3 20       |  3 0            | 20 3            |  1.4450291369907262  |  0.0 0.5\n",
      "3 21       |  3 0            | 21 3            |  1.467282800311228  |  0.0 0.5\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.0 0.5\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568782  |  0.0 0.5\n",
      "3 24       |  3 0            | 24 3            |  1.525513531640211  |  0.0 0.5\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136848  |  0.0 0.5\n",
      "3 26       |  3 0            | 26 3            |  1.5586337227781861  |  0.0 0.5\n",
      "3 27       |  3 0            | 27 3            |  1.5738080792907105  |  0.0 0.5\n",
      "3 28       |  3 0            | 28 3            |  1.5881705768802092  |  0.0 0.5\n",
      "3 29       |  3 0            | 29 3            |  1.6017923004390546  |  0.0 0.5\n",
      "3 30       |  3 0            | 30 3            |  1.6147359065137543  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 11 social network\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.009185460609227425 0.4977036509934318\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 12 rocky horror\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.02419282234900899 0.49395208939300733\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 13 shawshank redemption\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.033378282958236416 0.4916562039047883\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 19.416508275000204 -- 14 french connection\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.009185460609227425 0.4977036509934318\n",
      "0 2       |  4 0            | 2 0            |  7.500000000000002  |  0.009185460609227425 0.4977036509934318\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899106  |  0.009185460609227425 0.4977036509934318\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481877  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.000000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040285  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231684  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852769  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.250000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226612  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500428  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603615  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545707  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137446  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217029  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699555  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.87978103485236  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28       |  4 0            | 28 0            |  11.94307429364241  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268504  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  3 0            | 2 1            |  0.9165082750002043  |  0.0 0.5\n",
      "1 3       |  3 0            | 3 1            |  1.4017723684864514  |  0.0 0.5\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.3407066065980212 0.41563784409136695\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  3 0            | 6 1            |  2.083174941666872  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  3 0            | 7 1            |  2.208254137500102  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749898  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442295  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  3 0            | 11 1            |  2.5248411940089674  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398486  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.3407066065980212 0.41563784409136695\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666606  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 28.85186118476143 -- 15 star wars new hope\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 2            | 1 0            |  4.428842957142507  |  0.02419282234900899 0.49395208939300733\n",
      "0 2       |  4 2            | 2 0            |  5.999999999999993  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 2            | 3 0            |  6.831881303119278  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 2            | 4 0            |  7.357766313185497  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 2            | 5 0            |  7.72551375470373  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 3            | 6 0            |  5.333333333333325  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 3            | 7 0            |  5.476280985714165  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 3            | 8 0            |  5.591760034688146  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549564  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 1            | 10 0            |  10.815855815233046  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590198  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.06025697444209  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 3            | 13 0            |  11.160629627852764  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 3            | 14 0            |  11.249999999999996  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226604  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478023  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500423  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603606  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.5849462695457  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736362  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.68402905813744  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.72843562021702  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449547  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699546  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142708  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852353  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093478  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.9430742936424  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268496  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  11.999999999999996  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441586  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507654  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.0756146715932  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740933  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 9       |  2 1            | 9 1            |  0.6837298545071384  |  0.3165137842490122 0.4215255995031885\n",
      "1 10       |  2 1            | 10 1            |  1.055960423760986  |  0.3165137842490122 0.4215255995031885\n",
      "1 11       |  2 0            | 11 1            |  1.082074797432412  |  0.3165137842490122 0.4215255995031885\n",
      "1 12       |  2 0            | 12 1            |  1.1048406556027928  |  0.3165137842490122 0.4215255995031885\n",
      "1 15       |  2 0            | 15 1            |  1.158837634359692  |  0.3165137842490122 0.4215255995031885\n",
      "1 16       |  2 0            | 16 1            |  1.1733518610099765  |  0.3165137842490122 0.4215255995031885\n",
      "1 17       |  2 0            | 17 1            |  1.1865625206144585  |  0.3165137842490122 0.4215255995031885\n",
      "1 18       |  2 0            | 18 1            |  1.198654621235093  |  0.3165137842490122 0.4215255995031885\n",
      "1 19       |  2 0            | 19 1            |  1.2097785146235154  |  0.3165137842490122 0.4215255995031885\n",
      "1 20       |  2 0            | 20 1            |  1.220057788061645  |  0.3165137842490122 0.4215255995031885\n",
      "1 21       |  2 0            | 21 1            |  1.2295950723418585  |  0.3165137842490122 0.4215255995031885\n",
      "1 22       |  2 0            | 22 1            |  1.2384763847577744  |  0.3165137842490122 0.4215255995031885\n",
      "1 23       |  2 0            | 23 1            |  1.2467744236042861  |  0.3165137842490122 0.4215255995031885\n",
      "1 24       |  2 0            | 24 1            |  1.254551100054286  |  0.3165137842490122 0.4215255995031885\n",
      "1 25       |  2 0            | 25 1            |  1.2618595071429155  |  0.3165137842490122 0.4215255995031885\n",
      "1 26       |  2 0            | 26 1            |  1.2687454676848446  |  0.3165137842490122 0.4215255995031885\n",
      "1 27       |  2 0            | 27 1            |  1.2752487633330674  |  0.3165137842490122 0.4215255995031885\n",
      "1 28       |  2 0            | 28 1            |  1.281404119442854  |  0.3165137842490122 0.4215255995031885\n",
      "1 29       |  2 0            | 29 1            |  1.287242000968071  |  0.3165137842490122 0.4215255995031885\n",
      "1 30       |  2 0            | 30 1            |  1.2927892607143718  |  0.3165137842490122 0.4215255995031885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 31       |  2 0            | 31 1            |  1.2980696712026898  |  0.3165137842490122 0.4215255995031885\n",
      "1 32       |  2 0            | 32 1            |  1.3031043640159012  |  0.3165137842490122 0.4215255995031885\n",
      "1 33       |  2 0            | 33 1            |  1.307912195033012  |  0.3165137842490122 0.4215255995031885\n",
      "1 34       |  2 0            | 34 1            |  1.31251004986256  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "2 9       |  2 1            | 9 2            |  0.4218703473642229  |  0.0 0.5\n",
      "2 10       |  2 1            | 10 2            |  0.6631711630466057  |  0.0 0.5\n",
      "2 11       |  2 0            | 11 2            |  0.6892855367180388  |  0.0 0.5\n",
      "2 12       |  2 0            | 12 2            |  0.7120513948884195  |  0.0 0.5\n",
      "2 15       |  2 0            | 15 2            |  0.7660483736453187  |  0.0 0.5\n",
      "2 16       |  2 0            | 16 2            |  0.7805626002956032  |  0.0 0.5\n",
      "2 17       |  2 0            | 17 2            |  0.7937732599000853  |  0.0 0.5\n",
      "2 18       |  2 0            | 18 2            |  0.8058653605207198  |  0.0 0.5\n",
      "2 19       |  2 0            | 19 2            |  0.8169892539091421  |  0.0 0.5\n",
      "2 20       |  2 0            | 20 2            |  0.8272685273472717  |  0.0 0.5\n",
      "2 21       |  2 0            | 21 2            |  0.8368058116274852  |  0.0 0.5\n",
      "2 22       |  2 0            | 22 2            |  0.8456871240434012  |  0.0 0.5\n",
      "2 23       |  2 0            | 23 2            |  0.8539851628899058  |  0.0 0.5\n",
      "2 24       |  2 0            | 24 2            |  0.8617618393399056  |  0.0 0.5\n",
      "2 25       |  2 0            | 25 2            |  0.8690702464285422  |  0.0 0.5\n",
      "2 26       |  2 0            | 26 2            |  0.8759562069704714  |  0.0 0.5\n",
      "2 27       |  2 0            | 27 2            |  0.8824595026186941  |  0.0 0.5\n",
      "2 28       |  2 0            | 28 2            |  0.8886148587284808  |  0.0 0.5\n",
      "2 29       |  2 0            | 29 2            |  0.8944527402536977  |  0.0 0.5\n",
      "2 30       |  2 0            | 30 2            |  0.8999999999999986  |  0.0 0.5\n",
      "2 31       |  2 0            | 31 2            |  0.9052804104883165  |  0.0 0.5\n",
      "2 32       |  2 0            | 32 2            |  0.910315103301528  |  0.0 0.5\n",
      "2 33       |  2 0            | 33 2            |  0.9151229343186387  |  0.0 0.5\n",
      "2 34       |  2 0            | 34 2            |  0.9197207891481867  |  0.0 0.5\n",
      "----\n",
      "3 9       |  2 1            | 9 3            |  0.28322346351100336  |  0.0 0.5\n",
      "3 10       |  2 1            | 10 3            |  0.45520083726678706  |  0.0 0.5\n",
      "3 11       |  2 0            | 11 3            |  0.48131521093822016  |  0.0 0.5\n",
      "3 12       |  2 0            | 12 3            |  0.5040810691085937  |  0.0 0.5\n",
      "3 15       |  2 0            | 15 3            |  0.5580780478655001  |  0.0 0.5\n",
      "3 16       |  2 0            | 16 3            |  0.5725922745157845  |  0.0 0.5\n",
      "3 17       |  2 0            | 17 3            |  0.5858029341202595  |  0.0 0.5\n",
      "3 18       |  2 0            | 18 3            |  0.5978950347409011  |  0.0 0.5\n",
      "3 19       |  2 0            | 19 3            |  0.6090189281293164  |  0.0 0.5\n",
      "3 20       |  2 0            | 20 3            |  0.6192982015674531  |  0.0 0.5\n",
      "3 21       |  2 0            | 21 3            |  0.6288354858476666  |  0.0 0.5\n",
      "3 22       |  2 0            | 22 3            |  0.6377167982635825  |  0.0 0.5\n",
      "3 23       |  2 0            | 23 3            |  0.6460148371100871  |  0.0 0.5\n",
      "3 24       |  2 0            | 24 3            |  0.6537915135600869  |  0.0 0.5\n",
      "3 25       |  2 0            | 25 3            |  0.6610999206487165  |  0.0 0.5\n",
      "3 26       |  2 0            | 26 3            |  0.6679858811906456  |  0.0 0.5\n",
      "3 27       |  2 0            | 27 3            |  0.6744891768388754  |  0.0 0.5\n",
      "3 28       |  2 0            | 28 3            |  0.680644532948655  |  0.0 0.5\n",
      "3 29       |  2 0            | 29 3            |  0.686482414473879  |  0.0 0.5\n",
      "3 30       |  2 0            | 30 3            |  0.6920296742201728  |  0.0 0.5\n",
      "3 31       |  2 0            | 31 3            |  0.6973100847084979  |  0.0 0.5\n",
      "3 32       |  2 0            | 32 3            |  0.7023447775217093  |  0.0 0.5\n",
      "3 33       |  2 0            | 33 3            |  0.70715260853882  |  0.0 0.5\n",
      "3 34       |  2 0            | 34 3            |  0.7117504633683609  |  0.0 0.5\n",
      "----\n",
      "4 9       |  2 1            | 9 4            |  0.19557596183330261  |  0.0 0.5\n",
      "4 10       |  2 1            | 10 4            |  0.3237295847502324  |  0.0 0.5\n",
      "4 11       |  2 0            | 11 4            |  0.3498439584216655  |  0.0 0.5\n",
      "4 12       |  2 0            | 12 4            |  0.37260981659203907  |  0.0 0.5\n",
      "4 15       |  2 0            | 15 4            |  0.4266067953489454  |  0.0 0.5\n",
      "4 16       |  2 0            | 16 4            |  0.44112102199922987  |  0.0 0.5\n",
      "4 17       |  2 0            | 17 4            |  0.45433168160370485  |  0.0 0.5\n",
      "4 18       |  2 0            | 18 4            |  0.46642378222434644  |  0.0 0.5\n",
      "4 19       |  2 0            | 19 4            |  0.4775476756127617  |  0.0 0.5\n",
      "4 20       |  2 0            | 20 4            |  0.4878269490508984  |  0.0 0.5\n",
      "4 21       |  2 0            | 21 4            |  0.4973642333311119  |  0.0 0.5\n",
      "4 22       |  2 0            | 22 4            |  0.5062455457470278  |  0.0 0.5\n",
      "4 23       |  2 0            | 23 4            |  0.5145435845935324  |  0.0 0.5\n",
      "4 24       |  2 0            | 24 4            |  0.5223202610435322  |  0.0 0.5\n",
      "4 25       |  2 0            | 25 4            |  0.5296286681321618  |  0.0 0.5\n",
      "4 26       |  2 0            | 26 4            |  0.5365146286740909  |  0.0 0.5\n",
      "4 27       |  2 0            | 27 4            |  0.5430179243223208  |  0.0 0.5\n",
      "4 28       |  2 0            | 28 4            |  0.5491732804321003  |  0.0 0.5\n",
      "4 29       |  2 0            | 29 4            |  0.5550111619573244  |  0.0 0.5\n",
      "4 30       |  2 0            | 30 4            |  0.5605584217036181  |  0.0 0.5\n",
      "4 31       |  2 0            | 31 4            |  0.5658388321919432  |  0.0 0.5\n",
      "4 32       |  2 0            | 32 4            |  0.5708735250051546  |  0.0 0.5\n",
      "4 33       |  2 0            | 33 4            |  0.5756813560222653  |  0.0 0.5\n",
      "4 34       |  2 0            | 34 4            |  0.5802792108518062  |  0.0 0.5\n",
      "----\n",
      "5 9       |  2 1            | 9 5            |  0.13428472158026494  |  0.0 0.5\n",
      "5 10       |  2 1            | 10 5            |  0.2317927243706741  |  0.0 0.5\n",
      "5 11       |  2 0            | 11 5            |  0.2579070980421072  |  0.0 0.5\n",
      "5 12       |  2 0            | 12 5            |  0.28067295621248434  |  0.0 0.5\n",
      "5 15       |  2 0            | 15 5            |  0.33466993496938713  |  0.0 0.5\n",
      "5 16       |  2 0            | 16 5            |  0.3491841616196716  |  0.0 0.5\n",
      "5 17       |  2 0            | 17 5            |  0.3623948212241501  |  0.0 0.5\n",
      "5 18       |  2 0            | 18 5            |  0.37448692184478816  |  0.0 0.5\n",
      "5 19       |  2 0            | 19 5            |  0.38561081523320695  |  0.0 0.5\n",
      "5 20       |  2 0            | 20 5            |  0.3958900886713401  |  0.0 0.5\n",
      "5 21       |  2 0            | 21 5            |  0.4054273729515536  |  0.0 0.5\n",
      "5 22       |  2 0            | 22 5            |  0.41430868536746956  |  0.0 0.5\n",
      "5 23       |  2 0            | 23 5            |  0.42260672421397416  |  0.0 0.5\n",
      "5 24       |  2 0            | 24 5            |  0.43038340066397396  |  0.0 0.5\n",
      "5 25       |  2 0            | 25 5            |  0.4376918077526071  |  0.0 0.5\n",
      "5 26       |  2 0            | 26 5            |  0.4445777682945362  |  0.0 0.5\n",
      "5 27       |  2 0            | 27 5            |  0.4510810639427625  |  0.0 0.5\n",
      "5 28       |  2 0            | 28 5            |  0.4572364200525456  |  0.0 0.5\n",
      "5 29       |  2 0            | 29 5            |  0.4630743015777661  |  0.0 0.5\n",
      "5 30       |  2 0            | 30 5            |  0.4686215613240634  |  0.0 0.5\n",
      "5 31       |  2 0            | 31 5            |  0.4739019718123849  |  0.0 0.5\n",
      "5 32       |  2 0            | 32 5            |  0.47893666462559636  |  0.0 0.5\n",
      "5 33       |  2 0            | 33 5            |  0.48374449564270705  |  0.0 0.5\n",
      "5 34       |  2 0            | 34 5            |  0.4883423504722515  |  0.0 0.5\n",
      "----\n",
      "6 1       |  3 2            | 1 6            |  1.1903856809524989  |  -0.3165137842490122 0.5784744004968115\n",
      "6 2       |  3 2            | 2 6            |  0.6666666666666679  |  0.0 0.5\n",
      "6 3       |  3 2            | 3 6            |  0.3893728989602465  |  0.0 0.5\n",
      "6 4       |  3 2            | 4 6            |  0.21407789560484147  |  0.0 0.5\n",
      "6 5       |  3 2            | 5 6            |  0.09149541509875903  |  0.0 0.5\n",
      "6 9       |  3 1            | 9 6            |  0.2656110420926723  |  0.0 0.5\n",
      "6 10       |  3 1            | 10 6            |  0.38073271377542284  |  0.0 0.5\n",
      "6 11       |  3 0            | 11 6            |  0.44166625234209533  |  0.0 0.5\n",
      "6 12       |  3 0            | 12 6            |  0.4947865880729765  |  0.0 0.5\n",
      "6 15       |  3 0            | 15 6            |  0.6207795385057508  |  0.0 0.5\n",
      "6 16       |  3 0            | 16 6            |  0.6546460673564134  |  0.0 0.5\n",
      "6 17       |  3 0            | 17 6            |  0.6854709397668657  |  0.0 0.5\n",
      "6 18       |  3 0            | 18 6            |  0.7136858412150175  |  0.0 0.5\n",
      "6 19       |  3 0            | 19 6            |  0.7396415924546602  |  0.0 0.5\n",
      "6 20       |  3 0            | 20 6            |  0.7636265638103055  |  0.0 0.5\n",
      "6 21       |  3 0            | 21 6            |  0.7858802271308072  |  0.0 0.5\n",
      "6 22       |  3 0            | 22 6            |  0.8066032894346122  |  0.0 0.5\n",
      "6 23       |  3 0            | 23 6            |  0.8259653800764575  |  0.0 0.5\n",
      "6 24       |  3 0            | 24 6            |  0.8441109584597903  |  0.0 0.5\n",
      "6 25       |  3 0            | 25 6            |  0.8611639083332641  |  0.0 0.5\n",
      "6 26       |  3 0            | 26 6            |  0.8772311495977654  |  0.0 0.5\n",
      "6 27       |  3 0            | 27 6            |  0.8924055061102898  |  0.0 0.5\n",
      "6 28       |  3 0            | 28 6            |  0.9067680036997885  |  0.0 0.5\n",
      "6 29       |  3 0            | 29 6            |  0.9203897272586339  |  0.0 0.5\n",
      "6 30       |  3 0            | 30 6            |  0.9333333333333336  |  0.0 0.5\n",
      "6 31       |  3 0            | 31 6            |  0.9456542911394088  |  0.0 0.5\n",
      "6 32       |  3 0            | 32 6            |  0.9574019077035736  |  0.0 0.5\n",
      "6 33       |  3 0            | 33 6            |  0.9686201800768295  |  0.0 0.5\n",
      "6 34       |  3 0            | 34 6            |  0.9793485080124356  |  0.0 0.5\n",
      "----\n",
      "7 1       |  3 2            | 1 7            |  1.2618595071429155  |  -0.3165137842490122 0.5784744004968115\n",
      "7 2       |  3 2            | 2 7            |  0.738140492857088  |  0.0 0.5\n",
      "7 3       |  3 2            | 3 7            |  0.4608467251506596  |  0.0 0.5\n",
      "7 4       |  3 2            | 4 7            |  0.285551721795251  |  0.0 0.5\n",
      "7 5       |  3 2            | 5 7            |  0.16296924128917567  |  0.0 0.5\n",
      "7 9       |  3 1            | 9 7            |  0.15840030280704553  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10       |  3 1            | 10 7            |  0.2556535179421928  |  0.0 0.5\n",
      "7 11       |  3 0            | 11 7            |  0.3165870565088653  |  0.0 0.5\n",
      "7 12       |  3 0            | 12 7            |  0.36970739223974647  |  0.0 0.5\n",
      "7 15       |  3 0            | 15 7            |  0.49570034267252083  |  0.0 0.5\n",
      "7 16       |  3 0            | 16 7            |  0.5295668715231834  |  0.0 0.5\n",
      "7 17       |  3 0            | 17 7            |  0.5603917439336357  |  0.0 0.5\n",
      "7 18       |  3 0            | 18 7            |  0.5886066453817875  |  0.0 0.5\n",
      "7 19       |  3 0            | 19 7            |  0.6145623966214302  |  0.0 0.5\n",
      "7 20       |  3 0            | 20 7            |  0.6385473679770755  |  0.0 0.5\n",
      "7 21       |  3 0            | 21 7            |  0.6608010312975772  |  0.0 0.5\n",
      "7 22       |  3 0            | 22 7            |  0.6815240936013822  |  0.0 0.5\n",
      "7 23       |  3 0            | 23 7            |  0.7008861842432275  |  0.0 0.5\n",
      "7 24       |  3 0            | 24 7            |  0.7190317626265603  |  0.0 0.5\n",
      "7 25       |  3 0            | 25 7            |  0.736084712500034  |  0.0 0.5\n",
      "7 26       |  3 0            | 26 7            |  0.7521519537645354  |  0.0 0.5\n",
      "7 27       |  3 0            | 27 7            |  0.7673263102770598  |  0.0 0.5\n",
      "7 28       |  3 0            | 28 7            |  0.7816888078665585  |  0.0 0.5\n",
      "7 29       |  3 0            | 29 7            |  0.7953105314254039  |  0.0 0.5\n",
      "7 30       |  3 0            | 30 7            |  0.8082541375001036  |  0.0 0.5\n",
      "7 31       |  3 0            | 31 7            |  0.8205750953061788  |  0.0 0.5\n",
      "7 32       |  3 0            | 32 7            |  0.8323227118703436  |  0.0 0.5\n",
      "7 33       |  3 0            | 33 7            |  0.8435409842435995  |  0.0 0.5\n",
      "7 34       |  3 0            | 34 7            |  0.8542693121792055  |  0.0 0.5\n",
      "----\n",
      "8 1       |  3 2            | 1 8            |  1.319599031629906  |  -0.3165137842490122 0.5784744004968115\n",
      "8 2       |  3 2            | 2 8            |  0.795880017344075  |  0.0 0.5\n",
      "8 3       |  3 2            | 3 8            |  0.5185862496376537  |  0.0 0.5\n",
      "8 4       |  3 2            | 4 8            |  0.3432912462822486  |  0.0 0.5\n",
      "8 5       |  3 2            | 5 8            |  0.22070876577616616  |  0.0 0.5\n",
      "8 9       |  3 1            | 9 8            |  0.0717910160765598  |  0.0 0.5\n",
      "8 10       |  3 1            | 10 8            |  0.15460935008995946  |  0.0 0.5\n",
      "8 11       |  3 0            | 11 8            |  0.21554288865663196  |  0.0 0.5\n",
      "8 12       |  3 0            | 12 8            |  0.2686632243875131  |  0.0 0.5\n",
      "8 15       |  3 0            | 15 8            |  0.3946561748202875  |  0.0 0.5\n",
      "8 16       |  3 0            | 16 8            |  0.42852270367095  |  0.0 0.5\n",
      "8 17       |  3 0            | 17 8            |  0.4593475760814023  |  0.0 0.5\n",
      "8 18       |  3 0            | 18 8            |  0.4875624775295542  |  0.0 0.5\n",
      "8 19       |  3 0            | 19 8            |  0.5135182287691968  |  0.0 0.5\n",
      "8 20       |  3 0            | 20 8            |  0.5375032001248421  |  0.0 0.5\n",
      "8 21       |  3 0            | 21 8            |  0.5597568634453438  |  0.0 0.5\n",
      "8 22       |  3 0            | 22 8            |  0.5804799257491489  |  0.0 0.5\n",
      "8 23       |  3 0            | 23 8            |  0.5998420163909941  |  0.0 0.5\n",
      "8 24       |  3 0            | 24 8            |  0.617987594774327  |  0.0 0.5\n",
      "8 25       |  3 0            | 25 8            |  0.6350405446478007  |  0.0 0.5\n",
      "8 26       |  3 0            | 26 8            |  0.651107785912302  |  0.0 0.5\n",
      "8 27       |  3 0            | 27 8            |  0.6662821424248264  |  0.0 0.5\n",
      "8 28       |  3 0            | 28 8            |  0.6806446400143251  |  0.0 0.5\n",
      "8 29       |  3 0            | 29 8            |  0.6942663635731705  |  0.0 0.5\n",
      "8 30       |  3 0            | 30 8            |  0.7072099696478702  |  0.0 0.5\n",
      "8 31       |  3 0            | 31 8            |  0.7195309274539454  |  0.0 0.5\n",
      "8 32       |  3 0            | 32 8            |  0.7312785440181102  |  0.0 0.5\n",
      "8 33       |  3 0            | 33 8            |  0.7424968163913661  |  0.0 0.5\n",
      "8 34       |  3 0            | 34 8            |  0.7532251443269722  |  0.0 0.5\n",
      "----\n",
      "9 11       |  1 0            | 11 9            |  0.018826671890568747  |  0.0 0.5\n",
      "9 12       |  1 0            | 12 9            |  0.026415291280692088  |  0.0 0.5\n",
      "9 15       |  1 0            | 15 9            |  0.04441428419966087  |  0.0 0.5\n",
      "9 16       |  1 0            | 16 9            |  0.049252359749754504  |  0.0 0.5\n",
      "9 17       |  1 0            | 17 9            |  0.05365591295124972  |  0.0 0.5\n",
      "9 18       |  1 0            | 18 9            |  0.05768661315812906  |  0.0 0.5\n",
      "9 19       |  1 0            | 19 9            |  0.06139457762093414  |  0.0 0.5\n",
      "9 20       |  1 0            | 20 9            |  0.06482100210031305  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235383  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728118988  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276452315  |  0.0 0.5\n",
      "9 25       |  1 0            | 25 9            |  0.07875490846073419  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137723  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745265  |  0.0 0.5\n",
      "9 28       |  1 0            | 28 9            |  0.08526977922738155  |  0.0 0.5\n",
      "9 29       |  1 0            | 29 9            |  0.087215739735786  |  0.0 0.5\n",
      "9 30       |  1 0            | 30 9            |  0.08906482631788748  |  0.0 0.5\n",
      "9 31       |  1 0            | 31 9            |  0.0908249631473268  |  0.0 0.5\n",
      "9 32       |  1 0            | 32 9            |  0.09250319408506513  |  0.0 0.5\n",
      "9 33       |  1 0            | 33 9            |  0.09410580442409966  |  0.0 0.5\n",
      "9 34       |  1 0            | 34 9            |  0.09563842270061684  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 28.686902822426532 -- 16 lego batman\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.952561971428338  |  0.3407066065980212 0.41563784409136695\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 3            | 3 0            |  4.554587535412857  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 2            | 4 0            |  7.3577663131855005  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 1            | 5 0            |  9.013099380487692  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 1            | 6 0            |  9.333333333333332  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 1            | 7 0            |  9.5834917249998  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 1            | 8 0            |  9.785580060704266  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549571  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 1            | 10 0            |  10.815855815233054  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 1            | 11 0            |  10.946427683590205  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 1            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 1            | 13 0            |  11.16062962785277  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 1            | 14 0            |  11.250000000000004  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 1            | 15 0            |  11.330241868226612  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 1            | 16 0            |  11.40281300147803  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 1            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 1            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 1            | 19 0            |  11.584946269545707  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.87978103485236  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 1            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 1            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 4       |  3 2            | 4 1            |  0.9763077853476609  |  0.0 0.5\n",
      "1 5       |  3 1            | 5 1            |  1.6483353987806133  |  0.0 0.5\n",
      "1 6       |  3 1            | 6 1            |  1.785578521428743  |  0.0 0.5\n",
      "1 7       |  3 1            | 7 1            |  1.8927892607143697  |  0.0 0.5\n",
      "1 8       |  3 1            | 8 1            |  1.979398547444859  |  0.0 0.5\n",
      "1 9       |  3 1            | 9 1            |  2.0511895635214152  |  0.0 0.5\n",
      "1 10       |  3 1            | 10 1            |  2.4639076554422914  |  0.0 0.5\n",
      "1 11       |  3 1            | 11 1            |  2.524841194008964  |  0.0 0.5\n",
      "1 12       |  3 1            | 12 1            |  2.577961529739845  |  0.0 0.5\n",
      "1 13       |  3 1            | 13 1            |  2.624802101331497  |  0.0 0.5\n",
      "1 14       |  3 1            | 14 1            |  2.6665082750002043  |  0.0 0.5\n",
      "1 15       |  3 1            | 15 1            |  2.7039544801726194  |  0.0 0.5\n",
      "1 16       |  3 1            | 16 1            |  2.7378210090232855  |  0.0 0.5\n",
      "1 17       |  3 1            | 17 1            |  2.7686458814337342  |  0.0 0.5\n",
      "1 18       |  3 1            | 18 1            |  2.796860782881886  |  0.0 0.5\n",
      "1 19       |  3 1            | 19 1            |  2.8228165341215288  |  0.0 0.5\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477174  |  0.0 0.5\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.0 0.5\n",
      "1 22       |  3 0            | 22 1            |  2.889778231101481  |  0.0 0.5\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.0 0.5\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.0 0.5\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.0 0.5\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.0 0.5\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.0 0.5\n",
      "1 28       |  3 0            | 28 1            |  2.989942945366657  |  0.0 0.5\n",
      "1 29       |  3 1            | 29 1            |  3.003564668925506  |  0.0 0.5\n",
      "1 30       |  3 1            | 30 1            |  3.0165082750002057  |  0.0 0.5\n",
      "----\n",
      "2 4       |  3 2            | 4 2            |  0.45258877106182993  |  0.0 0.5\n",
      "2 5       |  3 1            | 5 2            |  0.8627568773518668  |  0.0 0.5\n",
      "2 6       |  3 1            | 6 2            |  0.9999999999999964  |  0.0 0.5\n",
      "2 7       |  3 1            | 7 2            |  1.1072107392856232  |  0.0 0.5\n",
      "2 8       |  3 1            | 8 2            |  1.1938200260161125  |  0.0 0.5\n",
      "2 9       |  3 1            | 9 2            |  1.2656110420926687  |  0.0 0.5\n",
      "2 10       |  3 1            | 10 2            |  1.5473993804420871  |  0.0 0.5\n",
      "2 11       |  3 1            | 11 2            |  1.6083329190087596  |  0.0 0.5\n",
      "2 12       |  3 1            | 12 2            |  1.6614532547396408  |  0.0 0.5\n",
      "2 13       |  3 1            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 14       |  3 1            | 14 2            |  1.75  |  0.0 0.5\n",
      "2 15       |  3 1            | 15 2            |  1.7874462051724151  |  0.0 0.5\n",
      "2 16       |  3 1            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 1            | 17 2            |  1.85213760643353  |  0.0 0.5\n",
      "2 18       |  3 1            | 18 2            |  1.8803525078816818  |  0.0 0.5\n",
      "2 19       |  3 1            | 19 2            |  1.9063082591213245  |  0.0 0.5\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769698  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012765  |  0.0 0.5\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "2 28       |  3 0            | 28 2            |  2.073434670366453  |  0.0 0.5\n",
      "2 29       |  3 1            | 29 2            |  2.0870563939253017  |  0.0 0.5\n",
      "2 30       |  3 1            | 30 2            |  2.1000000000000014  |  0.0 0.5\n",
      "----\n",
      "3 4       |  3 2            | 4 3            |  0.17529500335540504  |  0.0 0.5\n",
      "3 5       |  3 1            | 5 3            |  0.44681622579222235  |  0.0 0.5\n",
      "3 6       |  3 1            | 6 3            |  0.5840593484403591  |  0.0 0.5\n",
      "3 7       |  3 1            | 7 3            |  0.6912700877259859  |  0.0 0.5\n",
      "3 8       |  3 1            | 8 3            |  0.777879374456468  |  0.0 0.5\n",
      "3 9       |  3 1            | 9 3            |  0.8496703905330314  |  0.0 0.5\n",
      "3 10       |  3 1            | 10 3            |  1.0621352869558436  |  0.0 0.5\n",
      "3 11       |  3 1            | 11 3            |  1.123068825522516  |  0.0 0.5\n",
      "3 12       |  3 1            | 12 3            |  1.1761891612533972  |  0.0 0.5\n",
      "3 13       |  3 1            | 13 3            |  1.223029732845042  |  0.0 0.5\n",
      "3 14       |  3 1            | 14 3            |  1.2647359065137493  |  0.0 0.5\n",
      "3 15       |  3 1            | 15 3            |  1.3021821116861716  |  0.0 0.5\n",
      "3 16       |  3 1            | 16 3            |  1.3360486405368306  |  0.0 0.5\n",
      "3 17       |  3 1            | 17 3            |  1.3668735129472864  |  0.0 0.5\n",
      "3 18       |  3 1            | 18 3            |  1.3950884143954383  |  0.0 0.5\n",
      "3 19       |  3 1            | 19 3            |  1.421044165635081  |  0.0 0.5\n",
      "3 20       |  3 0            | 20 3            |  1.4450291369907262  |  0.0 0.5\n",
      "3 21       |  3 0            | 21 3            |  1.4672828003112244  |  0.0 0.5\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.0 0.5\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568747  |  0.0 0.5\n",
      "3 24       |  3 0            | 24 3            |  1.5255135316402075  |  0.0 0.5\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136813  |  0.0 0.5\n",
      "3 26       |  3 0            | 26 3            |  1.5586337227781826  |  0.0 0.5\n",
      "3 27       |  3 0            | 27 3            |  1.573808079290707  |  0.0 0.5\n",
      "3 28       |  3 0            | 28 3            |  1.5881705768802092  |  0.0 0.5\n",
      "3 29       |  3 1            | 29 3            |  1.601792300439051  |  0.0 0.5\n",
      "3 30       |  3 1            | 30 3            |  1.6147359065137508  |  0.0 0.5\n",
      "----\n",
      "4 5       |  2 1            | 5 4            |  0.06129124025303767  |  0.0 0.5\n",
      "4 6       |  2 1            | 6 4            |  0.10703894780241541  |  0.0 0.5\n",
      "4 7       |  2 1            | 7 4            |  0.1427758608976255  |  0.0 0.5\n",
      "4 8       |  2 1            | 8 4            |  0.17164562314112075  |  0.0 0.5\n",
      "4 9       |  2 1            | 9 4            |  0.19557596183330617  |  0.0 0.5\n",
      "4 10       |  2 1            | 10 4            |  0.3237295847502324  |  0.0 0.5\n",
      "4 11       |  2 1            | 11 4            |  0.3498439584216655  |  0.0 0.5\n",
      "4 12       |  2 1            | 12 4            |  0.3726098165920426  |  0.0 0.5\n",
      "4 13       |  2 1            | 13 4            |  0.39268434727417656  |  0.0 0.5\n",
      "4 14       |  2 1            | 14 4            |  0.4105584217036231  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 15       |  2 1            | 15 4            |  0.4266067953489454  |  0.0 0.5\n",
      "4 16       |  2 1            | 16 4            |  0.44112102199922987  |  0.0 0.5\n",
      "4 17       |  2 1            | 17 4            |  0.4543316816037084  |  0.0 0.5\n",
      "4 18       |  2 1            | 18 4            |  0.46642378222434644  |  0.0 0.5\n",
      "4 19       |  2 1            | 19 4            |  0.47754767561276523  |  0.0 0.5\n",
      "4 20       |  2 0            | 20 4            |  0.4878269490508984  |  0.0 0.5\n",
      "4 21       |  2 0            | 21 4            |  0.4973642333311119  |  0.0 0.5\n",
      "4 22       |  2 0            | 22 4            |  0.5062455457470278  |  0.0 0.5\n",
      "4 23       |  2 0            | 23 4            |  0.5145435845935324  |  0.0 0.5\n",
      "4 24       |  2 0            | 24 4            |  0.5223202610435322  |  0.0 0.5\n",
      "4 25       |  2 0            | 25 4            |  0.5296286681321654  |  0.0 0.5\n",
      "4 26       |  2 0            | 26 4            |  0.5365146286740945  |  0.0 0.5\n",
      "4 27       |  2 0            | 27 4            |  0.5430179243223208  |  0.0 0.5\n",
      "4 28       |  2 0            | 28 4            |  0.5491732804321039  |  0.0 0.5\n",
      "4 29       |  2 1            | 29 4            |  0.5550111619573244  |  0.0 0.5\n",
      "4 30       |  2 1            | 30 4            |  0.5605584217036217  |  0.0 0.5\n",
      "----\n",
      "5 20       |  1 0            | 20 5            |  0.13196336289044908  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765052024  |  0.0 0.5\n",
      "5 22       |  1 0            | 22 5            |  0.13810289512248985  |  0.0 0.5\n",
      "5 23       |  1 0            | 23 5            |  0.1408689080713259  |  0.0 0.5\n",
      "5 24       |  1 0            | 24 5            |  0.14346113355465917  |  0.0 0.5\n",
      "5 25       |  1 0            | 25 5            |  0.1458972692508702  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 27       |  1 0            | 27 5            |  0.15036035464758868  |  0.0 0.5\n",
      "5 28       |  1 0            | 28 5            |  0.15241214001751757  |  0.0 0.5\n",
      "----\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 23       |  1 0            | 23 6            |  0.11799505429663526  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 27       |  1 0            | 27 6            |  0.12748650087289803  |  0.0 0.5\n",
      "6 28       |  1 0            | 28 6            |  0.12953828624282693  |  0.0 0.5\n",
      "----\n",
      "7 20       |  1 0            | 20 7            |  0.09122105256815516  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822632  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019594  |  0.0 0.5\n",
      "7 23       |  1 0            | 23 7            |  0.10012659774903199  |  0.0 0.5\n",
      "7 24       |  1 0            | 24 7            |  0.10271882323236525  |  0.0 0.5\n",
      "7 25       |  1 0            | 25 7            |  0.10515495892857629  |  0.0 0.5\n",
      "7 26       |  1 0            | 26 7            |  0.10745027910921934  |  0.0 0.5\n",
      "7 27       |  1 0            | 27 7            |  0.10961804432529476  |  0.0 0.5\n",
      "7 28       |  1 0            | 28 7            |  0.11166982969522365  |  0.0 0.5\n",
      "----\n",
      "8 20       |  1 0            | 20 8            |  0.07678617144640754  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.0799652662064787  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367844831  |  0.0 0.5\n",
      "8 23       |  1 0            | 23 8            |  0.08569171662728436  |  0.0 0.5\n",
      "8 24       |  1 0            | 24 8            |  0.08828394211061763  |  0.0 0.5\n",
      "8 25       |  1 0            | 25 8            |  0.09072007780682867  |  0.0 0.5\n",
      "8 26       |  1 0            | 26 8            |  0.09301539798747172  |  0.0 0.5\n",
      "8 27       |  1 0            | 27 8            |  0.09518316320354714  |  0.0 0.5\n",
      "8 28       |  1 0            | 28 8            |  0.09723494857347603  |  0.0 0.5\n",
      "----\n",
      "9 20       |  1 0            | 20 9            |  0.06482100210031305  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235383  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728118988  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276452315  |  0.0 0.5\n",
      "9 25       |  1 0            | 25 9            |  0.07875490846073419  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137723  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745265  |  0.0 0.5\n",
      "9 28       |  1 0            | 28 9            |  0.08526977922738155  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 19.916508275000204 -- 17 crouching tiger hidden dragon\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.0 0.5\n",
      "0 2       |  4 1            | 2 0            |  7.000000000000002  |  0.009185460609227425 0.4977036509934318\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899106  |  0.033378282958236416 0.4916562039047883\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481877  |  0.033378282958236416 0.4916562039047883\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.033378282958236416 0.4916562039047883\n",
      "0 6       |  4 0            | 6 0            |  10.000000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040285  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231684  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852769  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.250000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226612  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500428  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603615  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545707  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137446  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217029  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699555  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.87978103485236  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.94307429364241  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268504  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.000000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  3 1            | 2 1            |  0.7855785214287465  |  0.009185460609227425 0.4977036509934318\n",
      "1 3       |  3 0            | 3 1            |  1.4017723684864514  |  0.033378282958236416 0.4916562039047883\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.033378282958236416 0.4916562039047883\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.033378282958236416 0.4916562039047883\n",
      "1 6       |  3 0            | 6 1            |  2.083174941666872  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  3 0            | 7 1            |  2.208254137500102  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749898  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442295  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  3 0            | 11 1            |  2.5248411940089674  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398486  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.34989206720724864 0.4134085947484186\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666606  |  0.34989206720724864 0.4134085947484186\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.34989206720724864 0.4134085947484186\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "2 3       |  1 0            | 3 2            |  0.06932344192660622  |  0.02419282234900899 0.49395208939300733\n",
      "2 4       |  1 0            | 4 2            |  0.11314719276546015  |  0.02419282234900899 0.49395208939300733\n",
      "2 5       |  1 0            | 5 2            |  0.1437928128919772  |  0.02419282234900899 0.49395208939300733\n",
      "2 6       |  1 0            | 6 2            |  0.16666666666666785  |  0.3407066065980212 0.41563784409136695\n",
      "2 7       |  1 0            | 7 2            |  0.18453512321427112  |  0.3407066065980212 0.41563784409136695\n",
      "2 8       |  1 0            | 8 2            |  0.19897000433601875  |  0.3407066065980212 0.41563784409136695\n",
      "2 9       |  1 0            | 9 2            |  0.21093517368211323  |  0.3407066065980212 0.41563784409136695\n",
      "2 10       |  1 0            | 10 2            |  0.22105705434886858  |  0.3407066065980212 0.41563784409136695\n",
      "2 11       |  1 0            | 11 2            |  0.22976184557268198  |  0.3407066065980212 0.41563784409136695\n",
      "2 12       |  1 0            | 12 2            |  0.23735046496280532  |  0.3407066065980212 0.41563784409136695\n",
      "2 13       |  1 0            | 13 2            |  0.24404197519018567  |  0.3407066065980212 0.41563784409136695\n",
      "2 14       |  1 0            | 14 2            |  0.25  |  0.3407066065980212 0.41563784409136695\n",
      "2 15       |  1 0            | 15 2            |  0.2553494578817741  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 16       |  1 0            | 16 2            |  0.26018753343186773  |  0.3407066065980212 0.41563784409136695\n",
      "2 17       |  1 0            | 17 2            |  0.26459108663336295  |  0.3407066065980212 0.41563784409136695\n",
      "2 18       |  1 0            | 18 2            |  0.2686217868402423  |  0.3407066065980212 0.41563784409136695\n",
      "2 19       |  1 0            | 19 2            |  0.2723297513030474  |  0.3407066065980212 0.41563784409136695\n",
      "2 20       |  1 0            | 20 2            |  0.2757561757824263  |  0.3407066065980212 0.41563784409136695\n",
      "2 21       |  1 0            | 21 2            |  0.27893527054249745  |  0.3407066065980212 0.41563784409136695\n",
      "2 22       |  1 0            | 22 2            |  0.28189570801446706  |  0.3407066065980212 0.41563784409136695\n",
      "2 23       |  1 0            | 23 2            |  0.2846617209633031  |  0.3407066065980212 0.41563784409136695\n",
      "2 24       |  1 0            | 24 2            |  0.2872539464466364  |  0.3407066065980212 0.41563784409136695\n",
      "2 25       |  1 0            | 25 2            |  0.2896900821428474  |  0.3407066065980212 0.41563784409136695\n",
      "2 26       |  1 0            | 26 2            |  0.29198540232349046  |  0.3407066065980212 0.41563784409136695\n",
      "2 27       |  1 0            | 27 2            |  0.2941531675395659  |  0.3407066065980212 0.41563784409136695\n",
      "2 28       |  1 0            | 28 2            |  0.2962049529094948  |  0.3407066065980212 0.41563784409136695\n",
      "2 29       |  1 0            | 29 2            |  0.29815091341789923  |  0.3407066065980212 0.41563784409136695\n",
      "2 30       |  1 0            | 30 2            |  0.3000000000000007  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.630929753571458 -- 18 fight club\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 1            | 1 0            |  5.166983449999595  |  0.34989206720724864 0.4134085947484186\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 1            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  1 0            | 2 1            |  0.13092975357145775  |  0.0 0.5\n",
      "1 3       |  1 0            | 3 1            |  0.20025319549806397  |  0.0 0.5\n",
      "1 4       |  1 0            | 4 1            |  0.24407694633691612  |  0.0 0.5\n",
      "1 5       |  1 0            | 5 1            |  0.27472256646343496  |  0.0 0.5\n",
      "1 6       |  1 0            | 6 1            |  0.2975964202381238  |  0.0 0.5\n",
      "1 7       |  1 0            | 7 1            |  0.3154648767857289  |  0.0 0.5\n",
      "1 8       |  1 0            | 8 1            |  0.3298997579074765  |  0.0 0.5\n",
      "1 9       |  1 0            | 9 1            |  0.3418649272535692  |  0.0 0.5\n",
      "1 10       |  1 0            | 10 1            |  0.3519868079203281  |  0.0 0.5\n",
      "1 11       |  1 0            | 11 1            |  0.36069159914413795  |  0.0 0.5\n",
      "1 12       |  1 0            | 12 1            |  0.36828021853426485  |  0.0 0.5\n",
      "1 13       |  1 0            | 13 1            |  0.37497172876164164  |  0.0 0.5\n",
      "1 14       |  1 0            | 14 1            |  0.38092975357145775  |  0.0 0.5\n",
      "1 15       |  1 0            | 15 1            |  0.38627921145323185  |  0.0 0.5\n",
      "1 16       |  1 0            | 16 1            |  0.3911172870033255  |  0.0 0.5\n",
      "1 17       |  1 0            | 17 1            |  0.3955208402048189  |  0.0 0.5\n",
      "1 18       |  1 0            | 18 1            |  0.39955154041169827  |  0.0 0.5\n",
      "1 19       |  1 0            | 19 1            |  0.4032595048745051  |  0.0 0.5\n",
      "1 20       |  1 0            | 20 1            |  0.40668592935388226  |  0.0 0.5\n",
      "1 21       |  1 0            | 21 1            |  0.4098650241139534  |  0.0 0.5\n",
      "1 22       |  1 0            | 22 1            |  0.4128254615859266  |  0.0 0.5\n",
      "1 23       |  1 0            | 23 1            |  0.41559147453476086  |  0.0 0.5\n",
      "1 24       |  1 0            | 24 1            |  0.41818370001809413  |  0.0 0.5\n",
      "1 25       |  1 0            | 25 1            |  0.42061983571430517  |  0.0 0.5\n",
      "1 27       |  1 0            | 27 1            |  0.42508292111102364  |  0.0 0.5\n",
      "1 28       |  1 0            | 28 1            |  0.42713470648095075  |  0.0 0.5\n",
      "1 29       |  1 0            | 29 1            |  0.42908066698935876  |  0.0 0.5\n",
      "1 30       |  1 0            | 30 1            |  0.43092975357145846  |  0.0 0.5\n",
      "1 31       |  1 0            | 31 1            |  0.4326898904008978  |  0.0 0.5\n",
      "1 32       |  1 0            | 32 1            |  0.43436812133863434  |  0.0 0.5\n",
      "1 33       |  1 0            | 33 1            |  0.43597073167767064  |  0.0 0.5\n",
      "1 34       |  1 0            | 34 1            |  0.4375033499541878  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 28.639213832155747 -- 19 die hard\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.952561971428338  |  0.0 0.5\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.0 0.5\n",
      "0 3       |  4 3            | 3 0            |  4.554587535412857  |  0.02419282234900899 0.49395208939300733\n",
      "0 4       |  4 3            | 4 0            |  4.905177542123667  |  0.02419282234900899 0.49395208939300733\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040285  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231684  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.16062962785277  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226612  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545707  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137448  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699556  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.87978103485236  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642411  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  3 0            | 6 1            |  2.0831749416668686  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  3 0            | 7 1            |  2.2082541375000986  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  3 0            | 9 1            |  2.393054490774986  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  3 0            | 10 1            |  2.4639076554422914  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  3 0            | 11 1            |  2.524841194008964  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  3 0            | 12 1            |  2.577961529739845  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  3 0            | 15 1            |  2.7039544801726194  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  3 0            | 17 1            |  2.7686458814337342  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  3 0            | 18 1            |  2.796860782881886  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215288  |  0.3407066065980212 0.41563784409136695\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477174  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  3 0            | 22 1            |  2.889778231101481  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  3 0            | 28 1            |  2.989942945366657  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.3407066065980212 0.41563784409136695\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.3407066065980212 0.41563784409136695\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "2 5       |  3 0            | 5 2            |  1.006549690243844  |  0.3407066065980212 0.41563784409136695\n",
      "2 6       |  3 0            | 6 2            |  1.1666666666666643  |  0.3407066065980212 0.41563784409136695\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624998943  |  0.3407066065980212 0.41563784409136695\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.3407066065980212 0.41563784409136695\n",
      "2 9       |  3 0            | 9 2            |  1.476546215774782  |  0.3407066065980212 0.41563784409136695\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420871  |  0.3407066065980212 0.41563784409136695\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087596  |  0.3407066065980212 0.41563784409136695\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396408  |  0.3407066065980212 0.41563784409136695\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.3407066065980212 0.41563784409136695\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.3407066065980212 0.41563784409136695\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724151  |  0.3407066065980212 0.41563784409136695\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.3407066065980212 0.41563784409136695\n",
      "2 17       |  3 0            | 17 2            |  1.85213760643353  |  0.3407066065980212 0.41563784409136695\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816818  |  0.3407066065980212 0.41563784409136695\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213245  |  0.3407066065980212 0.41563784409136695\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769698  |  0.3407066065980212 0.41563784409136695\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.3407066065980212 0.41563784409136695\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012765  |  0.3407066065980212 0.41563784409136695\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.3407066065980212 0.41563784409136695\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.3407066065980212 0.41563784409136695\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.3407066065980212 0.41563784409136695\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.3407066065980212 0.41563784409136695\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.3407066065980212 0.41563784409136695\n",
      "2 28       |  3 0            | 28 2            |  2.073434670366453  |  0.3407066065980212 0.41563784409136695\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.3407066065980212 0.41563784409136695\n",
      "2 30       |  3 0            | 30 2            |  2.1000000000000014  |  0.3407066065980212 0.41563784409136695\n",
      "2 31       |  3 0            | 31 2            |  2.1123209578060766  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "3 5       |  3 0            | 5 3            |  0.5212855967575933  |  0.3165137842490122 0.4215255995031885\n",
      "3 6       |  3 0            | 6 3            |  0.6814025731804207  |  0.3165137842490122 0.4215255995031885\n",
      "3 7       |  3 0            | 7 3            |  0.8064817690136508  |  0.3165137842490122 0.4215255995031885\n",
      "3 8       |  3 0            | 8 3            |  0.9075259368658806  |  0.3165137842490122 0.4215255995031885\n",
      "3 9       |  3 0            | 9 3            |  0.9912821222885384  |  0.3165137842490122 0.4215255995031885\n",
      "3 10       |  3 0            | 10 3            |  1.0621352869558436  |  0.3165137842490122 0.4215255995031885\n",
      "3 11       |  3 0            | 11 3            |  1.123068825522516  |  0.3165137842490122 0.4215255995031885\n",
      "3 12       |  3 0            | 12 3            |  1.1761891612533972  |  0.3165137842490122 0.4215255995031885\n",
      "3 13       |  3 0            | 13 3            |  1.223029732845042  |  0.3165137842490122 0.4215255995031885\n",
      "3 14       |  3 0            | 14 3            |  1.2647359065137493  |  0.3165137842490122 0.4215255995031885\n",
      "3 15       |  3 0            | 15 3            |  1.3021821116861716  |  0.3165137842490122 0.4215255995031885\n",
      "3 16       |  3 0            | 16 3            |  1.3360486405368306  |  0.3165137842490122 0.4215255995031885\n",
      "3 17       |  3 0            | 17 3            |  1.3668735129472864  |  0.3165137842490122 0.4215255995031885\n",
      "3 18       |  3 0            | 18 3            |  1.3950884143954383  |  0.3165137842490122 0.4215255995031885\n",
      "3 19       |  3 0            | 19 3            |  1.421044165635081  |  0.3165137842490122 0.4215255995031885\n",
      "3 20       |  3 0            | 20 3            |  1.4450291369907262  |  0.3165137842490122 0.4215255995031885\n",
      "3 21       |  3 0            | 21 3            |  1.4672828003112244  |  0.3165137842490122 0.4215255995031885\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.3165137842490122 0.4215255995031885\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568747  |  0.3165137842490122 0.4215255995031885\n",
      "3 24       |  3 0            | 24 3            |  1.5255135316402075  |  0.3165137842490122 0.4215255995031885\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136813  |  0.3165137842490122 0.4215255995031885\n",
      "3 26       |  3 0            | 26 3            |  1.5586337227781826  |  0.3165137842490122 0.4215255995031885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 27       |  3 0            | 27 3            |  1.573808079290707  |  0.3165137842490122 0.4215255995031885\n",
      "3 28       |  3 0            | 28 3            |  1.5881705768802092  |  0.3165137842490122 0.4215255995031885\n",
      "3 29       |  3 0            | 29 3            |  1.601792300439051  |  0.3165137842490122 0.4215255995031885\n",
      "3 30       |  3 0            | 30 3            |  1.6147359065137508  |  0.3165137842490122 0.4215255995031885\n",
      "3 31       |  3 0            | 31 3            |  1.627056864319826  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "4 5       |  3 0            | 5 4            |  0.21451934088563362  |  0.3165137842490122 0.4215255995031885\n",
      "4 6       |  3 0            | 6 4            |  0.3746363173084575  |  0.3165137842490122 0.4215255995031885\n",
      "4 7       |  3 0            | 7 4            |  0.4997155131416875  |  0.3165137842490122 0.4215255995031885\n",
      "4 8       |  3 0            | 8 4            |  0.6007596809939209  |  0.3165137842490122 0.4215255995031885\n",
      "4 9       |  3 0            | 9 4            |  0.6845158664165751  |  0.3165137842490122 0.4215255995031885\n",
      "4 10       |  3 0            | 10 4            |  0.7553690310838803  |  0.3165137842490122 0.4215255995031885\n",
      "4 11       |  3 0            | 11 4            |  0.8163025696505528  |  0.3165137842490122 0.4215255995031885\n",
      "4 12       |  3 0            | 12 4            |  0.869422905381434  |  0.3165137842490122 0.4215255995031885\n",
      "4 13       |  3 0            | 13 4            |  0.9162634769730822  |  0.3165137842490122 0.4215255995031885\n",
      "4 14       |  3 0            | 14 4            |  0.9579696506417896  |  0.3165137842490122 0.4215255995031885\n",
      "4 15       |  3 0            | 15 4            |  0.9954158558142083  |  0.3165137842490122 0.4215255995031885\n",
      "4 16       |  3 0            | 16 4            |  1.0292823846648709  |  0.3165137842490122 0.4215255995031885\n",
      "4 17       |  3 0            | 17 4            |  1.0601072570753232  |  0.3165137842490122 0.4215255995031885\n",
      "4 18       |  3 0            | 18 4            |  1.088322158523475  |  0.3165137842490122 0.4215255995031885\n",
      "4 19       |  3 0            | 19 4            |  1.1142779097631177  |  0.3165137842490122 0.4215255995031885\n",
      "4 20       |  3 0            | 20 4            |  1.138262881118763  |  0.3165137842490122 0.4215255995031885\n",
      "4 21       |  3 0            | 21 4            |  1.1605165444392647  |  0.3165137842490122 0.4215255995031885\n",
      "4 22       |  3 0            | 22 4            |  1.1812396067430697  |  0.3165137842490122 0.4215255995031885\n",
      "4 23       |  3 0            | 23 4            |  1.200601697384915  |  0.3165137842490122 0.4215255995031885\n",
      "4 24       |  3 0            | 24 4            |  1.2187472757682478  |  0.3165137842490122 0.4215255995031885\n",
      "4 25       |  3 0            | 25 4            |  1.2358002256417215  |  0.3165137842490122 0.4215255995031885\n",
      "4 26       |  3 0            | 26 4            |  1.2518674669062229  |  0.3165137842490122 0.4215255995031885\n",
      "4 27       |  3 0            | 27 4            |  1.2670418234187473  |  0.3165137842490122 0.4215255995031885\n",
      "4 28       |  3 0            | 28 4            |  1.281404321008246  |  0.3165137842490122 0.4215255995031885\n",
      "4 29       |  3 0            | 29 4            |  1.2950260445670914  |  0.3165137842490122 0.4215255995031885\n",
      "4 30       |  3 0            | 30 4            |  1.307969650641791  |  0.3165137842490122 0.4215255995031885\n",
      "4 31       |  3 0            | 31 4            |  1.3202906084478663  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 19.542769092338542 -- 20 last temptation of christ\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.009185460609227425 0.4977036509934318\n",
      "0 2       |  4 1            | 2 0            |  7.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 2            | 4 0            |  7.3577663131855005  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 2            | 5 0            |  7.725513754703734  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 2            | 7 0            |  8.214421478571255  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040283  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 2            | 9 0            |  8.531222084185346  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 1            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 2            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 1            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 2            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 2            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 2            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 1            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 2            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "2 1       |  1 0            | 1 2            |  0.13092975357145775  |  -0.3407066065980212 0.5843621559086332\n",
      "2 3       |  1 0            | 3 2            |  0.06932344192660622  |  0.0 0.5\n",
      "2 6       |  1 0            | 6 2            |  0.1666666666666643  |  0.0 0.5\n",
      "2 8       |  1 0            | 8 2            |  0.19897000433601875  |  0.0 0.5\n",
      "2 14       |  1 0            | 14 2            |  0.25  |  0.0 0.5\n",
      "2 18       |  1 0            | 18 2            |  0.2686217868402423  |  0.0 0.5\n",
      "2 20       |  1 0            | 20 2            |  0.2757561757824263  |  0.0 0.5\n",
      "2 21       |  1 0            | 21 2            |  0.27893527054249745  |  0.0 0.5\n",
      "2 22       |  1 0            | 22 2            |  0.28189570801446706  |  0.0 0.5\n",
      "2 23       |  1 0            | 23 2            |  0.28466172096330666  |  0.0 0.5\n",
      "2 24       |  1 0            | 24 2            |  0.28725394644663993  |  0.0 0.5\n",
      "2 25       |  1 0            | 25 2            |  0.2896900821428474  |  0.0 0.5\n",
      "2 26       |  1 0            | 26 2            |  0.29198540232349046  |  0.0 0.5\n",
      "2 27       |  1 0            | 27 2            |  0.29415316753956944  |  0.0 0.5\n",
      "2 28       |  1 0            | 28 2            |  0.2962049529094912  |  0.0 0.5\n",
      "2 29       |  1 0            | 29 2            |  0.29815091341789923  |  0.0 0.5\n",
      "2 30       |  1 0            | 30 2            |  0.30000000000000426  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "4 1       |  2 0            | 1 4            |  0.7322308390107466  |  -0.3407066065980212 0.5843621559086332\n",
      "4 2       |  2 1            | 2 4            |  0.2262943855309132  |  0.0 0.5\n",
      "4 3       |  2 0            | 3 4            |  0.13147125251655467  |  0.0 0.5\n",
      "4 6       |  2 0            | 6 4            |  0.16055842170362666  |  0.0 0.5\n",
      "4 8       |  2 0            | 8 4            |  0.2574684347116829  |  0.0 0.5\n",
      "4 10       |  2 1            | 10 4            |  0.3237295847502324  |  0.0 0.5\n",
      "4 12       |  2 1            | 12 4            |  0.3726098165920462  |  0.0 0.5\n",
      "4 14       |  2 0            | 14 4            |  0.41055842170362666  |  0.0 0.5\n",
      "4 17       |  2 1            | 17 4            |  0.45433168160371196  |  0.0 0.5\n",
      "4 18       |  2 0            | 18 4            |  0.46642378222434644  |  0.0 0.5\n",
      "4 20       |  2 0            | 20 4            |  0.4878269490508984  |  0.0 0.5\n",
      "4 21       |  2 0            | 21 4            |  0.4973642333311119  |  0.0 0.5\n",
      "4 22       |  2 0            | 22 4            |  0.5062455457470278  |  0.0 0.5\n",
      "4 23       |  2 0            | 23 4            |  0.5145435845935324  |  0.0 0.5\n",
      "4 24       |  2 0            | 24 4            |  0.5223202610435322  |  0.0 0.5\n",
      "4 25       |  2 0            | 25 4            |  0.5296286681321689  |  0.0 0.5\n",
      "4 26       |  2 0            | 26 4            |  0.536514628674098  |  0.0 0.5\n",
      "4 27       |  2 0            | 27 4            |  0.5430179243223208  |  0.0 0.5\n",
      "4 28       |  2 0            | 28 4            |  0.5491732804321074  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 29       |  2 0            | 29 4            |  0.5550111619573244  |  0.0 0.5\n",
      "4 30       |  2 0            | 30 4            |  0.5605584217036252  |  0.0 0.5\n",
      "----\n",
      "5 1       |  2 0            | 1 5            |  0.8241676993903084  |  -0.3407066065980212 0.5843621559086332\n",
      "5 2       |  2 1            | 2 5            |  0.2875856257839544  |  0.0 0.5\n",
      "5 3       |  2 0            | 3 5            |  0.22340811289611295  |  0.0 0.5\n",
      "5 6       |  2 0            | 6 5            |  0.06862156132406483  |  0.0 0.5\n",
      "5 8       |  2 0            | 8 5            |  0.16553157433212107  |  0.0 0.5\n",
      "5 10       |  2 1            | 10 5            |  0.2317927243706741  |  0.0 0.5\n",
      "5 12       |  2 1            | 12 5            |  0.28067295621248434  |  0.0 0.5\n",
      "5 14       |  2 0            | 14 5            |  0.31862156132406483  |  0.0 0.5\n",
      "5 17       |  2 1            | 17 5            |  0.3623948212241501  |  0.0 0.5\n",
      "5 18       |  2 0            | 18 5            |  0.37448692184478816  |  0.0 0.5\n",
      "5 20       |  2 0            | 20 5            |  0.3958900886713401  |  0.0 0.5\n",
      "5 21       |  2 0            | 21 5            |  0.4054273729515536  |  0.0 0.5\n",
      "5 22       |  2 0            | 22 5            |  0.41430868536746956  |  0.0 0.5\n",
      "5 23       |  2 0            | 23 5            |  0.42260672421397416  |  0.0 0.5\n",
      "5 24       |  2 0            | 24 5            |  0.43038340066397396  |  0.0 0.5\n",
      "5 25       |  2 0            | 25 5            |  0.4376918077526071  |  0.0 0.5\n",
      "5 26       |  2 0            | 26 5            |  0.4445777682945362  |  0.0 0.5\n",
      "5 27       |  2 0            | 27 5            |  0.4510810639427625  |  0.0 0.5\n",
      "5 28       |  2 0            | 28 5            |  0.4572364200525456  |  0.0 0.5\n",
      "5 29       |  2 0            | 29 5            |  0.4630743015777661  |  0.0 0.5\n",
      "5 30       |  2 0            | 30 5            |  0.4686215613240634  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "7 1       |  2 0            | 1 7            |  0.9463946303571866  |  -0.3407066065980212 0.5843621559086332\n",
      "7 2       |  2 1            | 2 7            |  0.3690702464285387  |  0.0 0.5\n",
      "7 3       |  2 0            | 3 7            |  0.34563504386299115  |  0.0 0.5\n",
      "7 6       |  2 0            | 6 7            |  0.05360536964281337  |  0.0 0.5\n",
      "7 8       |  2 0            | 8 7            |  0.04330464336524287  |  0.0 0.5\n",
      "7 10       |  2 1            | 10 7            |  0.10956579340379591  |  0.0 0.5\n",
      "7 12       |  2 1            | 12 7            |  0.15844602524560614  |  0.0 0.5\n",
      "7 14       |  2 0            | 14 7            |  0.19639463035718663  |  0.0 0.5\n",
      "7 17       |  2 1            | 17 7            |  0.24016789025727192  |  0.0 0.5\n",
      "7 18       |  2 0            | 18 7            |  0.25225999087790996  |  0.0 0.5\n",
      "7 20       |  2 0            | 20 7            |  0.2736631577044619  |  0.0 0.5\n",
      "7 21       |  2 0            | 21 7            |  0.2832004419846754  |  0.0 0.5\n",
      "7 22       |  2 0            | 22 7            |  0.29208175440059136  |  0.0 0.5\n",
      "7 23       |  2 0            | 23 7            |  0.30037979324709596  |  0.0 0.5\n",
      "7 24       |  2 0            | 24 7            |  0.30815646969709576  |  0.0 0.5\n",
      "7 25       |  2 0            | 25 7            |  0.3154648767857289  |  0.0 0.5\n",
      "7 26       |  2 0            | 26 7            |  0.322350837327658  |  0.0 0.5\n",
      "7 27       |  2 0            | 27 7            |  0.3288541329758843  |  0.0 0.5\n",
      "7 28       |  2 0            | 28 7            |  0.3350094890856674  |  0.0 0.5\n",
      "7 29       |  2 0            | 29 7            |  0.3408473706108879  |  0.0 0.5\n",
      "7 30       |  2 0            | 30 7            |  0.3463946303571852  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "9 1       |  2 0            | 1 9            |  1.0255947817607094  |  -0.3407066065980212 0.5843621559086332\n",
      "9 2       |  2 1            | 2 9            |  0.42187034736422646  |  0.0 0.5\n",
      "9 3       |  2 0            | 3 9            |  0.4248351952665139  |  0.0 0.5\n",
      "9 6       |  2 0            | 6 9            |  0.13280552104633614  |  0.0 0.5\n",
      "9 8       |  2 0            | 8 9            |  0.0358955080382799  |  0.0 0.5\n",
      "9 10       |  2 1            | 10 9            |  0.03036564200027314  |  0.0 0.5\n",
      "9 12       |  2 1            | 12 9            |  0.07924587384208337  |  0.0 0.5\n",
      "9 14       |  2 0            | 14 9            |  0.11719447895366386  |  0.0 0.5\n",
      "9 17       |  2 1            | 17 9            |  0.16096773885374915  |  0.0 0.5\n",
      "9 18       |  2 0            | 18 9            |  0.1730598394743872  |  0.0 0.5\n",
      "9 20       |  2 0            | 20 9            |  0.19446300630093916  |  0.0 0.5\n",
      "9 21       |  2 0            | 21 9            |  0.20400029058115265  |  0.0 0.5\n",
      "9 22       |  2 0            | 22 9            |  0.2128816029970686  |  0.0 0.5\n",
      "9 23       |  2 0            | 23 9            |  0.2211796418435732  |  0.0 0.5\n",
      "9 24       |  2 0            | 24 9            |  0.228956318293573  |  0.0 0.5\n",
      "9 25       |  2 0            | 25 9            |  0.2362647253822061  |  0.0 0.5\n",
      "9 26       |  2 0            | 26 9            |  0.24315068592413525  |  0.0 0.5\n",
      "9 27       |  2 0            | 27 9            |  0.24965398157236152  |  0.0 0.5\n",
      "9 28       |  2 0            | 28 9            |  0.25580933768214464  |  0.0 0.5\n",
      "9 29       |  2 0            | 29 9            |  0.2616472192073651  |  0.0 0.5\n",
      "9 30       |  2 0            | 30 9            |  0.26719447895366244  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "11 2       |  2 1            | 2 11            |  0.22976184557268198  |  0.0 0.5\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 21 tree of life\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.3407066065980212 0.41563784409136695\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 9.822067973767801 -- 22 murray saves christmas\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 3       |  2 0            | 3 0            |  1.7079703257798204  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  2 0            | 4 0            |  1.839441578296376  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  2 0            | 5 0            |  1.9313784386759343  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  2 0            | 6 0            |  2.000000000000001  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  2 1            | 7 0            |  1.3690702464285422  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  2 1            | 8 0            |  1.3979400086720375  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  2 1            | 9 0            |  1.4218703473642247  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  2 1            | 10 0            |  2.163171163046611  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  2 1            | 11 0            |  2.1892855367180415  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  2 1            | 12 0            |  2.2120513948884204  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  2 1            | 13 0            |  2.2321259255705543  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  2 1            | 14 0            |  2.250000000000001  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  2 1            | 15 0            |  2.266048373645323  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  2 1            | 16 0            |  2.2805626002956068  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  2 1            | 17 0            |  2.293773259900086  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  2 1            | 18 0            |  2.3058653605207233  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  2 1            | 19 0            |  2.316989253909142  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  2 0            | 20 0            |  2.3272685273472744  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  2 0            | 21 0            |  2.3368058116274897  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  2 0            | 22 0            |  2.3456871240434065  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  2 0            | 23 0            |  2.353985162889911  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  2 0            | 24 0            |  2.361761839339912  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  2 0            | 25 0            |  2.369070246428543  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  2 0            | 26 0            |  2.3759562069704723  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  2 0            | 27 0            |  2.3824595026186977  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  2 0            | 28 0            |  2.3886148587284826  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  2 0            | 29 0            |  2.3944527402537013  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  2 1            | 30 0            |  2.4000000000000012  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  2 1            | 31 0            |  2.405280410488319  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  2 1            | 32 0            |  2.4103151033015333  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  2 1            | 33 0            |  2.4151229343186422  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  2 0            | 34 0            |  2.4197207891481884  |  0.3407066065980212 0.41563784409136695\n",
      "0 35       |  2 0            | 35 0            |  2.4241238399803207  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36       |  2 0            | 36 0            |  2.4283457627196805  |  0.3407066065980212 0.41563784409136695\n",
      "0 37       |  2 0            | 37 0            |  2.4323989214493906  |  0.3407066065980212 0.41563784409136695\n",
      "0 38       |  2 0            | 38 0            |  2.436294525872678  |  0.3407066065980212 0.41563784409136695\n",
      "0 39       |  2 0            | 39 0            |  2.440042766283171  |  0.3407066065980212 0.41563784409136695\n",
      "0 40       |  2 0            | 40 0            |  2.4436529297538945  |  0.3407066065980212 0.41563784409136695\n",
      "0 41       |  2 0            | 41 0            |  2.447133500553883  |  0.3407066065980212 0.41563784409136695\n",
      "0 42       |  2 0            | 42 0            |  2.4504922472591  |  0.3407066065980212 0.41563784409136695\n",
      "0 43       |  2 0            | 43 0            |  2.4537362985901865  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 0       |  3 2            | 0 1            |  1.4762809857141708  |  0.0 0.5\n",
      "1 2       |  3 2            | 2 1            |  0.5237190142858292  |  0.3407066065980212 0.41563784409136695\n",
      "1 3       |  3 0            | 3 1            |  1.4017723684864514  |  0.3407066065980212 0.41563784409136695\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.3407066065980212 0.41563784409136695\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  3 0            | 6 1            |  2.0831749416668703  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  3 1            | 7 1            |  1.8927892607143733  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  3 1            | 8 1            |  1.979398547444858  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  3 1            | 9 1            |  2.051189563521418  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  3 1            | 10 1            |  2.463907655442294  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  3 1            | 11 1            |  2.524841194008965  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  3 1            | 12 1            |  2.5779615297398486  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  3 1            | 13 1            |  2.624802101331495  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  3 1            | 14 1            |  2.6665082750002034  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  3 1            | 15 1            |  2.703954480172621  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  3 1            | 16 1            |  2.737821009023283  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  3 1            | 17 1            |  2.768645881433735  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  3 1            | 18 1            |  2.7968607828818888  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  3 1            | 19 1            |  2.8228165341215323  |  0.3407066065980212 0.41563784409136695\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477175  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976766  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014826  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  3 0            | 23 1            |  2.909140321743328  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266616  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646366  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666597  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925504  |  0.3407066065980212 0.41563784409136695\n",
      "1 30       |  3 1            | 30 1            |  3.016508275000203  |  0.3407066065980212 0.41563784409136695\n",
      "1 31       |  3 1            | 31 1            |  3.02882923280628  |  0.3407066065980212 0.41563784409136695\n",
      "1 32       |  3 1            | 32 1            |  3.040576849370445  |  0.3407066065980212 0.41563784409136695\n",
      "1 33       |  3 1            | 33 1            |  3.051795121743699  |  0.3407066065980212 0.41563784409136695\n",
      "1 34       |  3 0            | 34 1            |  3.0625234496793077  |  0.3407066065980212 0.41563784409136695\n",
      "1 35       |  3 0            | 35 1            |  3.0727972349542823  |  0.3407066065980212 0.41563784409136695\n",
      "1 36       |  3 0            | 36 1            |  3.0826483880127897  |  0.3407066065980212 0.41563784409136695\n",
      "1 37       |  3 0            | 37 1            |  3.0921057583821137  |  0.3407066065980212 0.41563784409136695\n",
      "1 38       |  3 0            | 38 1            |  3.1011955020364503  |  0.3407066065980212 0.41563784409136695\n",
      "1 39       |  3 0            | 39 1            |  3.1099413963276  |  0.3407066065980212 0.41563784409136695\n",
      "1 40       |  3 0            | 40 1            |  3.118365111092621  |  0.3407066065980212 0.41563784409136695\n",
      "1 41       |  3 0            | 41 1            |  3.1264864429592603  |  0.3407066065980212 0.41563784409136695\n",
      "1 42       |  3 0            | 42 1            |  3.134323518604768  |  0.3407066065980212 0.41563784409136695\n",
      "1 43       |  3 0            | 43 1            |  3.141892971710636  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "2 3       |  2 0            | 3 2            |  0.20797032577982044  |  0.0 0.5\n",
      "2 4       |  2 0            | 4 2            |  0.3394415782963751  |  0.0 0.5\n",
      "2 5       |  2 0            | 5 2            |  0.4313784386759334  |  0.0 0.5\n",
      "2 6       |  2 0            | 6 2            |  0.5  |  0.0 0.5\n",
      "2 7       |  2 1            | 7 2            |  0.36907024642854225  |  0.0 0.5\n",
      "2 8       |  2 1            | 8 2            |  0.3979400086720375  |  0.0 0.5\n",
      "2 9       |  2 1            | 9 2            |  0.4218703473642247  |  0.0 0.5\n",
      "2 10       |  2 1            | 10 2            |  0.6631711630466111  |  0.0 0.5\n",
      "2 11       |  2 1            | 11 2            |  0.6892855367180406  |  0.0 0.5\n",
      "2 12       |  2 1            | 12 2            |  0.7120513948884195  |  0.0 0.5\n",
      "2 13       |  2 1            | 13 2            |  0.7321259255705534  |  0.0 0.5\n",
      "2 14       |  2 1            | 14 2            |  0.75  |  0.0 0.5\n",
      "2 15       |  2 1            | 15 2            |  0.7660483736453223  |  0.0 0.5\n",
      "2 16       |  2 1            | 16 2            |  0.780562600295605  |  0.0 0.5\n",
      "2 17       |  2 1            | 17 2            |  0.7937732599000853  |  0.0 0.5\n",
      "2 18       |  2 1            | 18 2            |  0.8058653605207233  |  0.0 0.5\n",
      "2 19       |  2 1            | 19 2            |  0.8169892539091403  |  0.0 0.5\n",
      "2 20       |  2 0            | 20 2            |  0.8272685273472735  |  0.0 0.5\n",
      "2 21       |  2 0            | 21 2            |  0.8368058116274888  |  0.0 0.5\n",
      "2 22       |  2 0            | 22 2            |  0.8456871240434047  |  0.0 0.5\n",
      "2 23       |  2 0            | 23 2            |  0.8539851628899111  |  0.0 0.5\n",
      "2 24       |  2 0            | 24 2            |  0.8617618393399109  |  0.0 0.5\n",
      "2 25       |  2 0            | 25 2            |  0.8690702464285422  |  0.0 0.5\n",
      "2 26       |  2 0            | 26 2            |  0.8759562069704714  |  0.0 0.5\n",
      "2 27       |  2 0            | 27 2            |  0.8824595026186959  |  0.0 0.5\n",
      "2 28       |  2 0            | 28 2            |  0.8886148587284808  |  0.0 0.5\n",
      "2 29       |  2 0            | 29 2            |  0.8944527402537013  |  0.0 0.5\n",
      "2 30       |  2 1            | 30 2            |  0.9000000000000004  |  0.0 0.5\n",
      "2 31       |  2 1            | 31 2            |  0.9052804104883183  |  0.0 0.5\n",
      "2 32       |  2 1            | 32 2            |  0.9103151033015315  |  0.0 0.5\n",
      "2 33       |  2 1            | 33 2            |  0.9151229343186404  |  0.0 0.5\n",
      "2 34       |  2 0            | 34 2            |  0.9197207891481884  |  0.0 0.5\n",
      "2 35       |  2 0            | 35 2            |  0.9241238399803198  |  0.0 0.5\n",
      "2 36       |  2 0            | 36 2            |  0.9283457627196796  |  0.0 0.5\n",
      "2 37       |  2 0            | 37 2            |  0.9323989214493906  |  0.0 0.5\n",
      "2 38       |  2 0            | 38 2            |  0.9362945258726771  |  0.0 0.5\n",
      "2 39       |  2 0            | 39 2            |  0.9400427662831703  |  0.0 0.5\n",
      "2 40       |  2 0            | 40 2            |  0.9436529297538936  |  0.0 0.5\n",
      "2 41       |  2 0            | 41 2            |  0.9471335005538819  |  0.0 0.5\n",
      "2 42       |  2 0            | 42 2            |  0.9504922472590991  |  0.0 0.5\n",
      "2 43       |  2 0            | 43 2            |  0.9537362985901865  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "7 3       |  1 0            | 3 7            |  0.1152116812876649  |  0.0 0.5\n",
      "7 4       |  1 0            | 4 7            |  0.07138793044881275  |  0.0 0.5\n",
      "7 5       |  1 0            | 5 7            |  0.04074231032229392  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 6       |  1 0            | 6 7            |  0.01786845654760505  |  0.0 0.5\n",
      "7 20       |  1 0            | 20 7            |  0.09122105256815338  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822455  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019771  |  0.0 0.5\n",
      "7 23       |  1 0            | 23 7            |  0.10012659774903199  |  0.0 0.5\n",
      "7 24       |  1 0            | 24 7            |  0.10271882323236525  |  0.0 0.5\n",
      "7 25       |  1 0            | 25 7            |  0.10515495892857629  |  0.0 0.5\n",
      "7 26       |  1 0            | 26 7            |  0.10745027910921934  |  0.0 0.5\n",
      "7 27       |  1 0            | 27 7            |  0.10961804432529476  |  0.0 0.5\n",
      "7 28       |  1 0            | 28 7            |  0.11166982969522188  |  0.0 0.5\n",
      "7 29       |  1 0            | 29 7            |  0.11361579020362989  |  0.0 0.5\n",
      "7 34       |  1 0            | 34 7            |  0.12203847316845717  |  0.0 0.5\n",
      "7 35       |  1 0            | 35 7            |  0.12350615677916821  |  0.0 0.5\n",
      "7 36       |  1 0            | 36 7            |  0.124913464358956  |  0.0 0.5\n",
      "7 37       |  1 0            | 37 7            |  0.12626451726885968  |  0.0 0.5\n",
      "7 38       |  1 0            | 38 7            |  0.12756305207662066  |  0.0 0.5\n",
      "7 39       |  1 0            | 39 7            |  0.12881246554678505  |  0.0 0.5\n",
      "7 40       |  1 0            | 40 7            |  0.13001585337035948  |  0.0 0.5\n",
      "7 41       |  1 0            | 41 7            |  0.13117604363702284  |  0.0 0.5\n",
      "7 42       |  1 0            | 42 7            |  0.13229562587209465  |  0.0 0.5\n",
      "7 43       |  1 0            | 43 7            |  0.13337697631579104  |  0.0 0.5\n",
      "----\n",
      "8 3       |  1 0            | 3 8            |  0.12964656240941252  |  0.0 0.5\n",
      "8 4       |  1 0            | 4 8            |  0.08582281157056038  |  0.0 0.5\n",
      "8 5       |  1 0            | 5 8            |  0.05517719144404154  |  0.0 0.5\n",
      "8 6       |  1 0            | 6 8            |  0.03230333766935267  |  0.0 0.5\n",
      "8 20       |  1 0            | 20 8            |  0.07678617144640576  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.07996526620647693  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367845009  |  0.0 0.5\n",
      "8 23       |  1 0            | 23 8            |  0.08569171662728436  |  0.0 0.5\n",
      "8 24       |  1 0            | 24 8            |  0.08828394211061763  |  0.0 0.5\n",
      "8 25       |  1 0            | 25 8            |  0.09072007780682867  |  0.0 0.5\n",
      "8 26       |  1 0            | 26 8            |  0.09301539798747172  |  0.0 0.5\n",
      "8 27       |  1 0            | 27 8            |  0.09518316320354714  |  0.0 0.5\n",
      "8 28       |  1 0            | 28 8            |  0.09723494857347426  |  0.0 0.5\n",
      "8 29       |  1 0            | 29 8            |  0.09918090908188226  |  0.0 0.5\n",
      "8 34       |  1 0            | 34 8            |  0.10760359204670955  |  0.0 0.5\n",
      "8 35       |  1 0            | 35 8            |  0.10907127565742059  |  0.0 0.5\n",
      "8 36       |  1 0            | 36 8            |  0.11047858323720838  |  0.0 0.5\n",
      "8 37       |  1 0            | 37 8            |  0.11182963614711205  |  0.0 0.5\n",
      "8 38       |  1 0            | 38 8            |  0.11312817095487304  |  0.0 0.5\n",
      "8 39       |  1 0            | 39 8            |  0.11437758442503743  |  0.0 0.5\n",
      "8 40       |  1 0            | 40 8            |  0.11558097224861186  |  0.0 0.5\n",
      "8 41       |  1 0            | 41 8            |  0.11674116251527522  |  0.0 0.5\n",
      "8 42       |  1 0            | 42 8            |  0.11786074475034702  |  0.0 0.5\n",
      "8 43       |  1 0            | 43 8            |  0.11894209519404342  |  0.0 0.5\n",
      "----\n",
      "9 3       |  1 0            | 3 9            |  0.14161173175550523  |  0.0 0.5\n",
      "9 4       |  1 0            | 4 9            |  0.09778798091665308  |  0.0 0.5\n",
      "9 5       |  1 0            | 5 9            |  0.06714236079013425  |  0.0 0.5\n",
      "9 6       |  1 0            | 6 9            |  0.04426850701544538  |  0.0 0.5\n",
      "9 20       |  1 0            | 20 9            |  0.06482100210031305  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235738  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728119166  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276452492  |  0.0 0.5\n",
      "9 25       |  1 0            | 25 9            |  0.07875490846073596  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137901  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745443  |  0.0 0.5\n",
      "9 28       |  1 0            | 28 9            |  0.08526977922738155  |  0.0 0.5\n",
      "9 29       |  1 0            | 29 9            |  0.08721573973578955  |  0.0 0.5\n",
      "9 34       |  1 0            | 34 9            |  0.09563842270061684  |  0.0 0.5\n",
      "9 35       |  1 0            | 35 9            |  0.09710610631132788  |  0.0 0.5\n",
      "9 36       |  1 0            | 36 9            |  0.09851341389111568  |  0.0 0.5\n",
      "9 37       |  1 0            | 37 9            |  0.09986446680101935  |  0.0 0.5\n",
      "9 38       |  1 0            | 38 9            |  0.10116300160878033  |  0.0 0.5\n",
      "9 39       |  1 0            | 39 9            |  0.10241241507894472  |  0.0 0.5\n",
      "9 40       |  1 0            | 40 9            |  0.10361580290251915  |  0.0 0.5\n",
      "9 41       |  1 0            | 41 9            |  0.10477599316918251  |  0.0 0.5\n",
      "9 42       |  1 0            | 42 9            |  0.10589557540425432  |  0.0 0.5\n",
      "9 43       |  1 0            | 43 9            |  0.10697692584795071  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 26.26181734059892 -- 23 black swan\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 2       |  4 1            | 2 0            |  7.0  |  0.033378282958236416 0.4916562039047883\n",
      "0 3       |  4 1            | 3 0            |  7.970528186972498  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481877  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 2            | 9 0            |  8.531222084185345  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 2            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 1            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 1            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 1            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 1            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  4 1            | 2 1            |  1.833016550000405  |  0.033378282958236416 0.4916562039047883\n",
      "1 3       |  4 1            | 3 1            |  2.8035447369729027  |  0.34989206720724864 0.4134085947484186\n",
      "1 4       |  4 0            | 4 1            |  3.6611541950537365  |  0.34989206720724864 0.4134085947484186\n",
      "1 5       |  4 0            | 5 1            |  4.1208384969515315  |  0.34989206720724864 0.4134085947484186\n",
      "1 6       |  4 0            | 6 1            |  4.463946303571863  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  4 0            | 7 1            |  4.731973151785933  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  4 0            | 8 1            |  4.948496368612144  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  4 2            | 9 1            |  4.102379127042834  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  4 2            | 10 1            |  5.279802118804913  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  4 1            | 11 1            |  5.4103739871620675  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  4 1            | 12 1            |  5.52420327801396  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  4 0            | 13 1            |  5.62457593142463  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  4 0            | 14 1            |  5.713946303571863  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  4 0            | 15 1            |  5.794188171798471  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  4 0            | 16 1            |  5.866759305049889  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  4 0            | 17 1            |  5.932812603072289  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  4 0            | 18 1            |  5.993273106175476  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  4 0            | 19 1            |  6.048892573117566  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  4 1            | 20 1            |  6.100288940308232  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  4 0            | 21 1            |  6.147975361709307  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  4 1            | 22 1            |  6.19238192378889  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  4 0            | 23 1            |  6.233872118021413  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  4 0            | 24 1            |  6.2727555002714155  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  4 0            | 25 1            |  6.309297535714574  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  4 0            | 26 1            |  6.34372733842422  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  4 0            | 27 1            |  6.3762438166653475  |  0.34989206720724864 0.4134085947484186\n",
      "1 28       |  4 0            | 28 1            |  6.40702059721427  |  0.34989206720724864 0.4134085947484186\n",
      "1 29       |  4 0            | 29 1            |  6.436210004840365  |  0.34989206720724864 0.4134085947484186\n",
      "1 30       |  4 0            | 30 1            |  6.463946303571863  |  0.34989206720724864 0.4134085947484186\n",
      "1 31       |  4 0            | 31 1            |  6.490348356013456  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 32       |  4 0            | 32 1            |  6.515521820079524  |  0.34989206720724864 0.4134085947484186\n",
      "1 33       |  4 0            | 33 1            |  6.539560975165067  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "2 4       |  1 0            | 4 2            |  0.1131471927654566  |  0.3165137842490122 0.4215255995031885\n",
      "2 5       |  1 0            | 5 2            |  0.1437928128919772  |  0.3165137842490122 0.4215255995031885\n",
      "2 6       |  1 0            | 6 2            |  0.16666666666666785  |  0.3165137842490122 0.4215255995031885\n",
      "2 7       |  1 0            | 7 2            |  0.18453512321427112  |  0.3165137842490122 0.4215255995031885\n",
      "2 8       |  1 0            | 8 2            |  0.19897000433601875  |  0.3165137842490122 0.4215255995031885\n",
      "2 13       |  1 0            | 13 2            |  0.24404197519018567  |  0.3165137842490122 0.4215255995031885\n",
      "2 14       |  1 0            | 14 2            |  0.25  |  0.3165137842490122 0.4215255995031885\n",
      "2 15       |  1 0            | 15 2            |  0.2553494578817741  |  0.3165137842490122 0.4215255995031885\n",
      "2 16       |  1 0            | 16 2            |  0.26018753343186773  |  0.3165137842490122 0.4215255995031885\n",
      "2 17       |  1 0            | 17 2            |  0.26459108663336295  |  0.3165137842490122 0.4215255995031885\n",
      "2 18       |  1 0            | 18 2            |  0.2686217868402423  |  0.3165137842490122 0.4215255995031885\n",
      "2 19       |  1 0            | 19 2            |  0.2723297513030474  |  0.3165137842490122 0.4215255995031885\n",
      "2 21       |  1 0            | 21 2            |  0.27893527054249745  |  0.3165137842490122 0.4215255995031885\n",
      "2 23       |  1 0            | 23 2            |  0.2846617209633031  |  0.3165137842490122 0.4215255995031885\n",
      "2 24       |  1 0            | 24 2            |  0.2872539464466364  |  0.3165137842490122 0.4215255995031885\n",
      "2 25       |  1 0            | 25 2            |  0.2896900821428474  |  0.3165137842490122 0.4215255995031885\n",
      "2 26       |  1 0            | 26 2            |  0.29198540232349046  |  0.3165137842490122 0.4215255995031885\n",
      "2 27       |  1 0            | 27 2            |  0.2941531675395659  |  0.3165137842490122 0.4215255995031885\n",
      "2 28       |  1 0            | 28 2            |  0.2962049529094948  |  0.3165137842490122 0.4215255995031885\n",
      "2 29       |  1 0            | 29 2            |  0.29815091341789923  |  0.3165137842490122 0.4215255995031885\n",
      "2 30       |  1 0            | 30 2            |  0.3000000000000007  |  0.3165137842490122 0.4215255995031885\n",
      "2 31       |  1 0            | 31 2            |  0.30176013682944003  |  0.3165137842490122 0.4215255995031885\n",
      "2 32       |  1 0            | 32 2            |  0.30343836776717836  |  0.3165137842490122 0.4215255995031885\n",
      "2 33       |  1 0            | 33 2            |  0.3050409781062129  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "3 4       |  1 0            | 4 3            |  0.04382375083885037  |  0.0 0.5\n",
      "3 5       |  1 0            | 5 3            |  0.07446937096537098  |  0.0 0.5\n",
      "3 6       |  1 0            | 6 3            |  0.09734322474006163  |  0.0 0.5\n",
      "3 7       |  1 0            | 7 3            |  0.1152116812876649  |  0.0 0.5\n",
      "3 8       |  1 0            | 8 3            |  0.12964656240941252  |  0.0 0.5\n",
      "3 13       |  1 0            | 13 3            |  0.17471853326357945  |  0.0 0.5\n",
      "3 14       |  1 0            | 14 3            |  0.18067655807339378  |  0.0 0.5\n",
      "3 15       |  1 0            | 15 3            |  0.18602601595516788  |  0.0 0.5\n",
      "3 16       |  1 0            | 16 3            |  0.1908640915052615  |  0.0 0.5\n",
      "3 17       |  1 0            | 17 3            |  0.19526764470675673  |  0.0 0.5\n",
      "3 18       |  1 0            | 18 3            |  0.19929834491363607  |  0.0 0.5\n",
      "3 19       |  1 0            | 19 3            |  0.20300630937644115  |  0.0 0.5\n",
      "3 21       |  1 0            | 21 3            |  0.20961182861589123  |  0.0 0.5\n",
      "3 23       |  1 0            | 23 3            |  0.2153382790366969  |  0.0 0.5\n",
      "3 24       |  1 0            | 24 3            |  0.21793050452003015  |  0.0 0.5\n",
      "3 25       |  1 0            | 25 3            |  0.2203666402162412  |  0.0 0.5\n",
      "3 26       |  1 0            | 26 3            |  0.22266196039688424  |  0.0 0.5\n",
      "3 27       |  1 0            | 27 3            |  0.22482972561295966  |  0.0 0.5\n",
      "3 28       |  1 0            | 28 3            |  0.22688151098288856  |  0.0 0.5\n",
      "3 29       |  1 0            | 29 3            |  0.228827471491293  |  0.0 0.5\n",
      "3 30       |  1 0            | 30 3            |  0.2306765580733945  |  0.0 0.5\n",
      "3 31       |  1 0            | 31 3            |  0.2324366949028338  |  0.0 0.5\n",
      "3 32       |  1 0            | 32 3            |  0.23411492584057214  |  0.0 0.5\n",
      "3 33       |  1 0            | 33 3            |  0.23571753617960667  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "9 2       |  2 1            | 2 9            |  0.4218703473642229  |  -0.3165137842490122 0.5784744004968115\n",
      "9 3       |  2 1            | 3 9            |  0.2832234635110069  |  0.0 0.5\n",
      "9 4       |  2 0            | 4 9            |  0.29336394274995925  |  0.0 0.5\n",
      "9 5       |  2 0            | 5 9            |  0.20142708237040452  |  0.0 0.5\n",
      "9 6       |  2 0            | 6 9            |  0.13280552104633614  |  0.0 0.5\n",
      "9 7       |  2 0            | 7 9            |  0.07920015140352277  |  0.0 0.5\n",
      "9 8       |  2 0            | 8 9            |  0.0358955080382799  |  0.0 0.5\n",
      "9 11       |  2 1            | 11 9            |  0.05648001567170624  |  0.0 0.5\n",
      "9 12       |  2 1            | 12 9            |  0.07924587384208337  |  0.0 0.5\n",
      "9 13       |  2 0            | 13 9            |  0.09932040452421731  |  0.0 0.5\n",
      "9 14       |  2 0            | 14 9            |  0.11719447895366386  |  0.0 0.5\n",
      "9 15       |  2 0            | 15 9            |  0.13324285259898616  |  0.0 0.5\n",
      "9 16       |  2 0            | 16 9            |  0.14775707924927062  |  0.0 0.5\n",
      "9 17       |  2 0            | 17 9            |  0.16096773885374915  |  0.0 0.5\n",
      "9 18       |  2 0            | 18 9            |  0.1730598394743872  |  0.0 0.5\n",
      "9 19       |  2 0            | 19 9            |  0.18418373286280598  |  0.0 0.5\n",
      "9 20       |  2 1            | 20 9            |  0.19446300630093916  |  0.0 0.5\n",
      "9 21       |  2 0            | 21 9            |  0.20400029058115265  |  0.0 0.5\n",
      "9 22       |  2 1            | 22 9            |  0.2128816029970686  |  0.0 0.5\n",
      "9 23       |  2 0            | 23 9            |  0.2211796418435732  |  0.0 0.5\n",
      "9 24       |  2 0            | 24 9            |  0.228956318293573  |  0.0 0.5\n",
      "9 25       |  2 0            | 25 9            |  0.2362647253822061  |  0.0 0.5\n",
      "9 26       |  2 0            | 26 9            |  0.24315068592413525  |  0.0 0.5\n",
      "9 27       |  2 0            | 27 9            |  0.24965398157236152  |  0.0 0.5\n",
      "9 28       |  2 0            | 28 9            |  0.25580933768214464  |  0.0 0.5\n",
      "9 29       |  2 0            | 29 9            |  0.2616472192073651  |  0.0 0.5\n",
      "9 30       |  2 0            | 30 9            |  0.26719447895366244  |  0.0 0.5\n",
      "9 31       |  2 0            | 31 9            |  0.27247488944198395  |  0.0 0.5\n",
      "9 32       |  2 0            | 32 9            |  0.2775095822551954  |  0.0 0.5\n",
      "9 33       |  2 0            | 33 9            |  0.2823174132723061  |  0.0 0.5\n",
      "----\n",
      "10 2       |  2 1            | 2 10            |  0.22105705434886858  |  -0.3165137842490122 0.5784744004968115\n",
      "10 3       |  2 1            | 3 10            |  0.15173361242226235  |  0.0 0.5\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 41.13206432531455 -- 24 emma\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 4       |  4 3            | 4 0            |  4.905177542123674  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233057  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590208  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.16062962785277  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 1            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226615  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.58494626954571  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736373  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137448  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449557  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699556  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142718  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 1            | 27 0            |  11.912297513093485  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642411  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441597  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593208  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  4 0            | 34 0            |  12.09860394574094  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 4       |  4 3            | 4 1            |  1.952615570695329  |  0.3407066065980212 0.41563784409136695\n",
      "1 5       |  4 0            | 5 1            |  4.120838496951535  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  4 0            | 6 1            |  4.463946303571859  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  4 0            | 7 1            |  4.731973151785937  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  4 0            | 8 1            |  4.94849636861214  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  4 0            | 9 1            |  5.12797390880354  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  4 0            | 10 1            |  5.279802118804909  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  4 0            | 11 1            |  5.4103739871620675  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  4 0            | 12 1            |  5.524203278013957  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  4 0            | 13 1            |  5.62457593142463  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  4 1            | 14 1            |  5.713946303571859  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  4 0            | 15 1            |  5.794188171798467  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  4 0            | 16 1            |  5.866759305049889  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  4 0            | 17 1            |  5.932812603072293  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  4 0            | 18 1            |  5.993273106175479  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  4 0            | 19 1            |  6.04889257311757  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 20       |  4 0            | 20 1            |  6.100288940308232  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  4 0            | 21 1            |  6.147975361709307  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  4 0            | 22 1            |  6.192381923788886  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  4 0            | 23 1            |  6.233872118021409  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  4 0            | 24 1            |  6.2727555002714155  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  4 0            | 25 1            |  6.3092975357145775  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  4 0            | 26 1            |  6.343727338424216  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  4 1            | 27 1            |  6.376243816665351  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  4 0            | 28 1            |  6.40702059721427  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  4 0            | 29 1            |  6.436210004840369  |  0.3407066065980212 0.41563784409136695\n",
      "1 30       |  4 0            | 30 1            |  6.463946303571866  |  0.3407066065980212 0.41563784409136695\n",
      "1 31       |  4 0            | 31 1            |  6.490348356013456  |  0.3407066065980212 0.41563784409136695\n",
      "1 32       |  4 0            | 32 1            |  6.5155218200795275  |  0.3407066065980212 0.41563784409136695\n",
      "1 33       |  4 0            | 33 1            |  6.539560975165067  |  0.3407066065980212 0.41563784409136695\n",
      "1 34       |  4 0            | 34 1            |  6.5625502493128  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "2 4       |  4 3            | 4 2            |  0.9051775421236741  |  0.3407066065980212 0.41563784409136695\n",
      "2 5       |  4 0            | 5 2            |  2.1568921933796616  |  0.3407066065980212 0.41563784409136695\n",
      "2 6       |  4 0            | 6 2            |  2.5  |  0.3407066065980212 0.41563784409136695\n",
      "2 7       |  4 0            | 7 2            |  2.7680268482140633  |  0.3407066065980212 0.41563784409136695\n",
      "2 8       |  4 0            | 8 2            |  2.984550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "2 9       |  4 0            | 9 2            |  3.1640276052316807  |  0.3407066065980212 0.41563784409136695\n",
      "2 10       |  4 0            | 10 2            |  3.31585581523305  |  0.3407066065980212 0.41563784409136695\n",
      "2 11       |  4 0            | 11 2            |  3.4464276835902012  |  0.3407066065980212 0.41563784409136695\n",
      "2 12       |  4 0            | 12 2            |  3.5602569744420975  |  0.3407066065980212 0.41563784409136695\n",
      "2 13       |  4 0            | 13 2            |  3.660629627852771  |  0.3407066065980212 0.41563784409136695\n",
      "2 14       |  4 1            | 14 2            |  3.75  |  0.3407066065980212 0.41563784409136695\n",
      "2 15       |  4 0            | 15 2            |  3.830241868226608  |  0.3407066065980212 0.41563784409136695\n",
      "2 16       |  4 0            | 16 2            |  3.902813001478023  |  0.3407066065980212 0.41563784409136695\n",
      "2 17       |  4 0            | 17 2            |  3.9688662995004265  |  0.3407066065980212 0.41563784409136695\n",
      "2 18       |  4 0            | 18 2            |  4.029326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "2 19       |  4 0            | 19 2            |  4.084946269545711  |  0.3407066065980212 0.41563784409136695\n",
      "2 20       |  4 0            | 20 2            |  4.136342636736373  |  0.3407066065980212 0.41563784409136695\n",
      "2 21       |  4 0            | 21 2            |  4.18402905813744  |  0.3407066065980212 0.41563784409136695\n",
      "2 22       |  4 0            | 22 2            |  4.228435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "2 23       |  4 0            | 23 2            |  4.26992581444955  |  0.3407066065980212 0.41563784409136695\n",
      "2 24       |  4 0            | 24 2            |  4.308809196699556  |  0.3407066065980212 0.41563784409136695\n",
      "2 25       |  4 0            | 25 2            |  4.345351232142711  |  0.3407066065980212 0.41563784409136695\n",
      "2 26       |  4 0            | 26 2            |  4.379781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "2 27       |  4 1            | 27 2            |  4.412297513093478  |  0.3407066065980212 0.41563784409136695\n",
      "2 28       |  4 0            | 28 2            |  4.443074293642411  |  0.3407066065980212 0.41563784409136695\n",
      "2 29       |  4 0            | 29 2            |  4.472263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "2 30       |  4 0            | 30 2            |  4.5  |  0.3407066065980212 0.41563784409136695\n",
      "2 31       |  4 0            | 31 2            |  4.526402052441597  |  0.3407066065980212 0.41563784409136695\n",
      "2 32       |  4 0            | 32 2            |  4.551575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "2 33       |  4 0            | 33 2            |  4.5756146715932005  |  0.3407066065980212 0.41563784409136695\n",
      "2 34       |  4 0            | 34 2            |  4.598603945740933  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "3 4       |  4 3            | 4 3            |  0.3505900067108172  |  0.3407066065980212 0.41563784409136695\n",
      "3 5       |  4 0            | 5 3            |  1.1170405644805612  |  0.3407066065980212 0.41563784409136695\n",
      "3 6       |  4 0            | 6 3            |  1.4601483711008996  |  0.3407066065980212 0.41563784409136695\n",
      "3 7       |  4 0            | 7 3            |  1.7281752193149629  |  0.3407066065980212 0.41563784409136695\n",
      "3 8       |  4 0            | 8 3            |  1.9446984361411808  |  0.3407066065980212 0.41563784409136695\n",
      "3 9       |  4 0            | 9 3            |  2.1241759763325803  |  0.3407066065980212 0.41563784409136695\n",
      "3 10       |  4 0            | 10 3            |  2.2760041863339495  |  0.3407066065980212 0.41563784409136695\n",
      "3 11       |  4 0            | 11 3            |  2.406576054691101  |  0.3407066065980212 0.41563784409136695\n",
      "3 12       |  4 0            | 12 3            |  2.52040534554299  |  0.3407066065980212 0.41563784409136695\n",
      "3 13       |  4 0            | 13 3            |  2.6207779989536633  |  0.3407066065980212 0.41563784409136695\n",
      "3 14       |  4 1            | 14 3            |  2.7101483711008996  |  0.3407066065980212 0.41563784409136695\n",
      "3 15       |  4 0            | 15 3            |  2.7903902393275075  |  0.3407066065980212 0.41563784409136695\n",
      "3 16       |  4 0            | 16 3            |  2.8629613725789227  |  0.3407066065980212 0.41563784409136695\n",
      "3 17       |  4 0            | 17 3            |  2.929014670601319  |  0.3407066065980212 0.41563784409136695\n",
      "3 18       |  4 0            | 18 3            |  2.9894751737045056  |  0.3407066065980212 0.41563784409136695\n",
      "3 19       |  4 0            | 19 3            |  3.045094640646603  |  0.3407066065980212 0.41563784409136695\n",
      "3 20       |  4 0            | 20 3            |  3.0964910078372654  |  0.3407066065980212 0.41563784409136695\n",
      "3 21       |  4 0            | 21 3            |  3.14417742923834  |  0.3407066065980212 0.41563784409136695\n",
      "3 22       |  4 0            | 22 3            |  3.1885839913179197  |  0.3407066065980212 0.41563784409136695\n",
      "3 23       |  4 0            | 23 3            |  3.23007418555045  |  0.3407066065980212 0.41563784409136695\n",
      "3 24       |  4 0            | 24 3            |  3.2689575678004488  |  0.3407066065980212 0.41563784409136695\n",
      "3 25       |  4 0            | 25 3            |  3.305499603243611  |  0.3407066065980212 0.41563784409136695\n",
      "3 26       |  4 0            | 26 3            |  3.3399294059532565  |  0.3407066065980212 0.41563784409136695\n",
      "3 27       |  4 1            | 27 3            |  3.372445884194377  |  0.3407066065980212 0.41563784409136695\n",
      "3 28       |  4 0            | 28 3            |  3.4032226647433035  |  0.3407066065980212 0.41563784409136695\n",
      "3 29       |  4 0            | 29 3            |  3.432412072369395  |  0.3407066065980212 0.41563784409136695\n",
      "3 30       |  4 0            | 30 3            |  3.4601483711008996  |  0.3407066065980212 0.41563784409136695\n",
      "3 31       |  4 0            | 31 3            |  3.4865504235424893  |  0.3407066065980212 0.41563784409136695\n",
      "3 32       |  4 0            | 32 3            |  3.5117238876085537  |  0.3407066065980212 0.41563784409136695\n",
      "3 33       |  4 0            | 33 3            |  3.5357630426941  |  0.3407066065980212 0.41563784409136695\n",
      "3 34       |  4 0            | 34 3            |  3.558752316841833  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "4 5       |  3 0            | 5 4            |  0.21451934088563718  |  0.0 0.5\n",
      "4 6       |  3 0            | 6 4            |  0.3746363173084575  |  0.0 0.5\n",
      "4 7       |  3 0            | 7 4            |  0.4997155131416946  |  0.0 0.5\n",
      "4 8       |  3 0            | 8 4            |  0.6007596809939244  |  0.0 0.5\n",
      "4 9       |  3 0            | 9 4            |  0.6845158664165751  |  0.0 0.5\n",
      "4 10       |  3 0            | 10 4            |  0.7553690310838874  |  0.0 0.5\n",
      "4 11       |  3 0            | 11 4            |  0.8163025696505528  |  0.0 0.5\n",
      "4 12       |  3 0            | 12 4            |  0.8694229053814411  |  0.0 0.5\n",
      "4 13       |  3 0            | 13 4            |  0.9162634769730857  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 14       |  3 1            | 14 4            |  0.9579696506417932  |  0.0 0.5\n",
      "4 15       |  3 0            | 15 4            |  0.9954158558142083  |  0.0 0.5\n",
      "4 16       |  3 0            | 16 4            |  1.0292823846648744  |  0.0 0.5\n",
      "4 17       |  3 0            | 17 4            |  1.0601072570753232  |  0.0 0.5\n",
      "4 18       |  3 0            | 18 4            |  1.0883221585234821  |  0.0 0.5\n",
      "4 19       |  3 0            | 19 4            |  1.1142779097631248  |  0.0 0.5\n",
      "4 20       |  3 0            | 20 4            |  1.138262881118763  |  0.0 0.5\n",
      "4 21       |  3 0            | 21 4            |  1.1605165444392682  |  0.0 0.5\n",
      "4 22       |  3 0            | 22 4            |  1.1812396067430697  |  0.0 0.5\n",
      "4 23       |  3 0            | 23 4            |  1.2006016973849185  |  0.0 0.5\n",
      "4 24       |  3 0            | 24 4            |  1.2187472757682514  |  0.0 0.5\n",
      "4 25       |  3 0            | 25 4            |  1.235800225641725  |  0.0 0.5\n",
      "4 26       |  3 0            | 26 4            |  1.2518674669062264  |  0.0 0.5\n",
      "4 27       |  3 1            | 27 4            |  1.2670418234187508  |  0.0 0.5\n",
      "4 28       |  3 0            | 28 4            |  1.281404321008253  |  0.0 0.5\n",
      "4 29       |  3 0            | 29 4            |  1.295026044567095  |  0.0 0.5\n",
      "4 30       |  3 0            | 30 4            |  1.3079696506417946  |  0.0 0.5\n",
      "4 31       |  3 0            | 31 4            |  1.3202906084478698  |  0.0 0.5\n",
      "4 32       |  3 0            | 32 4            |  1.3320382250120346  |  0.0 0.5\n",
      "4 33       |  3 0            | 33 4            |  1.3432564973852905  |  0.0 0.5\n",
      "4 34       |  3 0            | 34 4            |  1.3539848253209001  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 26.3180969887485 -- 25 mad max fury road\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.952561971428345  |  0.0 0.5\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.009185460609227425 0.4977036509934318\n",
      "0 3       |  4 3            | 3 0            |  4.554587535412864  |  0.033378282958236416 0.4916562039047883\n",
      "0 4       |  4 1            | 4 0            |  8.58406069871642  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379669  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.000000000000007  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214074  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040288  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231688  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233057  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590208  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442101  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852773  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.250000000000005  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226615  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478034  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500432  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603618  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.58494626954571  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736373  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.68402905813745  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217033  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449557  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699558  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142718  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852364  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093488  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642413  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268508  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.000000000000005  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441597  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507667  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 4       |  3 1            | 4 1            |  1.4644616780214967  |  0.34989206720724864 0.4134085947484186\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.34989206720724864 0.4134085947484186\n",
      "1 6       |  3 0            | 6 1            |  2.0831749416668757  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  3 0            | 7 1            |  2.2082541375001057  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749933  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  3 0            | 10 1            |  2.4639076554422985  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  3 0            | 11 1            |  2.524841194008971  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  3 0            | 12 1            |  2.577961529739852  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  3 0            | 15 1            |  2.7039544801726265  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  3 0            | 17 1            |  2.7686458814337414  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  3 0            | 18 1            |  2.796860782881893  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  3 0            | 19 1            |  2.822816534121536  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477181  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  3 0            | 22 1            |  2.889778231101488  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.34989206720724864 0.4134085947484186\n",
      "1 28       |  3 0            | 28 1            |  2.989942945366664  |  0.34989206720724864 0.4134085947484186\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.34989206720724864 0.4134085947484186\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.34989206720724864 0.4134085947484186\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.34989206720724864 0.4134085947484186\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "2 4       |  3 1            | 4 2            |  0.6788831565927502  |  0.3407066065980212 0.41563784409136695\n",
      "2 5       |  3 0            | 5 2            |  1.006549690243844  |  0.3407066065980212 0.41563784409136695\n",
      "2 6       |  3 0            | 6 2            |  1.1666666666666714  |  0.3407066065980212 0.41563784409136695\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624999014  |  0.3407066065980212 0.41563784409136695\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.3407066065980212 0.41563784409136695\n",
      "2 9       |  3 0            | 9 2            |  1.476546215774789  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10       |  3 0            | 10 2            |  1.5473993804420942  |  0.3407066065980212 0.41563784409136695\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087667  |  0.3407066065980212 0.41563784409136695\n",
      "2 12       |  3 0            | 12 2            |  1.661453254739648  |  0.3407066065980212 0.41563784409136695\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.3407066065980212 0.41563784409136695\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.3407066065980212 0.41563784409136695\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724223  |  0.3407066065980212 0.41563784409136695\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.3407066065980212 0.41563784409136695\n",
      "2 17       |  3 0            | 17 2            |  1.852137606433537  |  0.3407066065980212 0.41563784409136695\n",
      "2 18       |  3 0            | 18 2            |  1.880352507881689  |  0.3407066065980212 0.41563784409136695\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213316  |  0.3407066065980212 0.41563784409136695\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769769  |  0.3407066065980212 0.41563784409136695\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.3407066065980212 0.41563784409136695\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012836  |  0.3407066065980212 0.41563784409136695\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.3407066065980212 0.41563784409136695\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.3407066065980212 0.41563784409136695\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.3407066065980212 0.41563784409136695\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.3407066065980212 0.41563784409136695\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.3407066065980212 0.41563784409136695\n",
      "2 28       |  3 0            | 28 2            |  2.07343467036646  |  0.3407066065980212 0.41563784409136695\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.3407066065980212 0.41563784409136695\n",
      "2 30       |  3 0            | 30 2            |  2.1000000000000014  |  0.3407066065980212 0.41563784409136695\n",
      "2 31       |  3 0            | 31 2            |  2.1123209578060766  |  0.3407066065980212 0.41563784409136695\n",
      "2 32       |  3 0            | 32 2            |  2.1240685743702414  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "3 4       |  3 1            | 4 3            |  0.26294250503310934  |  0.3165137842490122 0.4215255995031885\n",
      "3 5       |  3 0            | 5 3            |  0.5212855967576004  |  0.3165137842490122 0.4215255995031885\n",
      "3 6       |  3 0            | 6 3            |  0.6814025731804207  |  0.3165137842490122 0.4215255995031885\n",
      "3 7       |  3 0            | 7 3            |  0.8064817690136508  |  0.3165137842490122 0.4215255995031885\n",
      "3 8       |  3 0            | 8 3            |  0.9075259368658877  |  0.3165137842490122 0.4215255995031885\n",
      "3 9       |  3 0            | 9 3            |  0.9912821222885384  |  0.3165137842490122 0.4215255995031885\n",
      "3 10       |  3 0            | 10 3            |  1.0621352869558436  |  0.3165137842490122 0.4215255995031885\n",
      "3 11       |  3 0            | 11 3            |  1.123068825522516  |  0.3165137842490122 0.4215255995031885\n",
      "3 12       |  3 0            | 12 3            |  1.1761891612533972  |  0.3165137842490122 0.4215255995031885\n",
      "3 13       |  3 0            | 13 3            |  1.223029732845049  |  0.3165137842490122 0.4215255995031885\n",
      "3 14       |  3 0            | 14 3            |  1.2647359065137564  |  0.3165137842490122 0.4215255995031885\n",
      "3 15       |  3 0            | 15 3            |  1.3021821116861716  |  0.3165137842490122 0.4215255995031885\n",
      "3 16       |  3 0            | 16 3            |  1.3360486405368377  |  0.3165137842490122 0.4215255995031885\n",
      "3 17       |  3 0            | 17 3            |  1.3668735129472864  |  0.3165137842490122 0.4215255995031885\n",
      "3 18       |  3 0            | 18 3            |  1.3950884143954383  |  0.3165137842490122 0.4215255995031885\n",
      "3 19       |  3 0            | 19 3            |  1.421044165635081  |  0.3165137842490122 0.4215255995031885\n",
      "3 20       |  3 0            | 20 3            |  1.4450291369907262  |  0.3165137842490122 0.4215255995031885\n",
      "3 21       |  3 0            | 21 3            |  1.4672828003112315  |  0.3165137842490122 0.4215255995031885\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.3165137842490122 0.4215255995031885\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568818  |  0.3165137842490122 0.4215255995031885\n",
      "3 24       |  3 0            | 24 3            |  1.5255135316402146  |  0.3165137842490122 0.4215255995031885\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136884  |  0.3165137842490122 0.4215255995031885\n",
      "3 26       |  3 0            | 26 3            |  1.5586337227781897  |  0.3165137842490122 0.4215255995031885\n",
      "3 27       |  3 0            | 27 3            |  1.573808079290714  |  0.3165137842490122 0.4215255995031885\n",
      "3 28       |  3 0            | 28 3            |  1.5881705768802092  |  0.3165137842490122 0.4215255995031885\n",
      "3 29       |  3 0            | 29 3            |  1.6017923004390582  |  0.3165137842490122 0.4215255995031885\n",
      "3 30       |  3 0            | 30 3            |  1.6147359065137579  |  0.3165137842490122 0.4215255995031885\n",
      "3 31       |  3 0            | 31 3            |  1.627056864319833  |  0.3165137842490122 0.4215255995031885\n",
      "3 32       |  3 0            | 32 3            |  1.6388044808839979  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "4 5       |  1 0            | 5 4            |  0.030645620126520612  |  0.0 0.5\n",
      "4 6       |  1 0            | 6 4            |  0.053519473901211256  |  0.0 0.5\n",
      "4 7       |  1 0            | 7 4            |  0.07138793044881453  |  0.0 0.5\n",
      "4 8       |  1 0            | 8 4            |  0.08582281157056215  |  0.0 0.5\n",
      "4 9       |  1 0            | 9 4            |  0.09778798091665664  |  0.0 0.5\n",
      "4 10       |  1 0            | 10 4            |  0.10790986158341198  |  0.0 0.5\n",
      "4 11       |  1 0            | 11 4            |  0.11661465280722538  |  0.0 0.5\n",
      "4 12       |  1 0            | 12 4            |  0.12420327219734872  |  0.0 0.5\n",
      "4 13       |  1 0            | 13 4            |  0.13089478242472907  |  0.0 0.5\n",
      "4 14       |  1 0            | 14 4            |  0.1368528072345434  |  0.0 0.5\n",
      "4 15       |  1 0            | 15 4            |  0.1422022651163175  |  0.0 0.5\n",
      "4 16       |  1 0            | 16 4            |  0.14704034066641114  |  0.0 0.5\n",
      "4 17       |  1 0            | 17 4            |  0.15144389386790635  |  0.0 0.5\n",
      "4 18       |  1 0            | 18 4            |  0.1554745940747857  |  0.0 0.5\n",
      "4 19       |  1 0            | 19 4            |  0.15918255853759078  |  0.0 0.5\n",
      "4 20       |  1 0            | 20 4            |  0.1626089830169697  |  0.0 0.5\n",
      "4 21       |  1 0            | 21 4            |  0.16578807777704085  |  0.0 0.5\n",
      "4 22       |  1 0            | 22 4            |  0.16874851524901047  |  0.0 0.5\n",
      "4 23       |  1 0            | 23 4            |  0.17151452819784652  |  0.0 0.5\n",
      "4 24       |  1 0            | 24 4            |  0.17410675368117978  |  0.0 0.5\n",
      "4 25       |  1 0            | 25 4            |  0.17654288937739082  |  0.0 0.5\n",
      "4 26       |  1 0            | 26 4            |  0.17883820955803387  |  0.0 0.5\n",
      "4 27       |  1 0            | 27 4            |  0.1810059747741093  |  0.0 0.5\n",
      "4 28       |  1 0            | 28 4            |  0.18305776014403818  |  0.0 0.5\n",
      "4 29       |  1 0            | 29 4            |  0.18500372065244264  |  0.0 0.5\n",
      "4 30       |  1 0            | 30 4            |  0.18685280723454412  |  0.0 0.5\n",
      "4 31       |  1 0            | 31 4            |  0.18861294406398343  |  0.0 0.5\n",
      "4 32       |  1 0            | 32 4            |  0.19029117500172177  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 16.247424626021168 -- 26 kung fury\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 1            | 1 0            |  5.166983449999595  |  0.34989206720724864 0.4134085947484186\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 1            | 7 0            |  9.583491724999798  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 1            | 8 0            |  9.785580060704262  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 1            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 1            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 1            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16       |  4 1            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 1            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 1            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.34989206720724864 0.4134085947484186\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901597  |  0.34989206720724864 0.4134085947484186\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598398  |  0.34989206720724864 0.4134085947484186\n",
      "0 37       |  4 0            | 37 0            |  12.16199460724695  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  1 0            | 2 1            |  0.13092975357145775  |  0.0 0.5\n",
      "1 3       |  1 0            | 3 1            |  0.20025319549806397  |  0.0 0.5\n",
      "1 4       |  1 0            | 4 1            |  0.2440769463369179  |  0.0 0.5\n",
      "1 5       |  1 0            | 5 1            |  0.27472256646343496  |  0.0 0.5\n",
      "1 6       |  1 0            | 6 1            |  0.2975964202381238  |  0.0 0.5\n",
      "1 9       |  1 0            | 9 1            |  0.3418649272535692  |  0.0 0.5\n",
      "1 10       |  1 0            | 10 1            |  0.3519868079203281  |  0.0 0.5\n",
      "1 11       |  1 0            | 11 1            |  0.36069159914413795  |  0.0 0.5\n",
      "1 12       |  1 0            | 12 1            |  0.36828021853426485  |  0.0 0.5\n",
      "1 18       |  1 0            | 18 1            |  0.39955154041169827  |  0.0 0.5\n",
      "1 20       |  1 0            | 20 1            |  0.40668592935388226  |  0.0 0.5\n",
      "1 21       |  1 0            | 21 1            |  0.4098650241139534  |  0.0 0.5\n",
      "1 22       |  1 0            | 22 1            |  0.4128254615859266  |  0.0 0.5\n",
      "1 23       |  1 0            | 23 1            |  0.41559147453476086  |  0.0 0.5\n",
      "1 24       |  1 0            | 24 1            |  0.41818370001809413  |  0.0 0.5\n",
      "1 25       |  1 0            | 25 1            |  0.42061983571430517  |  0.0 0.5\n",
      "1 26       |  1 0            | 26 1            |  0.4229151558949482  |  0.0 0.5\n",
      "1 27       |  1 0            | 27 1            |  0.42508292111102364  |  0.0 0.5\n",
      "1 28       |  1 0            | 28 1            |  0.42713470648095075  |  0.0 0.5\n",
      "1 29       |  1 0            | 29 1            |  0.42908066698935876  |  0.0 0.5\n",
      "1 30       |  1 0            | 30 1            |  0.43092975357145846  |  0.0 0.5\n",
      "1 31       |  1 0            | 31 1            |  0.4326898904008978  |  0.0 0.5\n",
      "1 32       |  1 0            | 32 1            |  0.43436812133863434  |  0.0 0.5\n",
      "1 33       |  1 0            | 33 1            |  0.43597073167767064  |  0.0 0.5\n",
      "1 34       |  1 0            | 34 1            |  0.4375033499541878  |  0.0 0.5\n",
      "1 35       |  1 0            | 35 1            |  0.4389710335648971  |  0.0 0.5\n",
      "1 36       |  1 0            | 36 1            |  0.4403783411446849  |  0.0 0.5\n",
      "1 37       |  1 0            | 37 1            |  0.44172939405458855  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "7 2       |  1 0            | 2 7            |  0.18453512321427112  |  0.0 0.5\n",
      "7 3       |  1 0            | 3 7            |  0.1152116812876649  |  0.0 0.5\n",
      "7 4       |  1 0            | 4 7            |  0.07138793044881098  |  0.0 0.5\n",
      "7 5       |  1 0            | 5 7            |  0.04074231032229392  |  0.0 0.5\n",
      "7 6       |  1 0            | 6 7            |  0.017868456547603273  |  0.0 0.5\n",
      "7 9       |  1 0            | 9 7            |  0.026400050467842107  |  0.0 0.5\n",
      "7 10       |  1 0            | 10 7            |  0.036521931134601004  |  0.0 0.5\n",
      "7 11       |  1 0            | 11 7            |  0.045226722358410854  |  0.0 0.5\n",
      "7 12       |  1 0            | 12 7            |  0.05281534174853775  |  0.0 0.5\n",
      "7 18       |  1 0            | 18 7            |  0.08408666362597117  |  0.0 0.5\n",
      "7 20       |  1 0            | 20 7            |  0.09122105256815516  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822632  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019949  |  0.0 0.5\n",
      "7 23       |  1 0            | 23 7            |  0.10012659774903199  |  0.0 0.5\n",
      "7 24       |  1 0            | 24 7            |  0.10271882323236525  |  0.0 0.5\n",
      "7 25       |  1 0            | 25 7            |  0.10515495892857629  |  0.0 0.5\n",
      "7 26       |  1 0            | 26 7            |  0.10745027910921934  |  0.0 0.5\n",
      "7 27       |  1 0            | 27 7            |  0.10961804432529476  |  0.0 0.5\n",
      "7 28       |  1 0            | 28 7            |  0.11166982969522365  |  0.0 0.5\n",
      "7 29       |  1 0            | 29 7            |  0.11361579020363166  |  0.0 0.5\n",
      "7 30       |  1 0            | 30 7            |  0.11546487678572959  |  0.0 0.5\n",
      "7 31       |  1 0            | 31 7            |  0.1172250136151689  |  0.0 0.5\n",
      "7 32       |  1 0            | 32 7            |  0.11890324455290724  |  0.0 0.5\n",
      "7 33       |  1 0            | 33 7            |  0.12050585489194177  |  0.0 0.5\n",
      "7 34       |  1 0            | 34 7            |  0.12203847316845895  |  0.0 0.5\n",
      "7 35       |  1 0            | 35 7            |  0.12350615677916821  |  0.0 0.5\n",
      "7 36       |  1 0            | 36 7            |  0.12491346435895778  |  0.0 0.5\n",
      "7 37       |  1 0            | 37 7            |  0.12626451726886145  |  0.0 0.5\n",
      "----\n",
      "8 2       |  1 0            | 2 8            |  0.19897000433601875  |  0.0 0.5\n",
      "8 3       |  1 0            | 3 8            |  0.12964656240941252  |  0.0 0.5\n",
      "8 4       |  1 0            | 4 8            |  0.08582281157056215  |  0.0 0.5\n",
      "8 5       |  1 0            | 5 8            |  0.05517719144404154  |  0.0 0.5\n",
      "8 6       |  1 0            | 6 8            |  0.032303337669350896  |  0.0 0.5\n",
      "8 9       |  1 0            | 9 8            |  0.011965169346094484  |  0.0 0.5\n",
      "8 10       |  1 0            | 10 8            |  0.02208705001284983  |  0.0 0.5\n",
      "8 11       |  1 0            | 11 8            |  0.03079184123666323  |  0.0 0.5\n",
      "8 12       |  1 0            | 12 8            |  0.03838046062678657  |  0.0 0.5\n",
      "8 18       |  1 0            | 18 8            |  0.06965178250422355  |  0.0 0.5\n",
      "8 20       |  1 0            | 20 8            |  0.07678617144640754  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.0799652662064787  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367844831  |  0.0 0.5\n",
      "8 23       |  1 0            | 23 8            |  0.08569171662728436  |  0.0 0.5\n",
      "8 24       |  1 0            | 24 8            |  0.08828394211061763  |  0.0 0.5\n",
      "8 25       |  1 0            | 25 8            |  0.09072007780682867  |  0.0 0.5\n",
      "8 26       |  1 0            | 26 8            |  0.09301539798747172  |  0.0 0.5\n",
      "8 27       |  1 0            | 27 8            |  0.09518316320354714  |  0.0 0.5\n",
      "8 28       |  1 0            | 28 8            |  0.09723494857347603  |  0.0 0.5\n",
      "8 29       |  1 0            | 29 8            |  0.09918090908188049  |  0.0 0.5\n",
      "8 30       |  1 0            | 30 8            |  0.10102999566398196  |  0.0 0.5\n",
      "8 31       |  1 0            | 31 8            |  0.10279013249342128  |  0.0 0.5\n",
      "8 32       |  1 0            | 32 8            |  0.10446836343115962  |  0.0 0.5\n",
      "8 33       |  1 0            | 33 8            |  0.10607097377019414  |  0.0 0.5\n",
      "8 34       |  1 0            | 34 8            |  0.10760359204671133  |  0.0 0.5\n",
      "8 35       |  1 0            | 35 8            |  0.10907127565742059  |  0.0 0.5\n",
      "8 36       |  1 0            | 36 8            |  0.1104785832372066  |  0.0 0.5\n",
      "8 37       |  1 0            | 37 8            |  0.11182963614711028  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 17.248996447822396 -- 27 mr smith goes to washington\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 2            | 1 0            |  4.4288429571425105  |  0.009185460609227425 0.4977036509934318\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.009185460609227425 0.4977036509934318\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.009185460609227425 0.4977036509934318\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481877  |  0.009185460609227425 0.4977036509934318\n",
      "0 5       |  4 1            | 5 0            |  9.013099380487692  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.000000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040285  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231684  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852769  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.250000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226612  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500428  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545707  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137446  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.87978103485236  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.000000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593208  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34       |  4 0            | 34 0            |  12.09860394574094  |  0.34989206720724864 0.4134085947484186\n",
      "0 35       |  4 0            | 35 0            |  12.1206191999016  |  0.34989206720724864 0.4134085947484186\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598402  |  0.34989206720724864 0.4134085947484186\n",
      "0 37       |  4 0            | 37 0            |  12.161994607246951  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  2 0            | 2 1            |  0.39278926071437326  |  0.0 0.5\n",
      "1 3       |  2 0            | 3 1            |  0.6007595864941955  |  0.0 0.5\n",
      "1 4       |  2 0            | 4 1            |  0.7322308390107466  |  0.0 0.5\n",
      "1 5       |  2 1            | 5 1            |  0.5494451329268735  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  2 0            | 6 1            |  0.8927892607143733  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  2 0            | 7 1            |  0.9463946303571866  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  2 0            | 8 1            |  0.9896992737224295  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  2 0            | 9 1            |  1.0255947817607094  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  2 0            | 10 1            |  1.055960423760986  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  2 0            | 11 1            |  1.0820747974324156  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  2 0            | 12 1            |  1.1048406556027928  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  2 0            | 13 1            |  1.1249151862849267  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  2 0            | 14 1            |  1.1427892607143733  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  2 0            | 15 1            |  1.1588376343596956  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  2 0            | 16 1            |  1.17335186100998  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  2 0            | 17 1            |  1.1865625206144585  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  2 0            | 18 1            |  1.1986546212350966  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  2 0            | 19 1            |  1.2097785146235154  |  0.3407066065980212 0.41563784409136695\n",
      "1 20       |  2 0            | 20 1            |  1.2200577880616486  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  2 0            | 21 1            |  1.229595072341862  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  2 0            | 22 1            |  1.238476384757778  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  2 0            | 23 1            |  1.2467744236042861  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  2 0            | 24 1            |  1.2545511000542842  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  2 0            | 25 1            |  1.2618595071429155  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  2 0            | 26 1            |  1.2687454676848446  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  2 0            | 27 1            |  1.2752487633330691  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  2 0            | 28 1            |  1.281404119442854  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  2 0            | 29 1            |  1.2872420009680745  |  0.3407066065980212 0.41563784409136695\n",
      "1 30       |  2 0            | 30 1            |  1.2927892607143736  |  0.3407066065980212 0.41563784409136695\n",
      "1 31       |  2 0            | 31 1            |  1.2980696712026916  |  0.3407066065980212 0.41563784409136695\n",
      "1 32       |  2 0            | 32 1            |  1.3031043640159048  |  0.3407066065980212 0.41563784409136695\n",
      "1 33       |  2 0            | 33 1            |  1.3079121950330137  |  0.3407066065980212 0.41563784409136695\n",
      "1 34       |  2 0            | 34 1            |  1.31251004986256  |  0.3407066065980212 0.41563784409136695\n",
      "1 35       |  2 0            | 35 1            |  1.316913100694693  |  0.3407066065980212 0.41563784409136695\n",
      "1 36       |  2 0            | 36 1            |  1.3211350234340529  |  0.3407066065980212 0.41563784409136695\n",
      "1 37       |  2 0            | 37 1            |  1.3251881821637639  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "5 2       |  1 0            | 2 5            |  0.1437928128919772  |  -0.3407066065980212 0.5843621559086332\n",
      "5 3       |  1 0            | 3 5            |  0.07446937096537098  |  -0.3407066065980212 0.5843621559086332\n",
      "5 4       |  1 0            | 4 5            |  0.03064562012651706  |  -0.3407066065980212 0.5843621559086332\n",
      "5 6       |  1 0            | 6 5            |  0.022873853774690645  |  0.0 0.5\n",
      "5 7       |  1 0            | 7 5            |  0.04074231032229392  |  0.0 0.5\n",
      "5 8       |  1 0            | 8 5            |  0.05517719144404154  |  0.0 0.5\n",
      "5 9       |  1 0            | 9 5            |  0.06714236079013602  |  0.0 0.5\n",
      "5 10       |  1 0            | 10 5            |  0.07726424145689137  |  0.0 0.5\n",
      "5 11       |  1 0            | 11 5            |  0.08596903268070477  |  0.0 0.5\n",
      "5 12       |  1 0            | 12 5            |  0.09355765207082811  |  0.0 0.5\n",
      "5 13       |  1 0            | 13 5            |  0.10024916229820846  |  0.0 0.5\n",
      "5 14       |  1 0            | 14 5            |  0.1062071871080228  |  0.0 0.5\n",
      "5 15       |  1 0            | 15 5            |  0.1115566449897969  |  0.0 0.5\n",
      "5 16       |  1 0            | 16 5            |  0.11639472053989053  |  0.0 0.5\n",
      "5 17       |  1 0            | 17 5            |  0.12079827374138574  |  0.0 0.5\n",
      "5 18       |  1 0            | 18 5            |  0.12482897394826509  |  0.0 0.5\n",
      "5 19       |  1 0            | 19 5            |  0.12853693841107017  |  0.0 0.5\n",
      "5 20       |  1 0            | 20 5            |  0.13196336289044908  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765052024  |  0.0 0.5\n",
      "5 22       |  1 0            | 22 5            |  0.13810289512248985  |  0.0 0.5\n",
      "5 23       |  1 0            | 23 5            |  0.1408689080713259  |  0.0 0.5\n",
      "5 24       |  1 0            | 24 5            |  0.14346113355465917  |  0.0 0.5\n",
      "5 25       |  1 0            | 25 5            |  0.1458972692508702  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 27       |  1 0            | 27 5            |  0.15036035464758868  |  0.0 0.5\n",
      "5 28       |  1 0            | 28 5            |  0.15241214001751757  |  0.0 0.5\n",
      "5 29       |  1 0            | 29 5            |  0.15435810052592203  |  0.0 0.5\n",
      "5 30       |  1 0            | 30 5            |  0.1562071871080235  |  0.0 0.5\n",
      "5 31       |  1 0            | 31 5            |  0.15796732393746282  |  0.0 0.5\n",
      "5 32       |  1 0            | 32 5            |  0.15964555487520116  |  0.0 0.5\n",
      "5 33       |  1 0            | 33 5            |  0.16124816521423568  |  0.0 0.5\n",
      "5 34       |  1 0            | 34 5            |  0.16278078349075287  |  0.0 0.5\n",
      "5 35       |  1 0            | 35 5            |  0.16424846710146213  |  0.0 0.5\n",
      "5 36       |  1 0            | 36 5            |  0.16565577468124815  |  0.0 0.5\n",
      "5 37       |  1 0            | 37 5            |  0.16700682759115182  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 16.463946303571863 -- 28 kill bill\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 2       |  3 0            | 2 0            |  3.5  |  0.3165137842490122 0.4215255995031885\n",
      "0 3       |  3 0            | 3 0            |  3.985264093486249  |  0.3165137842490122 0.4215255995031885\n",
      "0 4       |  3 0            | 4 0            |  4.292030349358209  |  0.3165137842490122 0.4215255995031885\n",
      "0 5       |  3 0            | 5 0            |  4.506549690243844  |  0.3165137842490122 0.4215255995031885\n",
      "0 6       |  3 0            | 6 0            |  4.666666666666668  |  0.3165137842490122 0.4215255995031885\n",
      "0 7       |  3 0            | 7 0            |  4.791745862499898  |  0.3165137842490122 0.4215255995031885\n",
      "0 8       |  3 0            | 8 0            |  4.892790030352131  |  0.3165137842490122 0.4215255995031885\n",
      "0 9       |  3 0            | 9 0            |  4.9765462157747855  |  0.3165137842490122 0.4215255995031885\n",
      "0 10       |  3 0            | 10 0            |  5.047399380442091  |  0.3165137842490122 0.4215255995031885\n",
      "0 11       |  3 0            | 11 0            |  5.108332919008761  |  0.3165137842490122 0.4215255995031885\n",
      "0 12       |  3 0            | 12 0            |  5.161453254739644  |  0.3165137842490122 0.4215255995031885\n",
      "0 13       |  3 0            | 13 0            |  5.208293826331291  |  0.3165137842490122 0.4215255995031885\n",
      "0 14       |  3 0            | 14 0            |  5.25  |  0.3165137842490122 0.4215255995031885\n",
      "0 15       |  3 0            | 15 0            |  5.287446205172419  |  0.3165137842490122 0.4215255995031885\n",
      "0 16       |  3 0            | 16 0            |  5.3213127340230795  |  0.3165137842490122 0.4215255995031885\n",
      "0 17       |  3 0            | 17 0            |  5.352137606433532  |  0.3165137842490122 0.4215255995031885\n",
      "0 18       |  3 0            | 18 0            |  5.380352507881685  |  0.3165137842490122 0.4215255995031885\n",
      "0 19       |  3 0            | 19 0            |  5.40630825912133  |  0.3165137842490122 0.4215255995031885\n",
      "0 20       |  3 0            | 20 0            |  5.4302932304769715  |  0.3165137842490122 0.4215255995031885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 21       |  3 0            | 21 0            |  5.452546893797473  |  0.3165137842490122 0.4215255995031885\n",
      "0 22       |  3 0            | 22 0            |  5.47326995610128  |  0.3165137842490122 0.4215255995031885\n",
      "0 23       |  3 0            | 23 0            |  5.4926320467431236  |  0.3165137842490122 0.4215255995031885\n",
      "0 24       |  3 0            | 24 0            |  5.510777625126458  |  0.3165137842490122 0.4215255995031885\n",
      "0 25       |  3 0            | 25 0            |  5.527830574999932  |  0.3165137842490122 0.4215255995031885\n",
      "0 26       |  3 0            | 26 0            |  5.543897816264433  |  0.3165137842490122 0.4215255995031885\n",
      "0 27       |  3 0            | 27 0            |  5.559072172776959  |  0.3165137842490122 0.4215255995031885\n",
      "0 28       |  3 0            | 28 0            |  5.573434670366456  |  0.3165137842490122 0.4215255995031885\n",
      "0 29       |  3 0            | 29 0            |  5.587056393925302  |  0.3165137842490122 0.4215255995031885\n",
      "0 30       |  3 1            | 30 0            |  5.6  |  0.3165137842490122 0.4215255995031885\n",
      "0 31       |  3 1            | 31 0            |  5.612320957806077  |  0.3165137842490122 0.4215255995031885\n",
      "0 32       |  3 1            | 32 0            |  5.624068574370241  |  0.3165137842490122 0.4215255995031885\n",
      "0 33       |  3 1            | 33 0            |  5.635286846743496  |  0.3165137842490122 0.4215255995031885\n",
      "0 34       |  3 1            | 34 0            |  5.646015174679103  |  0.3165137842490122 0.4215255995031885\n",
      "0 35       |  3 0            | 35 0            |  5.656288959954079  |  0.3165137842490122 0.4215255995031885\n",
      "0 36       |  3 0            | 36 0            |  5.666140113012586  |  0.3165137842490122 0.4215255995031885\n",
      "0 37       |  3 0            | 37 0            |  5.67559748338191  |  0.3165137842490122 0.4215255995031885\n",
      "0 38       |  3 0            | 38 0            |  5.684687227036246  |  0.3165137842490122 0.4215255995031885\n",
      "0 39       |  3 0            | 39 0            |  5.693433121327397  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "1 0       |  4 3            | 0 1            |  2.9525619714283415  |  0.0 0.5\n",
      "1 2       |  4 0            | 2 1            |  1.9639463035718627  |  0.3165137842490122 0.4215255995031885\n",
      "1 3       |  4 0            | 3 1            |  3.0037979324709667  |  0.3165137842490122 0.4215255995031885\n",
      "1 4       |  4 0            | 4 1            |  3.6611541950537383  |  0.3165137842490122 0.4215255995031885\n",
      "1 5       |  4 0            | 5 1            |  4.12083849695153  |  0.3165137842490122 0.4215255995031885\n",
      "1 6       |  4 0            | 6 1            |  4.463946303571863  |  0.3165137842490122 0.4215255995031885\n",
      "1 7       |  4 0            | 7 1            |  4.731973151785931  |  0.3165137842490122 0.4215255995031885\n",
      "1 8       |  4 0            | 8 1            |  4.948496368612144  |  0.3165137842490122 0.4215255995031885\n",
      "1 9       |  4 0            | 9 1            |  5.127973908803543  |  0.3165137842490122 0.4215255995031885\n",
      "1 10       |  4 0            | 10 1            |  5.2798021188049145  |  0.3165137842490122 0.4215255995031885\n",
      "1 11       |  4 0            | 11 1            |  5.4103739871620675  |  0.3165137842490122 0.4215255995031885\n",
      "1 12       |  4 0            | 12 1            |  5.52420327801396  |  0.3165137842490122 0.4215255995031885\n",
      "1 13       |  4 0            | 13 1            |  5.62457593142463  |  0.3165137842490122 0.4215255995031885\n",
      "1 14       |  4 0            | 14 1            |  5.713946303571863  |  0.3165137842490122 0.4215255995031885\n",
      "1 15       |  4 0            | 15 1            |  5.7941881717984725  |  0.3165137842490122 0.4215255995031885\n",
      "1 16       |  4 0            | 16 1            |  5.866759305049891  |  0.3165137842490122 0.4215255995031885\n",
      "1 17       |  4 0            | 17 1            |  5.932812603072289  |  0.3165137842490122 0.4215255995031885\n",
      "1 18       |  4 0            | 18 1            |  5.993273106175476  |  0.3165137842490122 0.4215255995031885\n",
      "1 19       |  4 0            | 19 1            |  6.048892573117568  |  0.3165137842490122 0.4215255995031885\n",
      "1 20       |  4 0            | 20 1            |  6.100288940308232  |  0.3165137842490122 0.4215255995031885\n",
      "1 21       |  4 0            | 21 1            |  6.147975361709307  |  0.3165137842490122 0.4215255995031885\n",
      "1 22       |  4 0            | 22 1            |  6.19238192378889  |  0.3165137842490122 0.4215255995031885\n",
      "1 23       |  4 0            | 23 1            |  6.233872118021415  |  0.3165137842490122 0.4215255995031885\n",
      "1 24       |  4 0            | 24 1            |  6.2727555002714155  |  0.3165137842490122 0.4215255995031885\n",
      "1 25       |  4 0            | 25 1            |  6.309297535714576  |  0.3165137842490122 0.4215255995031885\n",
      "1 26       |  4 0            | 26 1            |  6.34372733842422  |  0.3165137842490122 0.4215255995031885\n",
      "1 27       |  4 0            | 27 1            |  6.376243816665346  |  0.3165137842490122 0.4215255995031885\n",
      "1 28       |  4 0            | 28 1            |  6.40702059721427  |  0.3165137842490122 0.4215255995031885\n",
      "1 29       |  4 0            | 29 1            |  6.436210004840365  |  0.3165137842490122 0.4215255995031885\n",
      "1 30       |  4 1            | 30 1            |  6.463946303571863  |  0.3165137842490122 0.4215255995031885\n",
      "1 31       |  4 1            | 31 1            |  6.490348356013454  |  0.3165137842490122 0.4215255995031885\n",
      "1 32       |  4 1            | 32 1            |  6.515521820079524  |  0.3165137842490122 0.4215255995031885\n",
      "1 33       |  4 1            | 33 1            |  6.5395609751650685  |  0.3165137842490122 0.4215255995031885\n",
      "1 34       |  4 1            | 34 1            |  6.5625502493128  |  0.3165137842490122 0.4215255995031885\n",
      "1 35       |  4 0            | 35 1            |  6.58456550347346  |  0.3165137842490122 0.4215255995031885\n",
      "1 36       |  4 0            | 36 1            |  6.605675117170261  |  0.3165137842490122 0.4215255995031885\n",
      "1 37       |  4 0            | 37 1            |  6.625940910818812  |  0.3165137842490122 0.4215255995031885\n",
      "1 38       |  4 0            | 38 1            |  6.64541893293525  |  0.3165137842490122 0.4215255995031885\n",
      "1 39       |  4 0            | 39 1            |  6.664160134987712  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 25.37966851416904 -- 29 the godfather\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.952561971428345  |  0.3407066065980212 0.41563784409136695\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899108  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 2            | 4 0            |  7.357766313185504  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 1            | 5 0            |  9.013099380487695  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.000000000000004  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 2            | 7 0            |  8.21442147857126  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040287  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231686  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233055  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590207  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.0602569744421  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.16062962785277  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.250000000000004  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226613  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478032  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 1            | 17 0            |  11.46886629950043  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603617  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545709  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736371  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137448  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.72843562021703  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449556  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699556  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142717  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852362  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093487  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642411  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268506  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  12.000000000000004  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441595  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507665  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.07561467159321  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740942  |  0.3407066065980212 0.41563784409136695\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901602  |  0.3407066065980212 0.41563784409136695\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598403  |  0.3407066065980212 0.41563784409136695\n",
      "0 37       |  4 0            | 37 0            |  12.161994607246953  |  0.3407066065980212 0.41563784409136695\n",
      "0 38       |  4 0            | 38 0            |  12.18147262936339  |  0.3407066065980212 0.41563784409136695\n",
      "0 39       |  4 0            | 39 0            |  12.200213831415853  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 3       |  3 0            | 3 1            |  1.401772368486455  |  0.0 0.5\n",
      "1 4       |  3 2            | 4 1            |  0.9763077853476645  |  0.0 0.5\n",
      "1 5       |  3 1            | 5 1            |  1.6483353987806133  |  0.0 0.5\n",
      "1 6       |  3 0            | 6 1            |  2.0831749416668757  |  0.0 0.5\n",
      "1 7       |  3 2            | 7 1            |  1.261859507142919  |  0.0 0.5\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.0 0.5\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749933  |  0.0 0.5\n",
      "1 10       |  3 0            | 10 1            |  2.4639076554422985  |  0.0 0.5\n",
      "1 11       |  3 0            | 11 1            |  2.524841194008971  |  0.0 0.5\n",
      "1 12       |  3 0            | 12 1            |  2.577961529739852  |  0.0 0.5\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.0 0.5\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.0 0.5\n",
      "1 15       |  3 0            | 15 1            |  2.7039544801726265  |  0.0 0.5\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.0 0.5\n",
      "1 17       |  3 1            | 17 1            |  2.7686458814337414  |  0.0 0.5\n",
      "1 18       |  3 0            | 18 1            |  2.796860782881893  |  0.0 0.5\n",
      "1 19       |  3 0            | 19 1            |  2.822816534121536  |  0.0 0.5\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477181  |  0.0 0.5\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.0 0.5\n",
      "1 22       |  3 0            | 22 1            |  2.889778231101488  |  0.0 0.5\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.0 0.5\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.0 0.5\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.0 0.5\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.0 0.5\n",
      "1 28       |  3 0            | 28 1            |  2.989942945366664  |  0.0 0.5\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.0 0.5\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.0 0.5\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.0 0.5\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.0 0.5\n",
      "1 33       |  3 0            | 33 1            |  3.0517951217437016  |  0.0 0.5\n",
      "1 34       |  3 0            | 34 1            |  3.0625234496793112  |  0.0 0.5\n",
      "1 35       |  3 0            | 35 1            |  3.0727972349542867  |  0.0 0.5\n",
      "1 36       |  3 0            | 36 1            |  3.0826483880127924  |  0.0 0.5\n",
      "1 37       |  3 0            | 37 1            |  3.092105758382118  |  0.0 0.5\n",
      "1 38       |  3 0            | 38 1            |  3.101195502036454  |  0.0 0.5\n",
      "1 39       |  3 0            | 39 1            |  3.1099413963275993  |  0.0 0.5\n",
      "----\n",
      "2 3       |  3 0            | 3 2            |  0.48526409348625066  |  0.0 0.5\n",
      "2 4       |  3 2            | 4 2            |  0.4525887710618335  |  0.0 0.5\n",
      "2 5       |  3 1            | 5 2            |  0.8627568773518668  |  0.0 0.5\n",
      "2 6       |  3 0            | 6 2            |  1.1666666666666714  |  0.0 0.5\n",
      "2 7       |  3 2            | 7 2            |  0.738140492857088  |  0.0 0.5\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.0 0.5\n",
      "2 9       |  3 0            | 9 2            |  1.476546215774789  |  0.0 0.5\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420942  |  0.0 0.5\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087667  |  0.0 0.5\n",
      "2 12       |  3 0            | 12 2            |  1.661453254739648  |  0.0 0.5\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.0 0.5\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724223  |  0.0 0.5\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 1            | 17 2            |  1.852137606433537  |  0.0 0.5\n",
      "2 18       |  3 0            | 18 2            |  1.880352507881689  |  0.0 0.5\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213316  |  0.0 0.5\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769769  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012836  |  0.0 0.5\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "2 28       |  3 0            | 28 2            |  2.07343467036646  |  0.0 0.5\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.0 0.5\n",
      "2 30       |  3 0            | 30 2            |  2.1000000000000014  |  0.0 0.5\n",
      "2 31       |  3 0            | 31 2            |  2.1123209578060766  |  0.0 0.5\n",
      "2 32       |  3 0            | 32 2            |  2.1240685743702414  |  0.0 0.5\n",
      "2 33       |  3 0            | 33 2            |  2.1352868467434973  |  0.0 0.5\n",
      "2 34       |  3 0            | 34 2            |  2.146015174679107  |  0.0 0.5\n",
      "2 35       |  3 0            | 35 2            |  2.1562889599540824  |  0.0 0.5\n",
      "2 36       |  3 0            | 36 2            |  2.166140113012588  |  0.0 0.5\n",
      "2 37       |  3 0            | 37 2            |  2.175597483381914  |  0.0 0.5\n",
      "2 38       |  3 0            | 38 2            |  2.1846872270362496  |  0.0 0.5\n",
      "2 39       |  3 0            | 39 2            |  2.193433121327395  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "4 3       |  2 0            | 3 4            |  0.13147125251655112  |  0.0 0.5\n",
      "4 5       |  2 1            | 5 4            |  0.061291240253044776  |  0.0 0.5\n",
      "4 6       |  2 0            | 6 4            |  0.16055842170362666  |  0.0 0.5\n",
      "4 8       |  2 0            | 8 4            |  0.2574684347116829  |  0.0 0.5\n",
      "4 9       |  2 0            | 9 4            |  0.2933639427499628  |  0.0 0.5\n",
      "4 10       |  2 0            | 10 4            |  0.32372958475023594  |  0.0 0.5\n",
      "4 11       |  2 0            | 11 4            |  0.34984395842166904  |  0.0 0.5\n",
      "4 12       |  2 0            | 12 4            |  0.3726098165920462  |  0.0 0.5\n",
      "4 13       |  2 0            | 13 4            |  0.3926843472741801  |  0.0 0.5\n",
      "4 14       |  2 0            | 14 4            |  0.41055842170362666  |  0.0 0.5\n",
      "4 15       |  2 0            | 15 4            |  0.42660679534894896  |  0.0 0.5\n",
      "4 16       |  2 0            | 16 4            |  0.4411210219992334  |  0.0 0.5\n",
      "4 17       |  2 1            | 17 4            |  0.45433168160371196  |  0.0 0.5\n",
      "4 18       |  2 0            | 18 4            |  0.46642378222435  |  0.0 0.5\n",
      "4 19       |  2 0            | 19 4            |  0.4775476756127688  |  0.0 0.5\n",
      "4 20       |  2 0            | 20 4            |  0.48782694905090196  |  0.0 0.5\n",
      "4 21       |  2 0            | 21 4            |  0.49736423333111546  |  0.0 0.5\n",
      "4 22       |  2 0            | 22 4            |  0.5062455457470314  |  0.0 0.5\n",
      "4 23       |  2 0            | 23 4            |  0.514543584593536  |  0.0 0.5\n",
      "4 24       |  2 0            | 24 4            |  0.5223202610435358  |  0.0 0.5\n",
      "4 25       |  2 0            | 25 4            |  0.5296286681321689  |  0.0 0.5\n",
      "4 26       |  2 0            | 26 4            |  0.536514628674098  |  0.0 0.5\n",
      "4 27       |  2 0            | 27 4            |  0.5430179243223243  |  0.0 0.5\n",
      "4 28       |  2 0            | 28 4            |  0.5491732804321074  |  0.0 0.5\n",
      "4 29       |  2 0            | 29 4            |  0.5550111619573279  |  0.0 0.5\n",
      "4 30       |  2 0            | 30 4            |  0.5605584217036252  |  0.0 0.5\n",
      "4 31       |  2 0            | 31 4            |  0.5658388321919468  |  0.0 0.5\n",
      "4 32       |  2 0            | 32 4            |  0.5708735250051582  |  0.0 0.5\n",
      "4 33       |  2 0            | 33 4            |  0.5756813560222689  |  0.0 0.5\n",
      "4 34       |  2 0            | 34 4            |  0.5802792108518133  |  0.0 0.5\n",
      "4 35       |  2 0            | 35 4            |  0.5846822616839447  |  0.0 0.5\n",
      "4 36       |  2 0            | 36 4            |  0.5889041844233063  |  0.0 0.5\n",
      "4 37       |  2 0            | 37 4            |  0.5929573431530173  |  0.0 0.5\n",
      "4 38       |  2 0            | 38 4            |  0.5968529475763056  |  0.0 0.5\n",
      "4 39       |  2 0            | 39 4            |  0.600601187986797  |  0.0 0.5\n",
      "----\n",
      "5 3       |  1 0            | 3 5            |  0.07446937096537098  |  0.0 0.5\n",
      "5 6       |  1 0            | 6 5            |  0.022873853774690645  |  0.0 0.5\n",
      "5 8       |  1 0            | 8 5            |  0.05517719144404154  |  0.0 0.5\n",
      "5 9       |  1 0            | 9 5            |  0.06714236079013602  |  0.0 0.5\n",
      "5 10       |  1 0            | 10 5            |  0.07726424145689137  |  0.0 0.5\n",
      "5 11       |  1 0            | 11 5            |  0.08596903268070477  |  0.0 0.5\n",
      "5 12       |  1 0            | 12 5            |  0.09355765207082811  |  0.0 0.5\n",
      "5 13       |  1 0            | 13 5            |  0.10024916229820846  |  0.0 0.5\n",
      "5 14       |  1 0            | 14 5            |  0.1062071871080228  |  0.0 0.5\n",
      "5 15       |  1 0            | 15 5            |  0.1115566449897969  |  0.0 0.5\n",
      "5 16       |  1 0            | 16 5            |  0.11639472053989053  |  0.0 0.5\n",
      "5 18       |  1 0            | 18 5            |  0.12482897394826509  |  0.0 0.5\n",
      "5 19       |  1 0            | 19 5            |  0.12853693841107017  |  0.0 0.5\n",
      "5 20       |  1 0            | 20 5            |  0.13196336289044908  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765052024  |  0.0 0.5\n",
      "5 22       |  1 0            | 22 5            |  0.13810289512248985  |  0.0 0.5\n",
      "5 23       |  1 0            | 23 5            |  0.1408689080713259  |  0.0 0.5\n",
      "5 24       |  1 0            | 24 5            |  0.14346113355465917  |  0.0 0.5\n",
      "5 25       |  1 0            | 25 5            |  0.1458972692508702  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 27       |  1 0            | 27 5            |  0.15036035464758868  |  0.0 0.5\n",
      "5 28       |  1 0            | 28 5            |  0.15241214001751757  |  0.0 0.5\n",
      "5 29       |  1 0            | 29 5            |  0.15435810052592203  |  0.0 0.5\n",
      "5 30       |  1 0            | 30 5            |  0.1562071871080235  |  0.0 0.5\n",
      "5 31       |  1 0            | 31 5            |  0.15796732393746282  |  0.0 0.5\n",
      "5 32       |  1 0            | 32 5            |  0.15964555487520116  |  0.0 0.5\n",
      "5 33       |  1 0            | 33 5            |  0.16124816521423568  |  0.0 0.5\n",
      "5 34       |  1 0            | 34 5            |  0.16278078349075287  |  0.0 0.5\n",
      "5 35       |  1 0            | 35 5            |  0.16424846710146213  |  0.0 0.5\n",
      "5 36       |  1 0            | 36 5            |  0.16565577468124815  |  0.0 0.5\n",
      "5 37       |  1 0            | 37 5            |  0.16700682759115182  |  0.0 0.5\n",
      "5 38       |  1 0            | 38 5            |  0.16830536239891458  |  0.0 0.5\n",
      "5 39       |  1 0            | 39 5            |  0.16955477586908074  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "7 3       |  2 0            | 3 7            |  0.34563504386299115  |  0.0 0.5\n",
      "7 5       |  2 1            | 5 7            |  0.08148462064458784  |  0.0 0.5\n",
      "7 6       |  2 0            | 6 7            |  0.05360536964281337  |  0.0 0.5\n",
      "7 8       |  2 0            | 8 7            |  0.04330464336524287  |  0.0 0.5\n",
      "7 9       |  2 0            | 9 7            |  0.07920015140352277  |  0.0 0.5\n",
      "7 10       |  2 0            | 10 7            |  0.10956579340379591  |  0.0 0.5\n",
      "7 11       |  2 0            | 11 7            |  0.135680167075229  |  0.0 0.5\n",
      "7 12       |  2 0            | 12 7            |  0.15844602524560614  |  0.0 0.5\n",
      "7 13       |  2 0            | 13 7            |  0.17852055592774008  |  0.0 0.5\n",
      "7 14       |  2 0            | 14 7            |  0.19639463035718663  |  0.0 0.5\n",
      "7 15       |  2 0            | 15 7            |  0.21244300400250893  |  0.0 0.5\n",
      "7 16       |  2 0            | 16 7            |  0.22695723065279338  |  0.0 0.5\n",
      "7 17       |  2 1            | 17 7            |  0.24016789025727192  |  0.0 0.5\n",
      "7 18       |  2 0            | 18 7            |  0.25225999087790996  |  0.0 0.5\n",
      "7 19       |  2 0            | 19 7            |  0.26338388426632875  |  0.0 0.5\n",
      "7 20       |  2 0            | 20 7            |  0.2736631577044619  |  0.0 0.5\n",
      "7 21       |  2 0            | 21 7            |  0.2832004419846754  |  0.0 0.5\n",
      "7 22       |  2 0            | 22 7            |  0.29208175440059136  |  0.0 0.5\n",
      "7 23       |  2 0            | 23 7            |  0.30037979324709596  |  0.0 0.5\n",
      "7 24       |  2 0            | 24 7            |  0.30815646969709576  |  0.0 0.5\n",
      "7 25       |  2 0            | 25 7            |  0.3154648767857289  |  0.0 0.5\n",
      "7 26       |  2 0            | 26 7            |  0.322350837327658  |  0.0 0.5\n",
      "7 27       |  2 0            | 27 7            |  0.3288541329758843  |  0.0 0.5\n",
      "7 28       |  2 0            | 28 7            |  0.3350094890856674  |  0.0 0.5\n",
      "7 29       |  2 0            | 29 7            |  0.3408473706108879  |  0.0 0.5\n",
      "7 30       |  2 0            | 30 7            |  0.3463946303571852  |  0.0 0.5\n",
      "7 31       |  2 0            | 31 7            |  0.3516750408455067  |  0.0 0.5\n",
      "7 32       |  2 0            | 32 7            |  0.35670973365871816  |  0.0 0.5\n",
      "7 33       |  2 0            | 33 7            |  0.36151756467582885  |  0.0 0.5\n",
      "7 34       |  2 0            | 34 7            |  0.3661154195053733  |  0.0 0.5\n",
      "7 35       |  2 0            | 35 7            |  0.3705184703375046  |  0.0 0.5\n",
      "7 36       |  2 0            | 36 7            |  0.37474039307686624  |  0.0 0.5\n",
      "7 37       |  2 0            | 37 7            |  0.37879355180657726  |  0.0 0.5\n",
      "7 38       |  2 0            | 38 7            |  0.38268915622986555  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 39       |  2 0            | 39 7            |  0.3864373966403569  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.630929753571458 -- 30 pulp fiction\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 1            | 1 0            |  5.166983449999595  |  0.009185460609227425 0.4977036509934318\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 2            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 2            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  1 0            | 2 1            |  0.13092975357145775  |  0.3407066065980212 0.41563784409136695\n",
      "1 3       |  1 0            | 3 1            |  0.20025319549806397  |  0.3407066065980212 0.41563784409136695\n",
      "1 4       |  1 0            | 4 1            |  0.24407694633691612  |  0.3407066065980212 0.41563784409136695\n",
      "1 5       |  1 0            | 5 1            |  0.27472256646343496  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  1 0            | 6 1            |  0.2975964202381238  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  1 0            | 7 1            |  0.3154648767857289  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  1 0            | 8 1            |  0.3298997579074765  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  1 0            | 9 1            |  0.3418649272535692  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  1 0            | 10 1            |  0.3519868079203281  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  1 0            | 11 1            |  0.36069159914413795  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  1 0            | 12 1            |  0.36828021853426485  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  1 0            | 13 1            |  0.37497172876164164  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  1 0            | 14 1            |  0.38092975357145775  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  1 0            | 15 1            |  0.38627921145323185  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  1 0            | 16 1            |  0.3911172870033255  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  1 0            | 17 1            |  0.3955208402048189  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  1 0            | 18 1            |  0.39955154041169827  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  1 0            | 19 1            |  0.4032595048745051  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  1 0            | 22 1            |  0.4128254615859266  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  1 0            | 23 1            |  0.41559147453476086  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  1 0            | 24 1            |  0.41818370001809413  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  1 0            | 25 1            |  0.42061983571430517  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  1 0            | 26 1            |  0.4229151558949482  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  1 0            | 27 1            |  0.42508292111102364  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  1 0            | 28 1            |  0.42713470648095075  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  1 0            | 29 1            |  0.42908066698935876  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 17.15214588980331 -- 31 christmas vacation\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 1            | 1 0            |  5.1669834499995915  |  0.3165137842490122 0.4215255995031885\n",
      "0 2       |  4 1            | 2 0            |  6.9999999999999964  |  0.3165137842490122 0.4215255995031885\n",
      "0 3       |  4 0            | 3 0            |  8.5398516288991  |  0.3165137842490122 0.4215255995031885\n",
      "0 4       |  4 1            | 4 0            |  8.584060698716414  |  0.3165137842490122 0.4215255995031885\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379665  |  0.3165137842490122 0.4215255995031885\n",
      "0 6       |  4 1            | 6 0            |  9.33333333333333  |  0.3165137842490122 0.4215255995031885\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214067  |  0.3165137842490122 0.4215255995031885\n",
      "0 8       |  4 1            | 8 0            |  9.78558006070426  |  0.3165137842490122 0.4215255995031885\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231679  |  0.3165137842490122 0.4215255995031885\n",
      "0 10       |  4 1            | 10 0            |  10.81585581523305  |  0.3165137842490122 0.4215255995031885\n",
      "0 11       |  4 1            | 11 0            |  10.946427683590201  |  0.3165137842490122 0.4215255995031885\n",
      "0 12       |  4 1            | 12 0            |  11.060256974442094  |  0.3165137842490122 0.4215255995031885\n",
      "0 13       |  4 1            | 13 0            |  11.160629627852765  |  0.3165137842490122 0.4215255995031885\n",
      "0 14       |  4 1            | 14 0            |  11.249999999999996  |  0.3165137842490122 0.4215255995031885\n",
      "0 15       |  4 1            | 15 0            |  11.330241868226608  |  0.3165137842490122 0.4215255995031885\n",
      "0 16       |  4 1            | 16 0            |  11.402813001478027  |  0.3165137842490122 0.4215255995031885\n",
      "0 17       |  4 1            | 17 0            |  11.468866299500423  |  0.3165137842490122 0.4215255995031885\n",
      "0 18       |  4 1            | 18 0            |  11.52932680260361  |  0.3165137842490122 0.4215255995031885\n",
      "0 19       |  4 1            | 19 0            |  11.584946269545704  |  0.3165137842490122 0.4215255995031885\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736366  |  0.3165137842490122 0.4215255995031885\n",
      "0 21       |  4 0            | 21 0            |  11.68402905813744  |  0.3165137842490122 0.4215255995031885\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217024  |  0.3165137842490122 0.4215255995031885\n",
      "0 23       |  4 0            | 23 0            |  11.76992581444955  |  0.3165137842490122 0.4215255995031885\n",
      "0 24       |  4 0            | 24 0            |  11.80880919669955  |  0.3165137842490122 0.4215255995031885\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142711  |  0.3165137842490122 0.4215255995031885\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852355  |  0.3165137842490122 0.4215255995031885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27       |  4 0            | 27 0            |  11.912297513093481  |  0.3165137842490122 0.4215255995031885\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642404  |  0.3165137842490122 0.4215255995031885\n",
      "0 29       |  4 0            | 29 0            |  11.9722637012685  |  0.3165137842490122 0.4215255995031885\n",
      "0 30       |  4 0            | 30 0            |  11.999999999999996  |  0.3165137842490122 0.4215255995031885\n",
      "0 31       |  4 0            | 31 0            |  12.02640205244159  |  0.3165137842490122 0.4215255995031885\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507658  |  0.3165137842490122 0.4215255995031885\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593204  |  0.3165137842490122 0.4215255995031885\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740935  |  0.3165137842490122 0.4215255995031885\n",
      "0 35       |  4 1            | 35 0            |  12.120619199901595  |  0.3165137842490122 0.4215255995031885\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598396  |  0.3165137842490122 0.4215255995031885\n",
      "0 37       |  4 1            | 37 0            |  12.161994607246946  |  0.3165137842490122 0.4215255995031885\n",
      "0 38       |  4 0            | 38 0            |  12.181472629363384  |  0.3165137842490122 0.4215255995031885\n",
      "0 39       |  4 0            | 39 0            |  12.200213831415848  |  0.3165137842490122 0.4215255995031885\n",
      "0 40       |  4 0            | 40 0            |  12.218264648769464  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "1 3       |  1 0            | 3 1            |  0.20025319549806397  |  0.0 0.5\n",
      "1 5       |  1 0            | 5 1            |  0.2747225664634314  |  0.0 0.5\n",
      "1 7       |  1 0            | 7 1            |  0.3154648767857253  |  0.0 0.5\n",
      "1 9       |  1 0            | 9 1            |  0.34186492725356743  |  0.0 0.5\n",
      "1 20       |  1 0            | 20 1            |  0.4066859293538805  |  0.0 0.5\n",
      "1 21       |  1 0            | 21 1            |  0.40986502411395165  |  0.0 0.5\n",
      "1 22       |  1 0            | 22 1            |  0.4128254615859248  |  0.0 0.5\n",
      "1 23       |  1 0            | 23 1            |  0.4155914745347573  |  0.0 0.5\n",
      "1 24       |  1 0            | 24 1            |  0.4181837000180906  |  0.0 0.5\n",
      "1 25       |  1 0            | 25 1            |  0.42061983571430517  |  0.0 0.5\n",
      "1 26       |  1 0            | 26 1            |  0.4229151558949482  |  0.0 0.5\n",
      "1 27       |  1 0            | 27 1            |  0.4250829211110201  |  0.0 0.5\n",
      "1 28       |  1 0            | 28 1            |  0.427134706480949  |  0.0 0.5\n",
      "1 29       |  1 0            | 29 1            |  0.429080666989357  |  0.0 0.5\n",
      "1 30       |  1 0            | 30 1            |  0.4309297535714549  |  0.0 0.5\n",
      "1 31       |  1 0            | 31 1            |  0.43268989040089423  |  0.0 0.5\n",
      "1 32       |  1 0            | 32 1            |  0.43436812133863256  |  0.0 0.5\n",
      "1 33       |  1 0            | 33 1            |  0.43597073167767064  |  0.0 0.5\n",
      "1 34       |  1 0            | 34 1            |  0.4375033499541843  |  0.0 0.5\n",
      "1 36       |  1 0            | 36 1            |  0.4403783411446831  |  0.0 0.5\n",
      "1 38       |  1 0            | 38 1            |  0.44302792886234954  |  0.0 0.5\n",
      "1 39       |  1 0            | 39 1            |  0.44427734233251215  |  0.0 0.5\n",
      "1 40       |  1 0            | 40 1            |  0.4454807301560848  |  0.0 0.5\n",
      "----\n",
      "2 3       |  1 0            | 3 2            |  0.06932344192660622  |  0.0 0.5\n",
      "2 5       |  1 0            | 5 2            |  0.14379281289197365  |  0.0 0.5\n",
      "2 7       |  1 0            | 7 2            |  0.18453512321426757  |  0.0 0.5\n",
      "2 9       |  1 0            | 9 2            |  0.21093517368210968  |  0.0 0.5\n",
      "2 20       |  1 0            | 20 2            |  0.27575617578242273  |  0.0 0.5\n",
      "2 21       |  1 0            | 21 2            |  0.2789352705424939  |  0.0 0.5\n",
      "2 22       |  1 0            | 22 2            |  0.28189570801446706  |  0.0 0.5\n",
      "2 23       |  1 0            | 23 2            |  0.28466172096329956  |  0.0 0.5\n",
      "2 24       |  1 0            | 24 2            |  0.2872539464466328  |  0.0 0.5\n",
      "2 25       |  1 0            | 25 2            |  0.2896900821428474  |  0.0 0.5\n",
      "2 26       |  1 0            | 26 2            |  0.29198540232349046  |  0.0 0.5\n",
      "2 27       |  1 0            | 27 2            |  0.29415316753956233  |  0.0 0.5\n",
      "2 28       |  1 0            | 28 2            |  0.2962049529094912  |  0.0 0.5\n",
      "2 29       |  1 0            | 29 2            |  0.29815091341789923  |  0.0 0.5\n",
      "2 30       |  1 0            | 30 2            |  0.29999999999999716  |  0.0 0.5\n",
      "2 31       |  1 0            | 31 2            |  0.3017601368294365  |  0.0 0.5\n",
      "2 32       |  1 0            | 32 2            |  0.3034383677671748  |  0.0 0.5\n",
      "2 33       |  1 0            | 33 2            |  0.3050409781062129  |  0.0 0.5\n",
      "2 34       |  1 0            | 34 2            |  0.3065735963827265  |  0.0 0.5\n",
      "2 36       |  1 0            | 36 2            |  0.30944858757322535  |  0.0 0.5\n",
      "2 38       |  1 0            | 38 2            |  0.3120981752908918  |  0.0 0.5\n",
      "2 39       |  1 0            | 39 2            |  0.3133475887610544  |  0.0 0.5\n",
      "2 40       |  1 0            | 40 2            |  0.31455097658462705  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "4 3       |  1 0            | 3 4            |  0.043823750838853925  |  0.0 0.5\n",
      "4 5       |  1 0            | 5 4            |  0.03064562012651706  |  0.0 0.5\n",
      "4 7       |  1 0            | 7 4            |  0.07138793044881098  |  0.0 0.5\n",
      "4 9       |  1 0            | 9 4            |  0.09778798091665308  |  0.0 0.5\n",
      "4 20       |  1 0            | 20 4            |  0.16260898301696614  |  0.0 0.5\n",
      "4 21       |  1 0            | 21 4            |  0.1657880777770373  |  0.0 0.5\n",
      "4 22       |  1 0            | 22 4            |  0.16874851524900691  |  0.0 0.5\n",
      "4 23       |  1 0            | 23 4            |  0.17151452819784296  |  0.0 0.5\n",
      "4 24       |  1 0            | 24 4            |  0.17410675368117623  |  0.0 0.5\n",
      "4 25       |  1 0            | 25 4            |  0.17654288937738727  |  0.0 0.5\n",
      "4 26       |  1 0            | 26 4            |  0.17883820955803031  |  0.0 0.5\n",
      "4 27       |  1 0            | 27 4            |  0.18100597477410574  |  0.0 0.5\n",
      "4 28       |  1 0            | 28 4            |  0.18305776014403463  |  0.0 0.5\n",
      "4 29       |  1 0            | 29 4            |  0.18500372065243909  |  0.0 0.5\n",
      "4 30       |  1 0            | 30 4            |  0.18685280723454056  |  0.0 0.5\n",
      "4 31       |  1 0            | 31 4            |  0.18861294406397988  |  0.0 0.5\n",
      "4 32       |  1 0            | 32 4            |  0.19029117500171822  |  0.0 0.5\n",
      "4 33       |  1 0            | 33 4            |  0.19189378534075274  |  0.0 0.5\n",
      "4 34       |  1 0            | 34 4            |  0.19342640361726993  |  0.0 0.5\n",
      "4 36       |  1 0            | 36 4            |  0.1963013948077652  |  0.0 0.5\n",
      "4 38       |  1 0            | 38 4            |  0.19895098252543164  |  0.0 0.5\n",
      "4 39       |  1 0            | 39 4            |  0.2002003959955978  |  0.0 0.5\n",
      "4 40       |  1 0            | 40 4            |  0.20140378381917046  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "6 3       |  1 0            | 3 6            |  0.09734322474006163  |  0.0 0.5\n",
      "6 5       |  1 0            | 5 6            |  0.022873853774690645  |  0.0 0.5\n",
      "6 7       |  1 0            | 7 6            |  0.017868456547603273  |  0.0 0.5\n",
      "6 9       |  1 0            | 9 6            |  0.04426850701544538  |  0.0 0.5\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 23       |  1 0            | 23 6            |  0.11799505429663526  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 27       |  1 0            | 27 6            |  0.12748650087289803  |  0.0 0.5\n",
      "6 28       |  1 0            | 28 6            |  0.12953828624282693  |  0.0 0.5\n",
      "6 29       |  1 0            | 29 6            |  0.13148424675123138  |  0.0 0.5\n",
      "6 30       |  1 0            | 30 6            |  0.13333333333333286  |  0.0 0.5\n",
      "6 31       |  1 0            | 31 6            |  0.13509347016277218  |  0.0 0.5\n",
      "6 32       |  1 0            | 32 6            |  0.1367717011005105  |  0.0 0.5\n",
      "6 33       |  1 0            | 33 6            |  0.13837431143954504  |  0.0 0.5\n",
      "6 34       |  1 0            | 34 6            |  0.13990692971606222  |  0.0 0.5\n",
      "6 36       |  1 0            | 36 6            |  0.1427819209065575  |  0.0 0.5\n",
      "6 38       |  1 0            | 38 6            |  0.14543150862422394  |  0.0 0.5\n",
      "6 39       |  1 0            | 39 6            |  0.1466809220943901  |  0.0 0.5\n",
      "6 40       |  1 0            | 40 6            |  0.14788430991796275  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "8 3       |  1 0            | 3 8            |  0.12964656240941252  |  0.0 0.5\n",
      "8 5       |  1 0            | 5 8            |  0.05517719144404154  |  0.0 0.5\n",
      "8 7       |  1 0            | 7 8            |  0.014434881121747623  |  0.0 0.5\n",
      "8 9       |  1 0            | 9 8            |  0.011965169346094484  |  0.0 0.5\n",
      "8 20       |  1 0            | 20 8            |  0.07678617144640754  |  0.0 0.5\n",
      "8 21       |  1 0            | 21 8            |  0.0799652662064787  |  0.0 0.5\n",
      "8 22       |  1 0            | 22 8            |  0.08292570367844831  |  0.0 0.5\n",
      "8 23       |  1 0            | 23 8            |  0.08569171662728436  |  0.0 0.5\n",
      "8 24       |  1 0            | 24 8            |  0.08828394211061763  |  0.0 0.5\n",
      "8 25       |  1 0            | 25 8            |  0.09072007780682867  |  0.0 0.5\n",
      "8 26       |  1 0            | 26 8            |  0.09301539798747172  |  0.0 0.5\n",
      "8 27       |  1 0            | 27 8            |  0.09518316320354714  |  0.0 0.5\n",
      "8 28       |  1 0            | 28 8            |  0.09723494857347603  |  0.0 0.5\n",
      "8 29       |  1 0            | 29 8            |  0.09918090908188049  |  0.0 0.5\n",
      "8 30       |  1 0            | 30 8            |  0.10102999566398196  |  0.0 0.5\n",
      "8 31       |  1 0            | 31 8            |  0.10279013249342128  |  0.0 0.5\n",
      "8 32       |  1 0            | 32 8            |  0.10446836343115962  |  0.0 0.5\n",
      "8 33       |  1 0            | 33 8            |  0.10607097377019414  |  0.0 0.5\n",
      "8 34       |  1 0            | 34 8            |  0.10760359204671133  |  0.0 0.5\n",
      "8 36       |  1 0            | 36 8            |  0.1104785832372066  |  0.0 0.5\n",
      "8 38       |  1 0            | 38 8            |  0.11312817095487304  |  0.0 0.5\n",
      "8 39       |  1 0            | 39 8            |  0.1143775844250392  |  0.0 0.5\n",
      "8 40       |  1 0            | 40 8            |  0.11558097224861186  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 31.751390722406107 -- 32 psycho\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2       |  4 3            | 2 0            |  4.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 1            | 3 0            |  7.970528186972494  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 3            | 4 0            |  4.905177542123667  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379662  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 1            | 6 0            |  9.333333333333332  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 1            | 7 0            |  9.583491724999792  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.81585581523305  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590201  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852764  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226608  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478023  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545704  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.636342636736366  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.68402905813744  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 1            | 23 0            |  11.76992581444955  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.80880919669955  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142711  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093478  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 2       |  4 3            | 2 1            |  1.047438028571655  |  0.3407066065980212 0.41563784409136695\n",
      "1 3       |  4 1            | 3 1            |  2.8035447369729027  |  0.3407066065980212 0.41563784409136695\n",
      "1 4       |  4 3            | 4 1            |  1.9526155706953219  |  0.3407066065980212 0.41563784409136695\n",
      "1 5       |  4 0            | 5 1            |  4.120838496951528  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  4 1            | 6 1            |  4.166349883333734  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  4 1            | 7 1            |  4.416508275000201  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  4 0            | 8 1            |  4.94849636861214  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  4 0            | 9 1            |  5.12797390880354  |  0.3407066065980212 0.41563784409136695\n",
      "1 10       |  4 0            | 10 1            |  5.279802118804909  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  4 0            | 11 1            |  5.4103739871620675  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  4 0            | 12 1            |  5.524203278013957  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  4 0            | 13 1            |  5.62457593142463  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  4 0            | 14 1            |  5.713946303571859  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  4 0            | 15 1            |  5.794188171798467  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  4 0            | 16 1            |  5.866759305049889  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  4 0            | 17 1            |  5.932812603072286  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  4 0            | 18 1            |  5.993273106175472  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  4 0            | 19 1            |  6.048892573117563  |  0.3407066065980212 0.41563784409136695\n",
      "1 20       |  4 0            | 20 1            |  6.100288940308232  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  4 0            | 21 1            |  6.147975361709307  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  4 0            | 22 1            |  6.192381923788886  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  4 1            | 23 1            |  6.233872118021409  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  4 0            | 24 1            |  6.2727555002714155  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  4 0            | 25 1            |  6.30929753571457  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  4 0            | 26 1            |  6.343727338424216  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  4 0            | 27 1            |  6.376243816665344  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "2 3       |  3 1            | 3 2            |  0.41594065155963733  |  0.0 0.5\n",
      "2 5       |  3 0            | 5 2            |  1.006549690243844  |  0.0 0.5\n",
      "2 6       |  3 1            | 6 2            |  0.9999999999999964  |  0.0 0.5\n",
      "2 7       |  3 1            | 7 2            |  1.1072107392856232  |  0.0 0.5\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.0 0.5\n",
      "2 9       |  3 0            | 9 2            |  1.476546215774782  |  0.0 0.5\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420871  |  0.0 0.5\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087596  |  0.0 0.5\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396408  |  0.0 0.5\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.0 0.5\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724151  |  0.0 0.5\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 0            | 17 2            |  1.85213760643353  |  0.0 0.5\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816818  |  0.0 0.5\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213245  |  0.0 0.5\n",
      "2 20       |  3 0            | 20 2            |  1.9302932304769698  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012765  |  0.0 0.5\n",
      "2 23       |  3 1            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "----\n",
      "3 5       |  1 0            | 5 3            |  0.07446937096536743  |  0.0 0.5\n",
      "3 8       |  1 0            | 8 3            |  0.12964656240941252  |  0.0 0.5\n",
      "3 9       |  1 0            | 9 3            |  0.14161173175550346  |  0.0 0.5\n",
      "3 10       |  1 0            | 10 3            |  0.15173361242226235  |  0.0 0.5\n",
      "3 11       |  1 0            | 11 3            |  0.16043840364607576  |  0.0 0.5\n",
      "3 12       |  1 0            | 12 3            |  0.16802702303619554  |  0.0 0.5\n",
      "3 13       |  1 0            | 13 3            |  0.17471853326357945  |  0.0 0.5\n",
      "3 14       |  1 0            | 14 3            |  0.18067655807339378  |  0.0 0.5\n",
      "3 15       |  1 0            | 15 3            |  0.18602601595516433  |  0.0 0.5\n",
      "3 16       |  1 0            | 16 3            |  0.1908640915052615  |  0.0 0.5\n",
      "3 17       |  1 0            | 17 3            |  0.19526764470675317  |  0.0 0.5\n",
      "3 18       |  1 0            | 18 3            |  0.19929834491363607  |  0.0 0.5\n",
      "3 19       |  1 0            | 19 3            |  0.20300630937644115  |  0.0 0.5\n",
      "3 20       |  1 0            | 20 3            |  0.20643273385582006  |  0.0 0.5\n",
      "3 21       |  1 0            | 21 3            |  0.20961182861589123  |  0.0 0.5\n",
      "3 22       |  1 0            | 22 3            |  0.21257226608786084  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 24       |  1 0            | 24 3            |  0.2179305045200266  |  0.0 0.5\n",
      "3 25       |  1 0            | 25 3            |  0.2203666402162412  |  0.0 0.5\n",
      "3 26       |  1 0            | 26 3            |  0.22266196039688424  |  0.0 0.5\n",
      "3 27       |  1 0            | 27 3            |  0.2248297256129561  |  0.0 0.5\n",
      "----\n",
      "4 3       |  3 1            | 3 4            |  0.26294250503310934  |  0.0 0.5\n",
      "4 5       |  3 0            | 5 4            |  0.21451934088563362  |  0.0 0.5\n",
      "4 6       |  3 1            | 6 4            |  0.3211168434072498  |  0.0 0.5\n",
      "4 7       |  3 1            | 7 4            |  0.42832758269287297  |  0.0 0.5\n",
      "4 8       |  3 0            | 8 4            |  0.6007596809939209  |  0.0 0.5\n",
      "4 9       |  3 0            | 9 4            |  0.6845158664165751  |  0.0 0.5\n",
      "4 10       |  3 0            | 10 4            |  0.7553690310838803  |  0.0 0.5\n",
      "4 11       |  3 0            | 11 4            |  0.8163025696505528  |  0.0 0.5\n",
      "4 12       |  3 0            | 12 4            |  0.869422905381434  |  0.0 0.5\n",
      "4 13       |  3 0            | 13 4            |  0.9162634769730822  |  0.0 0.5\n",
      "4 14       |  3 0            | 14 4            |  0.9579696506417896  |  0.0 0.5\n",
      "4 15       |  3 0            | 15 4            |  0.9954158558142083  |  0.0 0.5\n",
      "4 16       |  3 0            | 16 4            |  1.0292823846648709  |  0.0 0.5\n",
      "4 17       |  3 0            | 17 4            |  1.0601072570753232  |  0.0 0.5\n",
      "4 18       |  3 0            | 18 4            |  1.088322158523475  |  0.0 0.5\n",
      "4 19       |  3 0            | 19 4            |  1.1142779097631177  |  0.0 0.5\n",
      "4 20       |  3 0            | 20 4            |  1.138262881118763  |  0.0 0.5\n",
      "4 21       |  3 0            | 21 4            |  1.1605165444392647  |  0.0 0.5\n",
      "4 22       |  3 0            | 22 4            |  1.1812396067430697  |  0.0 0.5\n",
      "4 23       |  3 1            | 23 4            |  1.200601697384915  |  0.0 0.5\n",
      "4 24       |  3 0            | 24 4            |  1.2187472757682478  |  0.0 0.5\n",
      "4 25       |  3 0            | 25 4            |  1.2358002256417215  |  0.0 0.5\n",
      "4 26       |  3 0            | 26 4            |  1.2518674669062229  |  0.0 0.5\n",
      "4 27       |  3 0            | 27 4            |  1.2670418234187473  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "6 5       |  1 0            | 5 6            |  0.022873853774690645  |  0.0 0.5\n",
      "6 8       |  1 0            | 8 6            |  0.032303337669350896  |  0.0 0.5\n",
      "6 9       |  1 0            | 9 6            |  0.04426850701544538  |  0.0 0.5\n",
      "6 10       |  1 0            | 10 6            |  0.054390387682200725  |  0.0 0.5\n",
      "6 11       |  1 0            | 11 6            |  0.06309517890601413  |  0.0 0.5\n",
      "6 12       |  1 0            | 12 6            |  0.07068379829613747  |  0.0 0.5\n",
      "6 13       |  1 0            | 13 6            |  0.07737530852351782  |  0.0 0.5\n",
      "6 14       |  1 0            | 14 6            |  0.08333333333333215  |  0.0 0.5\n",
      "6 15       |  1 0            | 15 6            |  0.08868279121510625  |  0.0 0.5\n",
      "6 16       |  1 0            | 16 6            |  0.09352086676519988  |  0.0 0.5\n",
      "6 17       |  1 0            | 17 6            |  0.0979244199666951  |  0.0 0.5\n",
      "6 18       |  1 0            | 18 6            |  0.10195512017357444  |  0.0 0.5\n",
      "6 19       |  1 0            | 19 6            |  0.10566308463637952  |  0.0 0.5\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 27       |  1 0            | 27 6            |  0.12748650087289803  |  0.0 0.5\n",
      "----\n",
      "7 5       |  1 0            | 5 7            |  0.04074231032229392  |  0.0 0.5\n",
      "7 8       |  1 0            | 8 7            |  0.014434881121747623  |  0.0 0.5\n",
      "7 9       |  1 0            | 9 7            |  0.026400050467842107  |  0.0 0.5\n",
      "7 10       |  1 0            | 10 7            |  0.03652193113459745  |  0.0 0.5\n",
      "7 11       |  1 0            | 11 7            |  0.045226722358410854  |  0.0 0.5\n",
      "7 12       |  1 0            | 12 7            |  0.052815341748534195  |  0.0 0.5\n",
      "7 13       |  1 0            | 13 7            |  0.05950685197591454  |  0.0 0.5\n",
      "7 14       |  1 0            | 14 7            |  0.06546487678572888  |  0.0 0.5\n",
      "7 15       |  1 0            | 15 7            |  0.07081433466750298  |  0.0 0.5\n",
      "7 16       |  1 0            | 16 7            |  0.07565241021759661  |  0.0 0.5\n",
      "7 17       |  1 0            | 17 7            |  0.08005596341909182  |  0.0 0.5\n",
      "7 18       |  1 0            | 18 7            |  0.08408666362597117  |  0.0 0.5\n",
      "7 19       |  1 0            | 19 7            |  0.08779462808877625  |  0.0 0.5\n",
      "7 20       |  1 0            | 20 7            |  0.09122105256815516  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822632  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019594  |  0.0 0.5\n",
      "7 24       |  1 0            | 24 7            |  0.10271882323236525  |  0.0 0.5\n",
      "7 25       |  1 0            | 25 7            |  0.10515495892857629  |  0.0 0.5\n",
      "7 26       |  1 0            | 26 7            |  0.10745027910921934  |  0.0 0.5\n",
      "7 27       |  1 0            | 27 7            |  0.10961804432529476  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 33 life is beautiful\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.0 0.5\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.3407066065980212 0.41563784409136695\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901597  |  0.3407066065980212 0.41563784409136695\n",
      "0 36       |  4 0            | 36 0            |  12.141728813598398  |  0.3407066065980212 0.41563784409136695\n",
      "0 37       |  4 0            | 37 0            |  12.16199460724695  |  0.3407066065980212 0.41563784409136695\n",
      "0 38       |  4 0            | 38 0            |  12.181472629363387  |  0.3407066065980212 0.41563784409136695\n",
      "0 39       |  4 0            | 39 0            |  12.20021383141585  |  0.3407066065980212 0.41563784409136695\n",
      "0 40       |  4 0            | 40 0            |  12.218264648769466  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 21.70783539347981 -- 34 dark knight\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 6       |  2 0            | 6 0            |  2.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  2 0            | 7 0            |  2.053605369642817  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  2 0            | 8 0            |  2.0969100130080562  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  2 0            | 9 0            |  2.132805521046336  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  2 0            | 11 0            |  2.189285536718039  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  2 0            | 12 0            |  2.2120513948884195  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  2 0            | 13 0            |  2.232125925570557  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  2 0            | 14 0            |  2.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  2 0            | 15 0            |  2.266048373645326  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  2 0            | 16 0            |  2.280562600295603  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  2 0            | 17 0            |  2.2937732599000853  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  2 0            | 19 0            |  2.316989253909142  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  2 0            | 20 0            |  2.3272685273472717  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  2 0            | 21 0            |  2.3368058116274923  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  2 0            | 22 0            |  2.3456871240434083  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  2 0            | 23 0            |  2.353985162889913  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  2 0            | 24 0            |  2.3617618393399127  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  2 0            | 25 0            |  2.3690702464285422  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  2 0            | 26 0            |  2.3759562069704714  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  2 0            | 27 0            |  2.382459502618694  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  2 0            | 28 0            |  2.388614858728481  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  2 0            | 29 0            |  2.3944527402536977  |  0.3407066065980212 0.41563784409136695\n",
      "0 30       |  2 0            | 30 0            |  2.3999999999999986  |  0.3407066065980212 0.41563784409136695\n",
      "0 31       |  2 0            | 31 0            |  2.4052804104883165  |  0.3407066065980212 0.41563784409136695\n",
      "0 32       |  2 0            | 32 0            |  2.410315103301535  |  0.3407066065980212 0.41563784409136695\n",
      "0 33       |  2 0            | 33 0            |  2.4151229343186387  |  0.3407066065980212 0.41563784409136695\n",
      "0 34       |  2 0            | 34 0            |  2.4197207891481867  |  0.3407066065980212 0.41563784409136695\n",
      "0 35       |  2 0            | 35 0            |  2.424123839980318  |  0.3407066065980212 0.41563784409136695\n",
      "0 36       |  2 0            | 36 0            |  2.4283457627196796  |  0.3407066065980212 0.41563784409136695\n",
      "0 37       |  2 0            | 37 0            |  2.4323989214493906  |  0.3407066065980212 0.41563784409136695\n",
      "0 38       |  2 0            | 38 0            |  2.4362945258726754  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 0       |  3 2            | 0 1            |  1.476280985714169  |  0.0 0.5\n",
      "1 5       |  3 2            | 5 1            |  1.0988902658537398  |  0.3407066065980212 0.41563784409136695\n",
      "1 6       |  3 0            | 6 1            |  2.0831749416668686  |  0.3407066065980212 0.41563784409136695\n",
      "1 7       |  3 0            | 7 1            |  2.2082541375000986  |  0.3407066065980212 0.41563784409136695\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.3407066065980212 0.41563784409136695\n",
      "1 9       |  3 0            | 9 1            |  2.393054490774986  |  0.3407066065980212 0.41563784409136695\n",
      "1 11       |  3 0            | 11 1            |  2.524841194008964  |  0.3407066065980212 0.41563784409136695\n",
      "1 12       |  3 0            | 12 1            |  2.577961529739845  |  0.3407066065980212 0.41563784409136695\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.3407066065980212 0.41563784409136695\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.3407066065980212 0.41563784409136695\n",
      "1 15       |  3 0            | 15 1            |  2.7039544801726194  |  0.3407066065980212 0.41563784409136695\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.3407066065980212 0.41563784409136695\n",
      "1 17       |  3 0            | 17 1            |  2.7686458814337342  |  0.3407066065980212 0.41563784409136695\n",
      "1 18       |  3 2            | 18 1            |  2.796860782881886  |  0.3407066065980212 0.41563784409136695\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215288  |  0.3407066065980212 0.41563784409136695\n",
      "1 20       |  3 0            | 20 1            |  2.846801505477174  |  0.3407066065980212 0.41563784409136695\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.3407066065980212 0.41563784409136695\n",
      "1 22       |  3 0            | 22 1            |  2.889778231101481  |  0.3407066065980212 0.41563784409136695\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.3407066065980212 0.41563784409136695\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.3407066065980212 0.41563784409136695\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.3407066065980212 0.41563784409136695\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.3407066065980212 0.41563784409136695\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.3407066065980212 0.41563784409136695\n",
      "1 28       |  3 0            | 28 1            |  2.989942945366657  |  0.3407066065980212 0.41563784409136695\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.3407066065980212 0.41563784409136695\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.3407066065980212 0.41563784409136695\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.3407066065980212 0.41563784409136695\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.3407066065980212 0.41563784409136695\n",
      "1 33       |  3 0            | 33 1            |  3.0517951217437016  |  0.3407066065980212 0.41563784409136695\n",
      "1 34       |  3 0            | 34 1            |  3.062523449679304  |  0.3407066065980212 0.41563784409136695\n",
      "1 35       |  3 0            | 35 1            |  3.0727972349542796  |  0.3407066065980212 0.41563784409136695\n",
      "1 36       |  3 0            | 36 1            |  3.0826483880127924  |  0.3407066065980212 0.41563784409136695\n",
      "1 37       |  3 0            | 37 1            |  3.092105758382111  |  0.3407066065980212 0.41563784409136695\n",
      "1 38       |  3 0            | 38 1            |  3.101195502036447  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "2 0       |  4 2            | 0 2            |  6.0  |  0.0 0.5\n",
      "2 1       |  4 3            | 1 2            |  1.047438028571662  |  0.0 0.5\n",
      "2 3       |  4 3            | 3 2            |  0.5545875354128569  |  0.3407066065980212 0.41563784409136695\n",
      "2 4       |  4 3            | 4 2            |  0.905177542123667  |  0.3407066065980212 0.41563784409136695\n",
      "2 5       |  4 2            | 5 2            |  1.7255137547037336  |  0.3407066065980212 0.41563784409136695\n",
      "2 6       |  4 0            | 6 2            |  2.5  |  0.3407066065980212 0.41563784409136695\n",
      "2 7       |  4 0            | 7 2            |  2.7680268482140704  |  0.3407066065980212 0.41563784409136695\n",
      "2 8       |  4 0            | 8 2            |  2.984550065040281  |  0.3407066065980212 0.41563784409136695\n",
      "2 9       |  4 0            | 9 2            |  3.1640276052316807  |  0.3407066065980212 0.41563784409136695\n",
      "2 10       |  4 3            | 10 2            |  3.31585581523305  |  0.3407066065980212 0.41563784409136695\n",
      "2 11       |  4 0            | 11 2            |  3.4464276835902012  |  0.3407066065980212 0.41563784409136695\n",
      "2 12       |  4 0            | 12 2            |  3.5602569744420975  |  0.3407066065980212 0.41563784409136695\n",
      "2 13       |  4 0            | 13 2            |  3.660629627852771  |  0.3407066065980212 0.41563784409136695\n",
      "2 14       |  4 0            | 14 2            |  3.75  |  0.3407066065980212 0.41563784409136695\n",
      "2 15       |  4 0            | 15 2            |  3.830241868226608  |  0.3407066065980212 0.41563784409136695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 16       |  4 0            | 16 2            |  3.9028130014780302  |  0.3407066065980212 0.41563784409136695\n",
      "2 17       |  4 0            | 17 2            |  3.9688662995004265  |  0.3407066065980212 0.41563784409136695\n",
      "2 18       |  4 2            | 18 2            |  4.029326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "2 19       |  4 0            | 19 2            |  4.0849462695457035  |  0.3407066065980212 0.41563784409136695\n",
      "2 20       |  4 0            | 20 2            |  4.136342636736366  |  0.3407066065980212 0.41563784409136695\n",
      "2 21       |  4 0            | 21 2            |  4.1840290581374475  |  0.3407066065980212 0.41563784409136695\n",
      "2 22       |  4 0            | 22 2            |  4.228435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "2 23       |  4 0            | 23 2            |  4.26992581444955  |  0.3407066065980212 0.41563784409136695\n",
      "2 24       |  4 0            | 24 2            |  4.308809196699556  |  0.3407066065980212 0.41563784409136695\n",
      "2 25       |  4 0            | 25 2            |  4.345351232142711  |  0.3407066065980212 0.41563784409136695\n",
      "2 26       |  4 0            | 26 2            |  4.379781034852357  |  0.3407066065980212 0.41563784409136695\n",
      "2 27       |  4 0            | 27 2            |  4.412297513093485  |  0.3407066065980212 0.41563784409136695\n",
      "2 28       |  4 0            | 28 2            |  4.443074293642411  |  0.3407066065980212 0.41563784409136695\n",
      "2 29       |  4 0            | 29 2            |  4.472263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "2 30       |  4 0            | 30 2            |  4.5  |  0.3407066065980212 0.41563784409136695\n",
      "2 31       |  4 0            | 31 2            |  4.52640205244159  |  0.3407066065980212 0.41563784409136695\n",
      "2 32       |  4 0            | 32 2            |  4.551575516507661  |  0.3407066065980212 0.41563784409136695\n",
      "2 33       |  4 0            | 33 2            |  4.575614671593208  |  0.3407066065980212 0.41563784409136695\n",
      "2 34       |  4 0            | 34 2            |  4.5986039457409404  |  0.3407066065980212 0.41563784409136695\n",
      "2 35       |  4 0            | 35 2            |  4.620619199901597  |  0.3407066065980212 0.41563784409136695\n",
      "2 36       |  4 0            | 36 2            |  4.641728813598398  |  0.3407066065980212 0.41563784409136695\n",
      "2 37       |  4 0            | 37 2            |  4.66199460724695  |  0.3407066065980212 0.41563784409136695\n",
      "2 38       |  4 0            | 38 2            |  4.681472629363384  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "3 0       |  3 2            | 0 3            |  2.277293767706425  |  -0.3407066065980212 0.5843621559086332\n",
      "3 5       |  3 2            | 5 3            |  0.2978774838614875  |  0.0 0.5\n",
      "3 6       |  3 0            | 6 3            |  0.6814025731804207  |  0.0 0.5\n",
      "3 7       |  3 0            | 7 3            |  0.8064817690136508  |  0.0 0.5\n",
      "3 8       |  3 0            | 8 3            |  0.9075259368658877  |  0.0 0.5\n",
      "3 9       |  3 0            | 9 3            |  0.9912821222885384  |  0.0 0.5\n",
      "3 11       |  3 0            | 11 3            |  1.123068825522516  |  0.0 0.5\n",
      "3 12       |  3 0            | 12 3            |  1.1761891612533972  |  0.0 0.5\n",
      "3 13       |  3 0            | 13 3            |  1.223029732845042  |  0.0 0.5\n",
      "3 14       |  3 0            | 14 3            |  1.2647359065137493  |  0.0 0.5\n",
      "3 15       |  3 0            | 15 3            |  1.3021821116861716  |  0.0 0.5\n",
      "3 16       |  3 0            | 16 3            |  1.3360486405368306  |  0.0 0.5\n",
      "3 17       |  3 0            | 17 3            |  1.3668735129472864  |  0.0 0.5\n",
      "3 18       |  3 2            | 18 3            |  1.3950884143954383  |  0.0 0.5\n",
      "3 19       |  3 0            | 19 3            |  1.421044165635081  |  0.0 0.5\n",
      "3 20       |  3 0            | 20 3            |  1.4450291369907262  |  0.0 0.5\n",
      "3 21       |  3 0            | 21 3            |  1.4672828003112244  |  0.0 0.5\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.0 0.5\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568747  |  0.0 0.5\n",
      "3 24       |  3 0            | 24 3            |  1.5255135316402075  |  0.0 0.5\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136884  |  0.0 0.5\n",
      "3 26       |  3 0            | 26 3            |  1.5586337227781897  |  0.0 0.5\n",
      "3 27       |  3 0            | 27 3            |  1.573808079290714  |  0.0 0.5\n",
      "3 28       |  3 0            | 28 3            |  1.5881705768802092  |  0.0 0.5\n",
      "3 29       |  3 0            | 29 3            |  1.601792300439051  |  0.0 0.5\n",
      "3 30       |  3 0            | 30 3            |  1.6147359065137508  |  0.0 0.5\n",
      "3 31       |  3 0            | 31 3            |  1.627056864319826  |  0.0 0.5\n",
      "3 32       |  3 0            | 32 3            |  1.6388044808839979  |  0.0 0.5\n",
      "3 33       |  3 0            | 33 3            |  1.6500227532572467  |  0.0 0.5\n",
      "3 34       |  3 0            | 34 3            |  1.6607510811928563  |  0.0 0.5\n",
      "3 35       |  3 0            | 35 3            |  1.6710248664678318  |  0.0 0.5\n",
      "3 36       |  3 0            | 36 3            |  1.6808760195263375  |  0.0 0.5\n",
      "3 37       |  3 0            | 37 3            |  1.6903333898956632  |  0.0 0.5\n",
      "3 38       |  3 0            | 38 3            |  1.699423133549999  |  0.0 0.5\n",
      "----\n",
      "4 0       |  3 2            | 0 4            |  2.4525887710618335  |  -0.3407066065980212 0.5843621559086332\n",
      "4 5       |  3 2            | 5 4            |  0.12258248050607534  |  0.0 0.5\n",
      "4 6       |  3 0            | 6 4            |  0.3746363173084575  |  0.0 0.5\n",
      "4 7       |  3 0            | 7 4            |  0.4997155131416875  |  0.0 0.5\n",
      "4 8       |  3 0            | 8 4            |  0.6007596809939244  |  0.0 0.5\n",
      "4 9       |  3 0            | 9 4            |  0.6845158664165751  |  0.0 0.5\n",
      "4 11       |  3 0            | 11 4            |  0.8163025696505528  |  0.0 0.5\n",
      "4 12       |  3 0            | 12 4            |  0.869422905381434  |  0.0 0.5\n",
      "4 13       |  3 0            | 13 4            |  0.9162634769730857  |  0.0 0.5\n",
      "4 14       |  3 0            | 14 4            |  0.9579696506417932  |  0.0 0.5\n",
      "4 15       |  3 0            | 15 4            |  0.9954158558142083  |  0.0 0.5\n",
      "4 16       |  3 0            | 16 4            |  1.0292823846648744  |  0.0 0.5\n",
      "4 17       |  3 0            | 17 4            |  1.0601072570753232  |  0.0 0.5\n",
      "4 18       |  3 2            | 18 4            |  1.088322158523475  |  0.0 0.5\n",
      "4 19       |  3 0            | 19 4            |  1.1142779097631177  |  0.0 0.5\n",
      "4 20       |  3 0            | 20 4            |  1.138262881118763  |  0.0 0.5\n",
      "4 21       |  3 0            | 21 4            |  1.1605165444392682  |  0.0 0.5\n",
      "4 22       |  3 0            | 22 4            |  1.1812396067430697  |  0.0 0.5\n",
      "4 23       |  3 0            | 23 4            |  1.2006016973849185  |  0.0 0.5\n",
      "4 24       |  3 0            | 24 4            |  1.2187472757682514  |  0.0 0.5\n",
      "4 25       |  3 0            | 25 4            |  1.235800225641725  |  0.0 0.5\n",
      "4 26       |  3 0            | 26 4            |  1.2518674669062264  |  0.0 0.5\n",
      "4 27       |  3 0            | 27 4            |  1.2670418234187508  |  0.0 0.5\n",
      "4 28       |  3 0            | 28 4            |  1.281404321008246  |  0.0 0.5\n",
      "4 29       |  3 0            | 29 4            |  1.295026044567095  |  0.0 0.5\n",
      "4 30       |  3 0            | 30 4            |  1.3079696506417946  |  0.0 0.5\n",
      "4 31       |  3 0            | 31 4            |  1.3202906084478698  |  0.0 0.5\n",
      "4 32       |  3 0            | 32 4            |  1.3320382250120346  |  0.0 0.5\n",
      "4 33       |  3 0            | 33 4            |  1.3432564973852905  |  0.0 0.5\n",
      "4 34       |  3 0            | 34 4            |  1.353984825320893  |  0.0 0.5\n",
      "4 35       |  3 0            | 35 4            |  1.3642586105958685  |  0.0 0.5\n",
      "4 36       |  3 0            | 36 4            |  1.3741097636543742  |  0.0 0.5\n",
      "4 37       |  3 0            | 37 4            |  1.3835671340237  |  0.0 0.5\n",
      "4 38       |  3 0            | 38 4            |  1.3926568776780357  |  0.0 0.5\n",
      "----\n",
      "5 6       |  2 0            | 6 5            |  0.06862156132406483  |  0.0 0.5\n",
      "5 7       |  2 0            | 7 5            |  0.1222269309668782  |  0.0 0.5\n",
      "5 8       |  2 0            | 8 5            |  0.16553157433212107  |  0.0 0.5\n",
      "5 9       |  2 0            | 9 5            |  0.20142708237040097  |  0.0 0.5\n",
      "5 11       |  2 0            | 11 5            |  0.2579070980421072  |  0.0 0.5\n",
      "5 12       |  2 0            | 12 5            |  0.28067295621248434  |  0.0 0.5\n",
      "5 13       |  2 0            | 13 5            |  0.3007474868946183  |  0.0 0.5\n",
      "5 14       |  2 0            | 14 5            |  0.31862156132406483  |  0.0 0.5\n",
      "5 15       |  2 0            | 15 5            |  0.33466993496938713  |  0.0 0.5\n",
      "5 16       |  2 0            | 16 5            |  0.3491841616196716  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 17       |  2 0            | 17 5            |  0.3623948212241501  |  0.0 0.5\n",
      "5 19       |  2 0            | 19 5            |  0.38561081523320695  |  0.0 0.5\n",
      "5 20       |  2 0            | 20 5            |  0.3958900886713401  |  0.0 0.5\n",
      "5 21       |  2 0            | 21 5            |  0.4054273729515536  |  0.0 0.5\n",
      "5 22       |  2 0            | 22 5            |  0.41430868536746956  |  0.0 0.5\n",
      "5 23       |  2 0            | 23 5            |  0.42260672421397416  |  0.0 0.5\n",
      "5 24       |  2 0            | 24 5            |  0.43038340066397396  |  0.0 0.5\n",
      "5 25       |  2 0            | 25 5            |  0.4376918077526071  |  0.0 0.5\n",
      "5 26       |  2 0            | 26 5            |  0.4445777682945362  |  0.0 0.5\n",
      "5 27       |  2 0            | 27 5            |  0.4510810639427625  |  0.0 0.5\n",
      "5 28       |  2 0            | 28 5            |  0.4572364200525456  |  0.0 0.5\n",
      "5 29       |  2 0            | 29 5            |  0.4630743015777661  |  0.0 0.5\n",
      "5 30       |  2 0            | 30 5            |  0.4686215613240634  |  0.0 0.5\n",
      "5 31       |  2 0            | 31 5            |  0.4739019718123849  |  0.0 0.5\n",
      "5 32       |  2 0            | 32 5            |  0.47893666462559636  |  0.0 0.5\n",
      "5 33       |  2 0            | 33 5            |  0.48374449564270705  |  0.0 0.5\n",
      "5 34       |  2 0            | 34 5            |  0.4883423504722515  |  0.0 0.5\n",
      "5 35       |  2 0            | 35 5            |  0.4927454013043828  |  0.0 0.5\n",
      "5 36       |  2 0            | 36 5            |  0.49696732404374444  |  0.0 0.5\n",
      "5 37       |  2 0            | 37 5            |  0.5010204827734555  |  0.0 0.5\n",
      "5 38       |  2 0            | 38 5            |  0.5049160871967437  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "10 0       |  3 2            | 0 10            |  2.163171163046613  |  -0.3407066065980212 0.5843621559086332\n",
      "10 5       |  3 2            | 5 10            |  0.2317927243706741  |  0.0 0.5\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 35 the green mile\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.033378282958236416 0.4916562039047883\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441592  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740937  |  0.34989206720724864 0.4134085947484186\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901597  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.0 -- 36 forrest gump\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.34989206720724864 0.4134085947484186\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040281  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.66402760523168  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852357  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 15.356207187108023 -- 37 top gun\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 0            | 1 0            |  5.536053696428137  |  0.34989206720724864 0.4134085947484186\n",
      "0 2       |  4 0            | 2 0            |  7.500000000000001  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481877  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 1            | 5 0            |  9.01309938048769  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 0            | 6 0            |  10.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040283  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231682  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 1            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449552  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142713  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852359  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093483  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593206  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740939  |  0.34989206720724864 0.4134085947484186\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901599  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "5 1       |  1 0            | 1 5            |  0.27472256646343496  |  0.0 0.5\n",
      "5 2       |  1 0            | 2 5            |  0.1437928128919772  |  0.0 0.5\n",
      "5 3       |  1 0            | 3 5            |  0.07446937096537098  |  0.0 0.5\n",
      "5 4       |  1 0            | 4 5            |  0.030645620126518835  |  0.0 0.5\n",
      "5 6       |  1 0            | 6 5            |  0.022873853774688868  |  0.0 0.5\n",
      "5 7       |  1 0            | 7 5            |  0.04074231032229392  |  0.0 0.5\n",
      "5 8       |  1 0            | 8 5            |  0.05517719144404154  |  0.0 0.5\n",
      "5 9       |  1 0            | 9 5            |  0.06714236079013425  |  0.0 0.5\n",
      "5 10       |  1 0            | 10 5            |  0.07726424145689315  |  0.0 0.5\n",
      "5 11       |  1 0            | 11 5            |  0.085969032680703  |  0.0 0.5\n",
      "5 12       |  1 0            | 12 5            |  0.09355765207082989  |  0.0 0.5\n",
      "5 13       |  1 0            | 13 5            |  0.10024916229820668  |  0.0 0.5\n",
      "5 14       |  1 0            | 14 5            |  0.1062071871080228  |  0.0 0.5\n",
      "5 15       |  1 0            | 15 5            |  0.1115566449897969  |  0.0 0.5\n",
      "5 16       |  1 0            | 16 5            |  0.11639472053989053  |  0.0 0.5\n",
      "5 17       |  1 0            | 17 5            |  0.12079827374138397  |  0.0 0.5\n",
      "5 18       |  1 0            | 18 5            |  0.12482897394826331  |  0.0 0.5\n",
      "5 19       |  1 0            | 19 5            |  0.12853693841107017  |  0.0 0.5\n",
      "5 20       |  1 0            | 20 5            |  0.1319633628904473  |  0.0 0.5\n",
      "5 21       |  1 0            | 21 5            |  0.13514245765051847  |  0.0 0.5\n",
      "5 23       |  1 0            | 23 5            |  0.1408689080713259  |  0.0 0.5\n",
      "5 24       |  1 0            | 24 5            |  0.14346113355465917  |  0.0 0.5\n",
      "5 25       |  1 0            | 25 5            |  0.1458972692508702  |  0.0 0.5\n",
      "5 26       |  1 0            | 26 5            |  0.14819258943151326  |  0.0 0.5\n",
      "5 27       |  1 0            | 27 5            |  0.15036035464758868  |  0.0 0.5\n",
      "5 28       |  1 0            | 28 5            |  0.1524121400175158  |  0.0 0.5\n",
      "5 29       |  1 0            | 29 5            |  0.1543581005259238  |  0.0 0.5\n",
      "5 30       |  1 0            | 30 5            |  0.1562071871080235  |  0.0 0.5\n",
      "5 31       |  1 0            | 31 5            |  0.15796732393746282  |  0.0 0.5\n",
      "5 32       |  1 0            | 32 5            |  0.15964555487519938  |  0.0 0.5\n",
      "5 33       |  1 0            | 33 5            |  0.16124816521423568  |  0.0 0.5\n",
      "5 34       |  1 0            | 34 5            |  0.16278078349075287  |  0.0 0.5\n",
      "5 35       |  1 0            | 35 5            |  0.16424846710146213  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 19.749841608333536 -- 38 how to train your dragon\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.0 0.5\n",
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 1            | 6 0            |  9.333333333333334  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 0            | 7 0            |  10.268026848214069  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040283  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231682  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590203  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442096  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852359  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.0  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.34989206720724864 0.4134085947484186\n",
      "0 32       |  4 0            | 32 0            |  12.051575516507661  |  0.34989206720724864 0.4134085947484186\n",
      "0 33       |  4 0            | 33 0            |  12.075614671593208  |  0.34989206720724864 0.4134085947484186\n",
      "0 34       |  4 0            | 34 0            |  12.098603945740939  |  0.34989206720724864 0.4134085947484186\n",
      "0 35       |  4 0            | 35 0            |  12.120619199901599  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  3 0            | 2 1            |  0.9165082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 3       |  3 0            | 3 1            |  1.4017723684864514  |  0.34989206720724864 0.4134085947484186\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.34989206720724864 0.4134085947484186\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.34989206720724864 0.4134085947484186\n",
      "1 6       |  3 1            | 6 1            |  1.7855785214287465  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  3 0            | 7 1            |  2.208254137500102  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749898  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442295  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  3 0            | 11 1            |  2.5248411940089674  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398486  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.34989206720724864 0.4134085947484186\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666606  |  0.34989206720724864 0.4134085947484186\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.34989206720724864 0.4134085947484186\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.34989206720724864 0.4134085947484186\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.34989206720724864 0.4134085947484186\n",
      "1 32       |  3 0            | 32 1            |  3.0405768493704457  |  0.34989206720724864 0.4134085947484186\n",
      "1 33       |  3 0            | 33 1            |  3.0517951217437016  |  0.34989206720724864 0.4134085947484186\n",
      "1 34       |  3 0            | 34 1            |  3.0625234496793077  |  0.34989206720724864 0.4134085947484186\n",
      "1 35       |  3 0            | 35 1            |  3.072797234954283  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "6 2       |  1 0            | 2 6            |  0.16666666666666785  |  0.0 0.5\n",
      "6 3       |  1 0            | 3 6            |  0.09734322474006163  |  0.0 0.5\n",
      "6 4       |  1 0            | 4 6            |  0.053519473901207704  |  0.0 0.5\n",
      "6 5       |  1 0            | 5 6            |  0.022873853774690645  |  0.0 0.5\n",
      "6 7       |  1 0            | 7 6            |  0.017868456547603273  |  0.0 0.5\n",
      "6 8       |  1 0            | 8 6            |  0.032303337669350896  |  0.0 0.5\n",
      "6 9       |  1 0            | 9 6            |  0.04426850701544538  |  0.0 0.5\n",
      "6 10       |  1 0            | 10 6            |  0.054390387682200725  |  0.0 0.5\n",
      "6 11       |  1 0            | 11 6            |  0.06309517890601413  |  0.0 0.5\n",
      "6 12       |  1 0            | 12 6            |  0.07068379829613747  |  0.0 0.5\n",
      "6 13       |  1 0            | 13 6            |  0.07737530852351782  |  0.0 0.5\n",
      "6 14       |  1 0            | 14 6            |  0.08333333333333215  |  0.0 0.5\n",
      "6 15       |  1 0            | 15 6            |  0.08868279121510625  |  0.0 0.5\n",
      "6 16       |  1 0            | 16 6            |  0.09352086676519988  |  0.0 0.5\n",
      "6 17       |  1 0            | 17 6            |  0.0979244199666951  |  0.0 0.5\n",
      "6 18       |  1 0            | 18 6            |  0.10195512017357444  |  0.0 0.5\n",
      "6 19       |  1 0            | 19 6            |  0.10566308463637952  |  0.0 0.5\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 23       |  1 0            | 23 6            |  0.11799505429663526  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 27       |  1 0            | 27 6            |  0.12748650087289803  |  0.0 0.5\n",
      "6 28       |  1 0            | 28 6            |  0.12953828624282693  |  0.0 0.5\n",
      "6 29       |  1 0            | 29 6            |  0.13148424675123138  |  0.0 0.5\n",
      "6 30       |  1 0            | 30 6            |  0.13333333333333286  |  0.0 0.5\n",
      "6 31       |  1 0            | 31 6            |  0.13509347016277218  |  0.0 0.5\n",
      "6 32       |  1 0            | 32 6            |  0.1367717011005105  |  0.0 0.5\n",
      "6 33       |  1 0            | 33 6            |  0.13837431143954504  |  0.0 0.5\n",
      "6 34       |  1 0            | 34 6            |  0.13990692971606222  |  0.0 0.5\n",
      "6 35       |  1 0            | 35 6            |  0.14137461332677148  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 20.065306485119265 -- 39 how to train your dragon 2\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 3            | 1 0            |  2.9525619714283415  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2       |  4 0            | 2 0            |  7.5  |  0.34989206720724864 0.4134085947484186\n",
      "0 3       |  4 0            | 3 0            |  8.539851628899104  |  0.34989206720724864 0.4134085947484186\n",
      "0 4       |  4 0            | 4 0            |  9.197207891481876  |  0.34989206720724864 0.4134085947484186\n",
      "0 5       |  4 0            | 5 0            |  9.656892193379667  |  0.34989206720724864 0.4134085947484186\n",
      "0 6       |  4 1            | 6 0            |  9.333333333333334  |  0.34989206720724864 0.4134085947484186\n",
      "0 7       |  4 1            | 7 0            |  9.583491724999798  |  0.34989206720724864 0.4134085947484186\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040283  |  0.34989206720724864 0.4134085947484186\n",
      "0 9       |  4 0            | 9 0            |  10.664027605231682  |  0.34989206720724864 0.4134085947484186\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233052  |  0.34989206720724864 0.4134085947484186\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590203  |  0.34989206720724864 0.4134085947484186\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442096  |  0.34989206720724864 0.4134085947484186\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.34989206720724864 0.4134085947484186\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.34989206720724864 0.4134085947484186\n",
      "0 15       |  4 0            | 15 0            |  11.33024186822661  |  0.34989206720724864 0.4134085947484186\n",
      "0 16       |  4 0            | 16 0            |  11.402813001478028  |  0.34989206720724864 0.4134085947484186\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.34989206720724864 0.4134085947484186\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.34989206720724864 0.4134085947484186\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545705  |  0.34989206720724864 0.4134085947484186\n",
      "0 20       |  4 0            | 20 0            |  11.63634263673637  |  0.34989206720724864 0.4134085947484186\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.34989206720724864 0.4134085947484186\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.34989206720724864 0.4134085947484186\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.34989206720724864 0.4134085947484186\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699555  |  0.34989206720724864 0.4134085947484186\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.34989206720724864 0.4134085947484186\n",
      "0 26       |  4 0            | 26 0            |  11.879781034852359  |  0.34989206720724864 0.4134085947484186\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.34989206720724864 0.4134085947484186\n",
      "0 28       |  4 0            | 28 0            |  11.94307429364241  |  0.34989206720724864 0.4134085947484186\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268504  |  0.34989206720724864 0.4134085947484186\n",
      "0 30       |  4 0            | 30 0            |  12.000000000000002  |  0.34989206720724864 0.4134085947484186\n",
      "0 31       |  4 0            | 31 0            |  12.026402052441593  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "1 2       |  3 0            | 2 1            |  0.9165082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 3       |  3 0            | 3 1            |  1.4017723684864514  |  0.34989206720724864 0.4134085947484186\n",
      "1 4       |  3 0            | 4 1            |  1.708538624358411  |  0.34989206720724864 0.4134085947484186\n",
      "1 5       |  3 0            | 5 1            |  1.9230579652440483  |  0.34989206720724864 0.4134085947484186\n",
      "1 6       |  3 1            | 6 1            |  1.7855785214287465  |  0.34989206720724864 0.4134085947484186\n",
      "1 7       |  3 1            | 7 1            |  1.8927892607143733  |  0.34989206720724864 0.4134085947484186\n",
      "1 8       |  3 0            | 8 1            |  2.3092983053523355  |  0.34989206720724864 0.4134085947484186\n",
      "1 9       |  3 0            | 9 1            |  2.3930544907749898  |  0.34989206720724864 0.4134085947484186\n",
      "1 10       |  3 0            | 10 1            |  2.463907655442295  |  0.34989206720724864 0.4134085947484186\n",
      "1 11       |  3 0            | 11 1            |  2.5248411940089674  |  0.34989206720724864 0.4134085947484186\n",
      "1 12       |  3 0            | 12 1            |  2.5779615297398486  |  0.34989206720724864 0.4134085947484186\n",
      "1 13       |  3 0            | 13 1            |  2.624802101331497  |  0.34989206720724864 0.4134085947484186\n",
      "1 14       |  3 0            | 14 1            |  2.6665082750002043  |  0.34989206720724864 0.4134085947484186\n",
      "1 15       |  3 0            | 15 1            |  2.703954480172623  |  0.34989206720724864 0.4134085947484186\n",
      "1 16       |  3 0            | 16 1            |  2.7378210090232855  |  0.34989206720724864 0.4134085947484186\n",
      "1 17       |  3 0            | 17 1            |  2.768645881433738  |  0.34989206720724864 0.4134085947484186\n",
      "1 18       |  3 0            | 18 1            |  2.7968607828818897  |  0.34989206720724864 0.4134085947484186\n",
      "1 19       |  3 0            | 19 1            |  2.8228165341215323  |  0.34989206720724864 0.4134085947484186\n",
      "1 20       |  3 0            | 20 1            |  2.8468015054771776  |  0.34989206720724864 0.4134085947484186\n",
      "1 21       |  3 0            | 21 1            |  2.8690551687976793  |  0.34989206720724864 0.4134085947484186\n",
      "1 22       |  3 0            | 22 1            |  2.8897782311014844  |  0.34989206720724864 0.4134085947484186\n",
      "1 23       |  3 0            | 23 1            |  2.9091403217433296  |  0.34989206720724864 0.4134085947484186\n",
      "1 24       |  3 0            | 24 1            |  2.9272859001266625  |  0.34989206720724864 0.4134085947484186\n",
      "1 25       |  3 0            | 25 1            |  2.944338850000136  |  0.34989206720724864 0.4134085947484186\n",
      "1 26       |  3 0            | 26 1            |  2.9604060912646375  |  0.34989206720724864 0.4134085947484186\n",
      "1 27       |  3 0            | 27 1            |  2.975580447777162  |  0.34989206720724864 0.4134085947484186\n",
      "1 28       |  3 0            | 28 1            |  2.9899429453666606  |  0.34989206720724864 0.4134085947484186\n",
      "1 29       |  3 0            | 29 1            |  3.003564668925506  |  0.34989206720724864 0.4134085947484186\n",
      "1 30       |  3 0            | 30 1            |  3.0165082750002057  |  0.34989206720724864 0.4134085947484186\n",
      "1 31       |  3 0            | 31 1            |  3.028829232806281  |  0.34989206720724864 0.4134085947484186\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "6 2       |  1 0            | 2 6            |  0.16666666666666785  |  0.0 0.5\n",
      "6 3       |  1 0            | 3 6            |  0.09734322474006163  |  0.0 0.5\n",
      "6 4       |  1 0            | 4 6            |  0.053519473901207704  |  0.0 0.5\n",
      "6 5       |  1 0            | 5 6            |  0.022873853774690645  |  0.0 0.5\n",
      "6 8       |  1 0            | 8 6            |  0.032303337669350896  |  0.0 0.5\n",
      "6 9       |  1 0            | 9 6            |  0.04426850701544538  |  0.0 0.5\n",
      "6 10       |  1 0            | 10 6            |  0.054390387682200725  |  0.0 0.5\n",
      "6 11       |  1 0            | 11 6            |  0.06309517890601413  |  0.0 0.5\n",
      "6 12       |  1 0            | 12 6            |  0.07068379829613747  |  0.0 0.5\n",
      "6 13       |  1 0            | 13 6            |  0.07737530852351782  |  0.0 0.5\n",
      "6 14       |  1 0            | 14 6            |  0.08333333333333215  |  0.0 0.5\n",
      "6 15       |  1 0            | 15 6            |  0.08868279121510625  |  0.0 0.5\n",
      "6 16       |  1 0            | 16 6            |  0.09352086676519988  |  0.0 0.5\n",
      "6 17       |  1 0            | 17 6            |  0.0979244199666951  |  0.0 0.5\n",
      "6 18       |  1 0            | 18 6            |  0.10195512017357444  |  0.0 0.5\n",
      "6 19       |  1 0            | 19 6            |  0.10566308463637952  |  0.0 0.5\n",
      "6 20       |  1 0            | 20 6            |  0.10908950911575843  |  0.0 0.5\n",
      "6 21       |  1 0            | 21 6            |  0.1122686038758296  |  0.0 0.5\n",
      "6 22       |  1 0            | 22 6            |  0.11522904134779921  |  0.0 0.5\n",
      "6 23       |  1 0            | 23 6            |  0.11799505429663526  |  0.0 0.5\n",
      "6 24       |  1 0            | 24 6            |  0.12058727977996853  |  0.0 0.5\n",
      "6 25       |  1 0            | 25 6            |  0.12302341547617957  |  0.0 0.5\n",
      "6 26       |  1 0            | 26 6            |  0.1253187356568226  |  0.0 0.5\n",
      "6 27       |  1 0            | 27 6            |  0.12748650087289803  |  0.0 0.5\n",
      "6 28       |  1 0            | 28 6            |  0.12953828624282693  |  0.0 0.5\n",
      "6 29       |  1 0            | 29 6            |  0.13148424675123138  |  0.0 0.5\n",
      "6 30       |  1 0            | 30 6            |  0.13333333333333286  |  0.0 0.5\n",
      "6 31       |  1 0            | 31 6            |  0.13509347016277218  |  0.0 0.5\n",
      "----\n",
      "7 2       |  1 0            | 2 7            |  0.18453512321427112  |  0.0 0.5\n",
      "7 3       |  1 0            | 3 7            |  0.1152116812876649  |  0.0 0.5\n",
      "7 4       |  1 0            | 4 7            |  0.07138793044881453  |  0.0 0.5\n",
      "7 5       |  1 0            | 5 7            |  0.04074231032229392  |  0.0 0.5\n",
      "7 8       |  1 0            | 8 7            |  0.014434881121747623  |  0.0 0.5\n",
      "7 9       |  1 0            | 9 7            |  0.026400050467842107  |  0.0 0.5\n",
      "7 10       |  1 0            | 10 7            |  0.03652193113459745  |  0.0 0.5\n",
      "7 11       |  1 0            | 11 7            |  0.045226722358410854  |  0.0 0.5\n",
      "7 12       |  1 0            | 12 7            |  0.052815341748534195  |  0.0 0.5\n",
      "7 13       |  1 0            | 13 7            |  0.05950685197591454  |  0.0 0.5\n",
      "7 14       |  1 0            | 14 7            |  0.06546487678572888  |  0.0 0.5\n",
      "7 15       |  1 0            | 15 7            |  0.07081433466750298  |  0.0 0.5\n",
      "7 16       |  1 0            | 16 7            |  0.07565241021759661  |  0.0 0.5\n",
      "7 17       |  1 0            | 17 7            |  0.08005596341909182  |  0.0 0.5\n",
      "7 18       |  1 0            | 18 7            |  0.08408666362597117  |  0.0 0.5\n",
      "7 19       |  1 0            | 19 7            |  0.08779462808877625  |  0.0 0.5\n",
      "7 20       |  1 0            | 20 7            |  0.09122105256815516  |  0.0 0.5\n",
      "7 21       |  1 0            | 21 7            |  0.09440014732822632  |  0.0 0.5\n",
      "7 22       |  1 0            | 22 7            |  0.09736058480019594  |  0.0 0.5\n",
      "7 23       |  1 0            | 23 7            |  0.10012659774903199  |  0.0 0.5\n",
      "7 24       |  1 0            | 24 7            |  0.10271882323236525  |  0.0 0.5\n",
      "7 25       |  1 0            | 25 7            |  0.10515495892857629  |  0.0 0.5\n",
      "7 26       |  1 0            | 26 7            |  0.10745027910921934  |  0.0 0.5\n",
      "7 27       |  1 0            | 27 7            |  0.10961804432529476  |  0.0 0.5\n",
      "7 28       |  1 0            | 28 7            |  0.11166982969522365  |  0.0 0.5\n",
      "7 29       |  1 0            | 29 7            |  0.11361579020362811  |  0.0 0.5\n",
      "7 30       |  1 0            | 30 7            |  0.11546487678572959  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 31       |  1 0            | 31 7            |  0.1172250136151689  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "----\n",
      "DONE 11,11\n",
      "DCG 29.683932058339124 -- 40 star wars\n",
      "better worse |  Gbetter Gworse |  Pbetter Pworse |  dcg:delta  | pred:delta rho |\n",
      "----\n",
      "0 1       |  4 2            | 1 0            |  4.428842957142507  |  0.02419282234900899 0.49395208939300733\n",
      "0 2       |  4 3            | 2 0            |  4.0  |  0.3407066065980212 0.41563784409136695\n",
      "0 3       |  4 3            | 3 0            |  4.554587535412857  |  0.3407066065980212 0.41563784409136695\n",
      "0 4       |  4 2            | 4 0            |  7.3577663131855005  |  0.3407066065980212 0.41563784409136695\n",
      "0 5       |  4 3            | 5 0            |  5.150342503135825  |  0.3407066065980212 0.41563784409136695\n",
      "0 6       |  4 3            | 6 0            |  5.333333333333332  |  0.3407066065980212 0.41563784409136695\n",
      "0 7       |  4 0            | 7 0            |  10.26802684821407  |  0.3407066065980212 0.41563784409136695\n",
      "0 8       |  4 0            | 8 0            |  10.484550065040285  |  0.3407066065980212 0.41563784409136695\n",
      "0 9       |  4 1            | 9 0            |  9.953092431549571  |  0.3407066065980212 0.41563784409136695\n",
      "0 10       |  4 0            | 10 0            |  10.815855815233054  |  0.3407066065980212 0.41563784409136695\n",
      "0 11       |  4 0            | 11 0            |  10.946427683590205  |  0.3407066065980212 0.41563784409136695\n",
      "0 12       |  4 0            | 12 0            |  11.060256974442098  |  0.3407066065980212 0.41563784409136695\n",
      "0 13       |  4 0            | 13 0            |  11.160629627852767  |  0.3407066065980212 0.41563784409136695\n",
      "0 14       |  4 0            | 14 0            |  11.25  |  0.3407066065980212 0.41563784409136695\n",
      "0 15       |  4 0            | 15 0            |  11.330241868226612  |  0.3407066065980212 0.41563784409136695\n",
      "0 16       |  4 0            | 16 0            |  11.40281300147803  |  0.3407066065980212 0.41563784409136695\n",
      "0 17       |  4 0            | 17 0            |  11.468866299500426  |  0.3407066065980212 0.41563784409136695\n",
      "0 18       |  4 0            | 18 0            |  11.529326802603613  |  0.3407066065980212 0.41563784409136695\n",
      "0 19       |  4 0            | 19 0            |  11.584946269545707  |  0.3407066065980212 0.41563784409136695\n",
      "0 20       |  4 1            | 20 0            |  11.63634263673637  |  0.3407066065980212 0.41563784409136695\n",
      "0 21       |  4 0            | 21 0            |  11.684029058137444  |  0.3407066065980212 0.41563784409136695\n",
      "0 22       |  4 0            | 22 0            |  11.728435620217027  |  0.3407066065980212 0.41563784409136695\n",
      "0 23       |  4 0            | 23 0            |  11.769925814449554  |  0.3407066065980212 0.41563784409136695\n",
      "0 24       |  4 0            | 24 0            |  11.808809196699553  |  0.3407066065980212 0.41563784409136695\n",
      "0 25       |  4 0            | 25 0            |  11.845351232142715  |  0.3407066065980212 0.41563784409136695\n",
      "0 26       |  4 0            | 26 0            |  11.87978103485236  |  0.3407066065980212 0.41563784409136695\n",
      "0 27       |  4 0            | 27 0            |  11.912297513093485  |  0.3407066065980212 0.41563784409136695\n",
      "0 28       |  4 0            | 28 0            |  11.943074293642407  |  0.3407066065980212 0.41563784409136695\n",
      "0 29       |  4 0            | 29 0            |  11.972263701268503  |  0.3407066065980212 0.41563784409136695\n",
      "----\n",
      "1 7       |  2 0            | 7 1            |  0.9463946303571831  |  0.3165137842490122 0.4215255995031885\n",
      "1 8       |  2 0            | 8 1            |  0.9896992737224295  |  0.3165137842490122 0.4215255995031885\n",
      "1 9       |  2 1            | 9 1            |  0.6837298545071384  |  0.3165137842490122 0.4215255995031885\n",
      "1 10       |  2 0            | 10 1            |  1.055960423760986  |  0.3165137842490122 0.4215255995031885\n",
      "1 11       |  2 0            | 11 1            |  1.082074797432412  |  0.3165137842490122 0.4215255995031885\n",
      "1 12       |  2 0            | 12 1            |  1.1048406556027928  |  0.3165137842490122 0.4215255995031885\n",
      "1 13       |  2 0            | 13 1            |  1.1249151862849232  |  0.3165137842490122 0.4215255995031885\n",
      "1 14       |  2 0            | 14 1            |  1.1427892607143733  |  0.3165137842490122 0.4215255995031885\n",
      "1 15       |  2 0            | 15 1            |  1.158837634359692  |  0.3165137842490122 0.4215255995031885\n",
      "1 16       |  2 0            | 16 1            |  1.1733518610099765  |  0.3165137842490122 0.4215255995031885\n",
      "1 17       |  2 0            | 17 1            |  1.1865625206144585  |  0.3165137842490122 0.4215255995031885\n",
      "1 18       |  2 0            | 18 1            |  1.198654621235093  |  0.3165137842490122 0.4215255995031885\n",
      "1 19       |  2 0            | 19 1            |  1.2097785146235154  |  0.3165137842490122 0.4215255995031885\n",
      "1 20       |  2 1            | 20 1            |  1.220057788061645  |  0.3165137842490122 0.4215255995031885\n",
      "1 21       |  2 0            | 21 1            |  1.2295950723418585  |  0.3165137842490122 0.4215255995031885\n",
      "1 22       |  2 0            | 22 1            |  1.2384763847577744  |  0.3165137842490122 0.4215255995031885\n",
      "1 23       |  2 0            | 23 1            |  1.2467744236042861  |  0.3165137842490122 0.4215255995031885\n",
      "1 24       |  2 0            | 24 1            |  1.254551100054286  |  0.3165137842490122 0.4215255995031885\n",
      "1 25       |  2 0            | 25 1            |  1.2618595071429155  |  0.3165137842490122 0.4215255995031885\n",
      "1 26       |  2 0            | 26 1            |  1.2687454676848446  |  0.3165137842490122 0.4215255995031885\n",
      "1 27       |  2 0            | 27 1            |  1.2752487633330674  |  0.3165137842490122 0.4215255995031885\n",
      "1 28       |  2 0            | 28 1            |  1.281404119442854  |  0.3165137842490122 0.4215255995031885\n",
      "1 29       |  2 0            | 29 1            |  1.287242000968071  |  0.3165137842490122 0.4215255995031885\n",
      "----\n",
      "2 1       |  3 2            | 1 2            |  0.523719014285831  |  -0.3165137842490122 0.5784744004968115\n",
      "2 4       |  3 2            | 4 2            |  0.45258877106182993  |  0.0 0.5\n",
      "2 7       |  3 0            | 7 2            |  1.2917458624998943  |  0.0 0.5\n",
      "2 8       |  3 0            | 8 2            |  1.3927900303521312  |  0.0 0.5\n",
      "2 9       |  3 1            | 9 2            |  1.2656110420926687  |  0.0 0.5\n",
      "2 10       |  3 0            | 10 2            |  1.5473993804420871  |  0.0 0.5\n",
      "2 11       |  3 0            | 11 2            |  1.6083329190087596  |  0.0 0.5\n",
      "2 12       |  3 0            | 12 2            |  1.6614532547396408  |  0.0 0.5\n",
      "2 13       |  3 0            | 13 2            |  1.7082938263312926  |  0.0 0.5\n",
      "2 14       |  3 0            | 14 2            |  1.75  |  0.0 0.5\n",
      "2 15       |  3 0            | 15 2            |  1.7874462051724151  |  0.0 0.5\n",
      "2 16       |  3 0            | 16 2            |  1.8213127340230812  |  0.0 0.5\n",
      "2 17       |  3 0            | 17 2            |  1.85213760643353  |  0.0 0.5\n",
      "2 18       |  3 0            | 18 2            |  1.8803525078816818  |  0.0 0.5\n",
      "2 19       |  3 0            | 19 2            |  1.9063082591213245  |  0.0 0.5\n",
      "2 20       |  3 1            | 20 2            |  1.9302932304769698  |  0.0 0.5\n",
      "2 21       |  3 0            | 21 2            |  1.952546893797475  |  0.0 0.5\n",
      "2 22       |  3 0            | 22 2            |  1.9732699561012765  |  0.0 0.5\n",
      "2 23       |  3 0            | 23 2            |  1.9926320467431253  |  0.0 0.5\n",
      "2 24       |  3 0            | 24 2            |  2.010777625126458  |  0.0 0.5\n",
      "2 25       |  3 0            | 25 2            |  2.027830574999932  |  0.0 0.5\n",
      "2 26       |  3 0            | 26 2            |  2.0438978162644332  |  0.0 0.5\n",
      "2 27       |  3 0            | 27 2            |  2.0590721727769576  |  0.0 0.5\n",
      "2 28       |  3 0            | 28 2            |  2.073434670366453  |  0.0 0.5\n",
      "2 29       |  3 0            | 29 2            |  2.0870563939253017  |  0.0 0.5\n",
      "----\n",
      "3 1       |  3 2            | 1 3            |  0.8010127819922559  |  -0.3165137842490122 0.5784744004968115\n",
      "3 4       |  3 2            | 4 3            |  0.17529500335540504  |  0.0 0.5\n",
      "3 7       |  3 0            | 7 3            |  0.8064817690136508  |  0.0 0.5\n",
      "3 8       |  3 0            | 8 3            |  0.9075259368658806  |  0.0 0.5\n",
      "3 9       |  3 1            | 9 3            |  0.8496703905330314  |  0.0 0.5\n",
      "3 10       |  3 0            | 10 3            |  1.0621352869558436  |  0.0 0.5\n",
      "3 11       |  3 0            | 11 3            |  1.123068825522516  |  0.0 0.5\n",
      "3 12       |  3 0            | 12 3            |  1.1761891612533972  |  0.0 0.5\n",
      "3 13       |  3 0            | 13 3            |  1.223029732845042  |  0.0 0.5\n",
      "3 14       |  3 0            | 14 3            |  1.2647359065137493  |  0.0 0.5\n",
      "3 15       |  3 0            | 15 3            |  1.3021821116861716  |  0.0 0.5\n",
      "3 16       |  3 0            | 16 3            |  1.3360486405368306  |  0.0 0.5\n",
      "3 17       |  3 0            | 17 3            |  1.3668735129472864  |  0.0 0.5\n",
      "3 18       |  3 0            | 18 3            |  1.3950884143954383  |  0.0 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 19       |  3 0            | 19 3            |  1.421044165635081  |  0.0 0.5\n",
      "3 20       |  3 1            | 20 3            |  1.4450291369907262  |  0.0 0.5\n",
      "3 21       |  3 0            | 21 3            |  1.4672828003112244  |  0.0 0.5\n",
      "3 22       |  3 0            | 22 3            |  1.488005862615033  |  0.0 0.5\n",
      "3 23       |  3 0            | 23 3            |  1.5073679532568747  |  0.0 0.5\n",
      "3 24       |  3 0            | 24 3            |  1.5255135316402075  |  0.0 0.5\n",
      "3 25       |  3 0            | 25 3            |  1.5425664815136813  |  0.0 0.5\n",
      "3 26       |  3 0            | 26 3            |  1.5586337227781826  |  0.0 0.5\n",
      "3 27       |  3 0            | 27 3            |  1.573808079290707  |  0.0 0.5\n",
      "3 28       |  3 0            | 28 3            |  1.5881705768802092  |  0.0 0.5\n",
      "3 29       |  3 0            | 29 3            |  1.601792300439051  |  0.0 0.5\n",
      "----\n",
      "4 7       |  2 0            | 7 4            |  0.21416379134643648  |  0.0 0.5\n",
      "4 8       |  2 0            | 8 4            |  0.25746843471167935  |  0.0 0.5\n",
      "4 9       |  2 1            | 9 4            |  0.19557596183330617  |  0.0 0.5\n",
      "4 10       |  2 0            | 10 4            |  0.3237295847502324  |  0.0 0.5\n",
      "4 11       |  2 0            | 11 4            |  0.3498439584216655  |  0.0 0.5\n",
      "4 12       |  2 0            | 12 4            |  0.3726098165920426  |  0.0 0.5\n",
      "4 13       |  2 0            | 13 4            |  0.39268434727417656  |  0.0 0.5\n",
      "4 14       |  2 0            | 14 4            |  0.4105584217036231  |  0.0 0.5\n",
      "4 15       |  2 0            | 15 4            |  0.4266067953489454  |  0.0 0.5\n",
      "4 16       |  2 0            | 16 4            |  0.44112102199922987  |  0.0 0.5\n",
      "4 17       |  2 0            | 17 4            |  0.4543316816037084  |  0.0 0.5\n",
      "4 18       |  2 0            | 18 4            |  0.46642378222434644  |  0.0 0.5\n",
      "4 19       |  2 0            | 19 4            |  0.47754767561276523  |  0.0 0.5\n",
      "4 20       |  2 1            | 20 4            |  0.4878269490508984  |  0.0 0.5\n",
      "4 21       |  2 0            | 21 4            |  0.4973642333311119  |  0.0 0.5\n",
      "4 22       |  2 0            | 22 4            |  0.5062455457470278  |  0.0 0.5\n",
      "4 23       |  2 0            | 23 4            |  0.5145435845935324  |  0.0 0.5\n",
      "4 24       |  2 0            | 24 4            |  0.5223202610435322  |  0.0 0.5\n",
      "4 25       |  2 0            | 25 4            |  0.5296286681321654  |  0.0 0.5\n",
      "4 26       |  2 0            | 26 4            |  0.5365146286740945  |  0.0 0.5\n",
      "4 27       |  2 0            | 27 4            |  0.5430179243223208  |  0.0 0.5\n",
      "4 28       |  2 0            | 28 4            |  0.5491732804321039  |  0.0 0.5\n",
      "4 29       |  2 0            | 29 4            |  0.5550111619573244  |  0.0 0.5\n",
      "----\n",
      "5 1       |  3 2            | 1 5            |  1.0988902658537398  |  -0.3165137842490122 0.5784744004968115\n",
      "5 4       |  3 2            | 4 5            |  0.12258248050608245  |  0.0 0.5\n",
      "5 7       |  3 0            | 7 5            |  0.28519617225605387  |  0.0 0.5\n",
      "5 8       |  3 0            | 8 5            |  0.38624034010828723  |  0.0 0.5\n",
      "5 9       |  3 1            | 9 5            |  0.4028541647408055  |  0.0 0.5\n",
      "5 10       |  3 0            | 10 5            |  0.5408496901982467  |  0.0 0.5\n",
      "5 11       |  3 0            | 11 5            |  0.6017832287649192  |  0.0 0.5\n",
      "5 12       |  3 0            | 12 5            |  0.6549035644958003  |  0.0 0.5\n",
      "5 13       |  3 0            | 13 5            |  0.7017441360874486  |  0.0 0.5\n",
      "5 14       |  3 0            | 14 5            |  0.743450309756156  |  0.0 0.5\n",
      "5 15       |  3 0            | 15 5            |  0.7808965149285747  |  0.0 0.5\n",
      "5 16       |  3 0            | 16 5            |  0.8147630437792373  |  0.0 0.5\n",
      "5 17       |  3 0            | 17 5            |  0.8455879161896895  |  0.0 0.5\n",
      "5 18       |  3 0            | 18 5            |  0.8738028176378414  |  0.0 0.5\n",
      "5 19       |  3 0            | 19 5            |  0.8997585688774841  |  0.0 0.5\n",
      "5 20       |  3 1            | 20 5            |  0.9237435402331293  |  0.0 0.5\n",
      "5 21       |  3 0            | 21 5            |  0.945997203553631  |  0.0 0.5\n",
      "5 22       |  3 0            | 22 5            |  0.9667202658574361  |  0.0 0.5\n",
      "5 23       |  3 0            | 23 5            |  0.9860823564992813  |  0.0 0.5\n",
      "5 24       |  3 0            | 24 5            |  1.0042279348826142  |  0.0 0.5\n",
      "5 25       |  3 0            | 25 5            |  1.021280884756088  |  0.0 0.5\n",
      "5 26       |  3 0            | 26 5            |  1.0373481260205892  |  0.0 0.5\n",
      "5 27       |  3 0            | 27 5            |  1.0525224825331136  |  0.0 0.5\n",
      "5 28       |  3 0            | 28 5            |  1.0668849801226123  |  0.0 0.5\n",
      "5 29       |  3 0            | 29 5            |  1.0805067036814577  |  0.0 0.5\n",
      "----\n",
      "6 1       |  3 2            | 1 6            |  1.1903856809524989  |  -0.3165137842490122 0.5784744004968115\n",
      "6 4       |  3 2            | 4 6            |  0.21407789560483437  |  0.0 0.5\n",
      "6 7       |  3 0            | 7 6            |  0.12507919583323002  |  0.0 0.5\n",
      "6 8       |  3 0            | 8 6            |  0.22612336368546337  |  0.0 0.5\n",
      "6 9       |  3 1            | 9 6            |  0.2656110420926723  |  0.0 0.5\n",
      "6 10       |  3 0            | 10 6            |  0.38073271377542284  |  0.0 0.5\n",
      "6 11       |  3 0            | 11 6            |  0.44166625234209533  |  0.0 0.5\n",
      "6 12       |  3 0            | 12 6            |  0.4947865880729765  |  0.0 0.5\n",
      "6 13       |  3 0            | 13 6            |  0.5416271596646247  |  0.0 0.5\n",
      "6 14       |  3 0            | 14 6            |  0.5833333333333321  |  0.0 0.5\n",
      "6 15       |  3 0            | 15 6            |  0.6207795385057508  |  0.0 0.5\n",
      "6 16       |  3 0            | 16 6            |  0.6546460673564134  |  0.0 0.5\n",
      "6 17       |  3 0            | 17 6            |  0.6854709397668657  |  0.0 0.5\n",
      "6 18       |  3 0            | 18 6            |  0.7136858412150175  |  0.0 0.5\n",
      "6 19       |  3 0            | 19 6            |  0.7396415924546602  |  0.0 0.5\n",
      "6 20       |  3 1            | 20 6            |  0.7636265638103055  |  0.0 0.5\n",
      "6 21       |  3 0            | 21 6            |  0.7858802271308072  |  0.0 0.5\n",
      "6 22       |  3 0            | 22 6            |  0.8066032894346122  |  0.0 0.5\n",
      "6 23       |  3 0            | 23 6            |  0.8259653800764575  |  0.0 0.5\n",
      "6 24       |  3 0            | 24 6            |  0.8441109584597903  |  0.0 0.5\n",
      "6 25       |  3 0            | 25 6            |  0.8611639083332641  |  0.0 0.5\n",
      "6 26       |  3 0            | 26 6            |  0.8772311495977654  |  0.0 0.5\n",
      "6 27       |  3 0            | 27 6            |  0.8924055061102898  |  0.0 0.5\n",
      "6 28       |  3 0            | 28 6            |  0.9067680036997885  |  0.0 0.5\n",
      "6 29       |  3 0            | 29 6            |  0.9203897272586339  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "----\n",
      "9 7       |  1 0            | 7 9            |  0.026400050467842107  |  0.0 0.5\n",
      "9 8       |  1 0            | 8 9            |  0.011965169346094484  |  0.0 0.5\n",
      "9 10       |  1 0            | 10 9            |  0.010121880666755345  |  0.0 0.5\n",
      "9 11       |  1 0            | 11 9            |  0.018826671890568747  |  0.0 0.5\n",
      "9 12       |  1 0            | 12 9            |  0.026415291280692088  |  0.0 0.5\n",
      "9 13       |  1 0            | 13 9            |  0.033106801508072436  |  0.0 0.5\n",
      "9 14       |  1 0            | 14 9            |  0.03906482631788677  |  0.0 0.5\n",
      "9 15       |  1 0            | 15 9            |  0.04441428419966087  |  0.0 0.5\n",
      "9 16       |  1 0            | 16 9            |  0.049252359749754504  |  0.0 0.5\n",
      "9 17       |  1 0            | 17 9            |  0.05365591295124972  |  0.0 0.5\n",
      "9 18       |  1 0            | 18 9            |  0.05768661315812906  |  0.0 0.5\n",
      "9 19       |  1 0            | 19 9            |  0.06139457762093414  |  0.0 0.5\n",
      "9 21       |  1 0            | 21 9            |  0.06800009686038422  |  0.0 0.5\n",
      "9 22       |  1 0            | 22 9            |  0.07096053433235383  |  0.0 0.5\n",
      "9 23       |  1 0            | 23 9            |  0.07372654728118988  |  0.0 0.5\n",
      "9 24       |  1 0            | 24 9            |  0.07631877276452315  |  0.0 0.5\n",
      "9 25       |  1 0            | 25 9            |  0.07875490846073419  |  0.0 0.5\n",
      "9 26       |  1 0            | 26 9            |  0.08105022864137723  |  0.0 0.5\n",
      "9 27       |  1 0            | 27 9            |  0.08321799385745265  |  0.0 0.5\n",
      "9 28       |  1 0            | 28 9            |  0.08526977922738155  |  0.0 0.5\n",
      "9 29       |  1 0            | 29 9            |  0.087215739735786  |  0.0 0.5\n",
      "----\n",
      "----\n",
      "DONE 11,11\n"
     ]
    },
    {
=======
   "execution_count": 25,
=======
   "execution_count": 96,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>uid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>last_prediction</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>discount</th>\n",
       "      <th>gain</th>\n",
       "      <th>train_dcg</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_7555</td>\n",
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.083591]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>213.776822</td>\n",
       "      <td>106.888411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1370</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>48.010828</td>\n",
       "      <td>26.458003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1369</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>31.382749</td>\n",
       "      <td>18.143963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1_13258</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>1.292030</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>6.460558</td>\n",
       "      <td>7.448315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1368</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>5.802792</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>43.639845</td>\n",
       "      <td>21.819923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>40</td>\n",
       "      <td>40_37079</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.846078</td>\n",
       "      <td>4.923039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>40</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.903461</td>\n",
       "      <td>4.951730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>40</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.957655</td>\n",
       "      <td>4.978827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>40</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-10.008949</td>\n",
       "      <td>5.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>40</td>\n",
       "      <td>40_43052</td>\n",
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-10.057598</td>\n",
       "      <td>5.028799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid        uid   keywords   docId  grade                features  \\\n",
       "0       1     1_7555      rambo    7555      4  [11.657399, 10.083591]   \n",
       "1       1     1_1370      rambo    1370      3   [9.456276, 13.265001]   \n",
       "2       1     1_1369      rambo    1369      3   [6.036743, 11.113943]   \n",
       "3       1    1_13258      rambo   13258      2         [0.0, 6.869545]   \n",
       "4       1     1_1368      rambo    1368      4        [0.0, 11.113943]   \n",
       "...   ...        ...        ...     ...    ...                     ...   \n",
       "1385   40   40_37079  star wars   37079      0              [0.0, 0.0]   \n",
       "1386   40  40_126757  star wars  126757      0              [0.0, 0.0]   \n",
       "1387   40   40_39797  star wars   39797      0              [0.0, 0.0]   \n",
       "1388   40   40_18112  star wars   18112      0              [0.0, 0.0]   \n",
       "1389   40   40_43052  star wars   43052      0              [0.0, 0.0]   \n",
       "\n",
       "      last_prediction  display_rank  discount       gain  train_dcg  \\\n",
       "0                   0             0  1.000000  15.000000  30.700871   \n",
       "1                   0             1  0.630930   4.416508  30.700871   \n",
       "2                   0             2  0.500000   3.500000  30.700871   \n",
       "3                   0             3  0.430677   1.292030  30.700871   \n",
       "4                   0             4  0.386853   5.802792  30.700871   \n",
       "...               ...           ...       ...        ...        ...   \n",
       "1385                0            25  0.210310   0.000000  30.207651   \n",
       "1386                0            26  0.208015   0.000000  30.207651   \n",
       "1387                0            27  0.205847   0.000000  30.207651   \n",
       "1388                0            28  0.203795   0.000000  30.207651   \n",
       "1389                0             9  0.289065   0.000000  30.207651   \n",
       "\n",
       "            dcg      lambda      weight  \n",
       "0     30.552986  213.776822  106.888411  \n",
       "1     30.552986   48.010828   26.458003  \n",
       "2     30.552986   31.382749   18.143963  \n",
       "3     30.552986    6.460558    7.448315  \n",
       "4     30.552986   43.639845   21.819923  \n",
       "...         ...         ...         ...  \n",
       "1385  30.120435   -9.846078    4.923039  \n",
       "1386  30.120435   -9.903461    4.951730  \n",
       "1387  30.120435   -9.957655    4.978827  \n",
       "1388  30.120435  -10.008949    5.004475  \n",
       "1389  30.120435  -10.057598    5.028799  \n",
       "\n",
       "[1390 rows x 14 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> e7358dd (Use a stable sorting algorithm)
    }
   ],
   "source": [
    "def compute_swaps_scaled_with_weights(query_judgments, axis, metric=dcg, at=10):\n",
    "    \"\"\"Compute the 'lambda' the DCG impact of every query result swapped with every-other query result\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort to see ideal ordering\n",
    "    # This isn't strictly nescesarry, but it's helpful to understand the algorithm\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False, kind='stable').reset_index()\n",
=======
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False).reset_index()\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False, kind='merge_sort').reset_index()\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
    "    query_judgments = query_judgments.sort_values('last_prediction', ascending=False, kind='stable').reset_index()\n",
>>>>>>> bd537d0 (Fix DCG calculation)
    "\n",
    "    # Instead of explicitly 'swapping' we just swap the 'display_rank' - where \n",
    "    # in the final ranking this would be placed. We can easily use that to compute DCG\n",
    "    query_judgments['display_rank'] = query_judgments.index.to_series()\n",
    "    query_judgments['train_dcg'] = query_judgments['dcg'] = metric(query_judgments, at=at)\n",
    "    train_dcg = query_judgments.loc[0, 'dcg']\n",
<<<<<<< HEAD
<<<<<<< HEAD
    " \n",
    "    qid = query_judgments.loc[0, 'qid']\n",
    "    keywords = query_judgments.loc[0, 'keywords']\n",
    "\n",
    "\n",
    "    query_judgments['lambda'] = 0.0\n",
    "    query_judgments['weight'] = 0.0\n",
    "\n",
    "    for better in range(0,len(query_judgments)):\n",
    "         for worse in range(0,len(query_judgments)):\n",
    "            if better > at and worse > at:\n",
    "                return query_judgments\n",
=======
=======
    " \n",
    "    qid = query_judgments.loc[0, 'qid']\n",
    "    keywords = query_judgments.loc[0, 'keywords']\n",
    "\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
    "\n",
    "    query_judgments['lambda'] = 0.0\n",
    "    query_judgments['weight'] = 0.0\n",
    "\n",
    "    for better in range(0,len(query_judgments)):\n",
    "         for worse in range(0,len(query_judgments)):\n",
    "            if better > at and worse > at:\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "                break\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "                if dump:\n",
    "                    print(f\"DONE {better},{worse}\")\n",
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
    "                return query_judgments\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
    "                \n",
    "            if query_judgments.loc[better, 'grade'] > query_judgments.loc[worse, 'grade']:\n",
    "                query_judgments = rank_with_swap(query_judgments, better, worse)\n",
    "                query_judgments['dcg'] = metric(query_judgments, at=at)\n",
    "\n",
    "                dcg_after_swap = query_judgments.loc[0, 'dcg']\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "                delta = abs(train_dcg - dcg_after_swap)\n",
    "\n",
    "                if delta != 0.0:\n",
<<<<<<< HEAD
    "                    last_model_score_diff = query_judgments.loc[better, 'last_prediction'] - query_judgments.loc[worse, 'last_prediction']\n",
    "                    rho = 1.0 / (1.0 + exp(last_model_score_diff)) \n",
=======
    "                delta = train_dcg - dcg_after_swap\n",
=======
    "                delta = abs(train_dcg - dcg_after_swap)\n",
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "\n",
    "                if delta > 0.0:\n",
    "                    last_model_score_diff = query_judgments.loc[better, 'last_prediction'] - query_judgments.loc[worse, 'last_prediction']\n",
    "                    rho = 1.0 / (1.0 + exp(last_model_score_diff))   \n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "                    last_model_score_diff = query_judgments.loc[better, 'last_prediction'] - query_judgments.loc[worse, 'last_prediction']\n",
    "                    rho = 1.0 / (1.0 + exp(last_model_score_diff)) \n",
<<<<<<< HEAD
    "                    if dump:\n",
    "                        print(better, worse, \"      | \",\n",
    "                              query_judgments.loc[better, 'grade'], query_judgments.loc[worse, 'grade'], '           |',\n",
    "                              query_judgments.loc[better, 'display_rank'], query_judgments.loc[worse, 'display_rank'], '           | ', \n",
    "                              delta, ' | ',\n",
    "                              last_model_score_diff, rho)\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
    "\n",
    "                    assert(delta >= 0.0)\n",
    "                    assert(rho >= 0.0)\n",
    "                   \n",
    "                    query_judgments.loc[better, 'lambda'] += delta * rho\n",
    "                    query_judgments.loc[worse, 'lambda'] -= delta * rho\n",
    "            \n",
    "                    # --------------\n",
    "                    # NEW!\n",
    "                    #  last_model_score_diff        rho         weight\n",
    "                    #      0.0                      0.5         0.25 (max possible value)\n",
    "                    #      100.0                    0.0000      0.0  (max possible value)\n",
    "                    # \n",
    "                    # If the current model has an ambiguous prediction, we include more of the delta in the weight\n",
    "                    # If the current model has a strong prediction, weight approaches 0\n",
    "                    query_judgments.loc[better, 'weight'] += rho * (1.0 - rho) * delta;\n",
    "                    query_judgments.loc[worse, 'weight'] += rho * (1.0 - rho) * delta;\n",
    "                    #\n",
    "                    # These will be used to rescale each decision tree node's predictions\n",
    "                    # If many results in a leaf node have last model score ~ ambiguous\n",
    "                    #     the resulting model will have a high denominator ~ (1 / deltaDCG)\n",
    "                    # If many results in a leaf node have last model score - not ambiguous, positive\n",
    "                    #     the resulting model will have a low denominator\n",
    "                    #\n",
    "                    # Apparently we want to cancel out the deltas if last model was ambiguous?\n",
    "                    # ---------------\n",
    "\n",
    "                    \n",
    "\n",
    "    return query_judgments\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 95bbadd (use absolute value in delta calculatio)
    "# Convert to Pandas Dataframe\n",
    "judgments = to_dataframe(ftr_logger.logged)\n",
    "judgments['last_prediction'] = 0\n",
    "lambdas_per_query = judgments.groupby('qid').apply(compute_swaps_scaled_with_weights, axis=1)\n",
    "lambdas_per_query = lambdas_per_query.drop('qid', axis=1).reset_index().drop(['level_1', 'index'], axis=1)\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
    "lambdas_per_query = judgments.groupby('qid').apply(compute_swaps_scaled_with_weights, axis=1)\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "print(\"ROUND TWO\")\n",
    "print(\"---------\")\n",
    "\n",
    "features = lambdas_per_query['features'].tolist()\n",
    "tree = DecisionTreeRegressor(max_leaf_nodes=4)\n",
    "tree.fit(features, lambdas_per_query['lambda'])    \n",
    "\n",
    "\n",
    "lambdas_per_query['path'] = tree_paths(tree, features)\n",
    "predictions = lambdas_per_query.groupby('path')['lambda'].sum() / lambdas_per_query.groupby('path')['weight'].sum()\n",
    "predictions = predictions.fillna(0.0) # for divide by 0\n",
    "\n",
    "# -------------------\n",
    "#4. Add to ensemble, recreate last prediction\n",
    "new_tree = OverridenRegressionTree(predictions=predictions, tree=tree)\n",
    "ensemble.append(new_tree)\n",
    "next_predictions = new_tree.predict(features, use_original=True)\n",
    "lambdas_per_query['last_prediction'] += (next_predictions * learning_rate) \n",
    "        \n",
    "lambdas_per_query = lambdas_per_query.groupby('qid').apply(compute_swaps_scaled_with_weights, axis=1, dump=True)\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
    "\n",
    "lambdas_per_query"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 97,
=======
   "execution_count": 389,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 535,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=4)"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 97,
=======
     "execution_count": 389,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 535,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": 185,
=======
   "execution_count": 215,
>>>>>>> bd537d0 (Fix DCG calculation)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>qid</th>\n",
       "      <th>uid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>last_prediction</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>discount</th>\n",
       "      <th>gain</th>\n",
       "      <th>train_dcg</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
       "      <th>weight</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3_26508</td>\n",
       "      <td>war games</td>\n",
       "      <td>26508</td>\n",
       "      <td>0</td>\n",
       "      <td>[11.566039, 7.2067547]</td>\n",
       "      <td>0.190016</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.509695</td>\n",
       "      <td>0.627486</td>\n",
       "      <td>1010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3_19855</td>\n",
       "      <td>war games</td>\n",
       "      <td>19855</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.7652884, 3.404544]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>29</td>\n",
       "      <td>0.201849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.501782</td>\n",
       "      <td>0.750891</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3_10428</td>\n",
       "      <td>war games</td>\n",
       "      <td>10428</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>22</td>\n",
       "      <td>0.218104</td>\n",
       "      <td>0.218104</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.444889</td>\n",
       "      <td>0.722445</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3_12699</td>\n",
       "      <td>war games</td>\n",
       "      <td>12699</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>23</td>\n",
       "      <td>0.215338</td>\n",
       "      <td>0.215338</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.454570</td>\n",
       "      <td>0.727285</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3_136698</td>\n",
       "      <td>war games</td>\n",
       "      <td>136698</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>24</td>\n",
       "      <td>0.212746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.463643</td>\n",
       "      <td>0.731821</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3_1557</td>\n",
       "      <td>war games</td>\n",
       "      <td>1557</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.472169</td>\n",
       "      <td>0.736085</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3_19433</td>\n",
       "      <td>war games</td>\n",
       "      <td>19433</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.480203</td>\n",
       "      <td>0.740102</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3_10431</td>\n",
       "      <td>war games</td>\n",
       "      <td>10431</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.7652884, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.487790</td>\n",
       "      <td>0.743895</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3_222461</td>\n",
       "      <td>war games</td>\n",
       "      <td>222461</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>28</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.494971</td>\n",
       "      <td>0.747486</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>3_208988</td>\n",
       "      <td>war games</td>\n",
       "      <td>208988</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.7652884, 3.7722988]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>30</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.508254</td>\n",
       "      <td>0.754127</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3_10951</td>\n",
       "      <td>war games</td>\n",
       "      <td>10951</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>20</td>\n",
       "      <td>0.224244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.423401</td>\n",
       "      <td>0.711700</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3_12180</td>\n",
       "      <td>war games</td>\n",
       "      <td>12180</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.912464, 3.8183646]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>31</td>\n",
       "      <td>0.198240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.514415</td>\n",
       "      <td>0.757207</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>3_10253</td>\n",
       "      <td>war games</td>\n",
       "      <td>10253</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.912464, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>32</td>\n",
       "      <td>0.196562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.520288</td>\n",
       "      <td>0.760144</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>3_11</td>\n",
       "      <td>war games</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.487882, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>33</td>\n",
       "      <td>0.194959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.525898</td>\n",
       "      <td>0.762949</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>3_2649</td>\n",
       "      <td>war games</td>\n",
       "      <td>2649</td>\n",
       "      <td>0</td>\n",
       "      <td>[7.4929605, 3.7447038]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>34</td>\n",
       "      <td>0.193426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.531262</td>\n",
       "      <td>0.765631</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>3_6917</td>\n",
       "      <td>war games</td>\n",
       "      <td>6917</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>35</td>\n",
       "      <td>0.191959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.536399</td>\n",
       "      <td>0.768199</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>3_20158</td>\n",
       "      <td>war games</td>\n",
       "      <td>20158</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>36</td>\n",
       "      <td>0.190551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.541324</td>\n",
       "      <td>0.770662</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>3_76875</td>\n",
       "      <td>war games</td>\n",
       "      <td>76875</td>\n",
       "      <td>0</td>\n",
       "      <td>[7.4929605, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>37</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.546053</td>\n",
       "      <td>0.773026</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3_126148</td>\n",
       "      <td>war games</td>\n",
       "      <td>126148</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>21</td>\n",
       "      <td>0.221065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.434528</td>\n",
       "      <td>0.717264</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>3_91893</td>\n",
       "      <td>war games</td>\n",
       "      <td>91893</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>19</td>\n",
       "      <td>0.227670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.411408</td>\n",
       "      <td>0.705704</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>3_14154</td>\n",
       "      <td>war games</td>\n",
       "      <td>14154</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.395574, 4.1198707]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>48.233180</td>\n",
       "      <td>25.251649</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3_293767</td>\n",
       "      <td>war games</td>\n",
       "      <td>293767</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.1965258]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>9</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.196527</td>\n",
       "      <td>0.598264</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>3_365371</td>\n",
       "      <td>war games</td>\n",
       "      <td>365371</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.822857, 3.9629867]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-0.458254</td>\n",
       "      <td>0.229127</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>3_116059</td>\n",
       "      <td>war games</td>\n",
       "      <td>116059</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.5915227]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-0.700886</td>\n",
       "      <td>0.350443</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>3_335988</td>\n",
       "      <td>war games</td>\n",
       "      <td>335988</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.4955344]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-0.854269</td>\n",
       "      <td>0.427135</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>3_354287</td>\n",
       "      <td>war games</td>\n",
       "      <td>354287</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.487882, 4.4331245]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>5</td>\n",
       "      <td>0.356207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-0.961529</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3_390054</td>\n",
       "      <td>war games</td>\n",
       "      <td>390054</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.041587</td>\n",
       "      <td>0.520794</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>3_346672</td>\n",
       "      <td>war games</td>\n",
       "      <td>346672</td>\n",
       "      <td>0</td>\n",
       "      <td>[4.616252, 2.8177607]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>7</td>\n",
       "      <td>0.315465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.104127</td>\n",
       "      <td>0.552064</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>3_369885</td>\n",
       "      <td>war games</td>\n",
       "      <td>369885</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.404544]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>8</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.154649</td>\n",
       "      <td>0.577325</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>3_381288</td>\n",
       "      <td>war games</td>\n",
       "      <td>381288</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 2.4952173]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>11</td>\n",
       "      <td>0.270238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.231954</td>\n",
       "      <td>0.615977</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>3_24964</td>\n",
       "      <td>war games</td>\n",
       "      <td>24964</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>18</td>\n",
       "      <td>0.231378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.398430</td>\n",
       "      <td>0.699215</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>3_860</td>\n",
       "      <td>war games</td>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 6.025596]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>4.184144</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>1.262421</td>\n",
       "      <td>0.631210</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>3_9614</td>\n",
       "      <td>war games</td>\n",
       "      <td>9614</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>12</td>\n",
       "      <td>0.262650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.288981</td>\n",
       "      <td>0.644490</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>3_125842</td>\n",
       "      <td>war games</td>\n",
       "      <td>125842</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>13</td>\n",
       "      <td>0.255958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.312401</td>\n",
       "      <td>0.656201</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>3_427760</td>\n",
       "      <td>war games</td>\n",
       "      <td>427760</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>14</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.333254</td>\n",
       "      <td>0.666627</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>3_4247</td>\n",
       "      <td>war games</td>\n",
       "      <td>4247</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>15</td>\n",
       "      <td>0.244651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.351977</td>\n",
       "      <td>0.675989</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>3_30335</td>\n",
       "      <td>war games</td>\n",
       "      <td>30335</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>16</td>\n",
       "      <td>0.239812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.368911</td>\n",
       "      <td>0.684455</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>3_10207</td>\n",
       "      <td>war games</td>\n",
       "      <td>10207</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>17</td>\n",
       "      <td>0.235409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.384323</td>\n",
       "      <td>0.692161</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>3_144910</td>\n",
       "      <td>war games</td>\n",
       "      <td>144910</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.5033813, 1.8313766]</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>38</td>\n",
       "      <td>0.187902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>-1.550598</td>\n",
       "      <td>0.775299</td>\n",
       "      <td>1101000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  qid       uid   keywords   docId  grade                features  \\\n",
       "0     115    3   3_26508  war games   26508      0  [11.566039, 7.2067547]   \n",
       "29    110    3   3_19855  war games   19855      0   [6.7652884, 3.404544]   \n",
       "22    103    3   3_10428  war games   10428      1              [0.0, 0.0]   \n",
       "23    104    3   3_12699  war games   12699      1              [0.0, 0.0]   \n",
       "24    105    3  3_136698  war games  136698      0              [0.0, 0.0]   \n",
       "25    106    3    3_1557  war games    1557      1              [0.0, 0.0]   \n",
       "26    107    3   3_19433  war games   19433      1              [0.0, 0.0]   \n",
       "27    108    3   3_10431  war games   10431      0        [6.7652884, 0.0]   \n",
       "28    109    3  3_222461  war games  222461      0              [0.0, 0.0]   \n",
       "30    111    3  3_208988  war games  208988      0  [6.7652884, 3.7722988]   \n",
       "20    101    3   3_10951  war games   10951      0              [0.0, 0.0]   \n",
       "31    112    3   3_12180  war games   12180      0   [5.912464, 3.8183646]   \n",
       "32    113    3   3_10253  war games   10253      0         [5.912464, 0.0]   \n",
       "33    114    3      3_11  war games      11      0         [5.487882, 0.0]   \n",
       "34    116    3    3_2649  war games    2649      0  [7.4929605, 3.7447038]   \n",
       "35    117    3    3_6917  war games    6917      0              [0.0, 0.0]   \n",
       "36    118    3   3_20158  war games   20158      0              [0.0, 0.0]   \n",
       "37    119    3   3_76875  war games   76875      0        [7.4929605, 0.0]   \n",
       "21    102    3  3_126148  war games  126148      0              [0.0, 0.0]   \n",
       "19    100    3   3_91893  war games   91893      0              [0.0, 0.0]   \n",
       "1      82    3   3_14154  war games   14154      3   [8.395574, 4.1198707]   \n",
       "9      90    3  3_293767  war games  293767      0        [0.0, 3.1965258]   \n",
       "2      83    3  3_365371  war games  365371      0   [2.822857, 3.9629867]   \n",
       "3      84    3  3_116059  war games  116059      0        [0.0, 3.5915227]   \n",
       "4      85    3  3_335988  war games  335988      0        [0.0, 3.4955344]   \n",
       "5      86    3  3_354287  war games  354287      0   [5.487882, 4.4331245]   \n",
       "6      87    3  3_390054  war games  390054      0              [0.0, 0.0]   \n",
       "7      88    3  3_346672  war games  346672      0   [4.616252, 2.8177607]   \n",
       "8      89    3  3_369885  war games  369885      0         [0.0, 3.404544]   \n",
       "10     91    3  3_381288  war games  381288      0        [0.0, 2.4952173]   \n",
       "18     99    3   3_24964  war games   24964      0              [0.0, 0.0]   \n",
       "11     92    3     3_860  war games     860      4         [0.0, 6.025596]   \n",
       "12     93    3    3_9614  war games    9614      0              [0.0, 0.0]   \n",
       "13     94    3  3_125842  war games  125842      0              [0.0, 0.0]   \n",
       "14     95    3  3_427760  war games  427760      0              [0.0, 0.0]   \n",
       "15     96    3    3_4247  war games    4247      0              [0.0, 0.0]   \n",
       "16     97    3   3_30335  war games   30335      0              [0.0, 0.0]   \n",
       "17     98    3   3_10207  war games   10207      0              [0.0, 0.0]   \n",
       "38    120    3  3_144910  war games  144910      0  [3.5033813, 1.8313766]   \n",
       "\n",
       "    last_prediction  display_rank  discount      gain  train_dcg       dcg  \\\n",
       "0          0.190016             0  1.000000  0.000000   4.416508  4.416508   \n",
       "29        -0.150691            29  0.201849  0.000000   4.416508  4.416508   \n",
       "22        -0.150691            22  0.218104  0.218104   4.416508  4.416508   \n",
       "23        -0.150691            23  0.215338  0.215338   4.416508  4.416508   \n",
       "24        -0.150691            24  0.212746  0.000000   4.416508  4.416508   \n",
       "25        -0.150691            25  0.210310  0.210310   4.416508  4.416508   \n",
       "26        -0.150691            26  0.208015  0.208015   4.416508  4.416508   \n",
       "27        -0.150691            27  0.205847  0.000000   4.416508  4.416508   \n",
       "28        -0.150691            28  0.203795  0.000000   4.416508  4.416508   \n",
       "30        -0.150691            30  0.200000  0.000000   4.416508  4.416508   \n",
       "20        -0.150691            20  0.224244  0.000000   4.416508  4.416508   \n",
       "31        -0.150691            31  0.198240  0.000000   4.416508  4.416508   \n",
       "32        -0.150691            32  0.196562  0.000000   4.416508  4.416508   \n",
       "33        -0.150691            33  0.194959  0.000000   4.416508  4.416508   \n",
       "34        -0.150691            34  0.193426  0.000000   4.416508  4.416508   \n",
       "35        -0.150691            35  0.191959  0.000000   4.416508  4.416508   \n",
       "36        -0.150691            36  0.190551  0.000000   4.416508  4.416508   \n",
       "37        -0.150691            37  0.189200  0.000000   4.416508  4.416508   \n",
       "21        -0.150691            21  0.221065  0.000000   4.416508  4.416508   \n",
       "19        -0.150691            19  0.227670  0.000000   4.416508  4.416508   \n",
       "1         -0.150691             1  0.630930  4.416508   4.416508  4.416508   \n",
       "9         -0.150691             9  0.289065  0.000000   4.416508  4.416508   \n",
       "2         -0.150691             2  0.500000  0.000000   4.416508  4.416508   \n",
       "3         -0.150691             3  0.430677  0.000000   4.416508  4.416508   \n",
       "4         -0.150691             4  0.386853  0.000000   4.416508  4.416508   \n",
       "5         -0.150691             5  0.356207  0.000000   4.416508  4.416508   \n",
       "6         -0.150691             6  0.333333  0.000000   4.416508  4.416508   \n",
       "7         -0.150691             7  0.315465  0.000000   4.416508  4.416508   \n",
       "8         -0.150691             8  0.301030  0.000000   4.416508  4.416508   \n",
       "10        -0.150691            11  0.270238  0.000000   4.416508  4.416508   \n",
       "18        -0.150691            18  0.231378  0.000000   4.416508  4.416508   \n",
       "11        -0.150691            10  0.278943  4.184144   4.416508  4.416508   \n",
       "12        -0.150691            12  0.262650  0.000000   4.416508  4.416508   \n",
       "13        -0.150691            13  0.255958  0.000000   4.416508  4.416508   \n",
       "14        -0.150691            14  0.250000  0.000000   4.416508  4.416508   \n",
       "15        -0.150691            15  0.244651  0.000000   4.416508  4.416508   \n",
       "16        -0.150691            16  0.239812  0.000000   4.416508  4.416508   \n",
       "17        -0.150691            17  0.235409  0.000000   4.416508  4.416508   \n",
       "38        -0.150691            38  0.187902  0.000000   4.416508  4.416508   \n",
       "\n",
       "       lambda     weight     path  \n",
       "0   -1.509695   0.627486  1010010  \n",
       "29  -1.501782   0.750891  1101000  \n",
       "22  -1.444889   0.722445  1101000  \n",
       "23  -1.454570   0.727285  1101000  \n",
       "24  -1.463643   0.731821  1101000  \n",
       "25  -1.472169   0.736085  1101000  \n",
       "26  -1.480203   0.740102  1101000  \n",
       "27  -1.487790   0.743895  1101000  \n",
       "28  -1.494971   0.747486  1101000  \n",
       "30  -1.508254   0.754127  1101000  \n",
       "20  -1.423401   0.711700  1101000  \n",
       "31  -1.514415   0.757207  1101000  \n",
       "32  -1.520288   0.760144  1101000  \n",
       "33  -1.525898   0.762949  1101000  \n",
       "34  -1.531262   0.765631  1101000  \n",
       "35  -1.536399   0.768199  1101000  \n",
       "36  -1.541324   0.770662  1101000  \n",
       "37  -1.546053   0.773026  1101000  \n",
       "21  -1.434528   0.717264  1101000  \n",
       "19  -1.411408   0.705704  1101000  \n",
       "1   48.233180  25.251649  1101000  \n",
       "9   -1.196527   0.598264  1101000  \n",
       "2   -0.458254   0.229127  1101000  \n",
       "3   -0.700886   0.350443  1101000  \n",
       "4   -0.854269   0.427135  1101000  \n",
       "5   -0.961529   0.480764  1101000  \n",
       "6   -1.041587   0.520794  1101000  \n",
       "7   -1.104127   0.552064  1101000  \n",
       "8   -1.154649   0.577325  1101000  \n",
       "10  -1.231954   0.615977  1101000  \n",
       "18  -1.398430   0.699215  1101000  \n",
       "11   1.262421   0.631210  1101000  \n",
       "12  -1.288981   0.644490  1101000  \n",
       "13  -1.312401   0.656201  1101000  \n",
       "14  -1.333254   0.666627  1101000  \n",
       "15  -1.351977   0.675989  1101000  \n",
       "16  -1.368911   0.684455  1101000  \n",
       "17  -1.384323   0.692161  1101000  \n",
       "38  -1.550598   0.775299  1101000  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas_per_query.loc[3, :].sort_values('last_prediction', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
=======
   "execution_count": 29,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 97,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=4)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> e7358dd (Use a stable sorting algorithm)
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "train_set = lambdas_per_query[['lambda', 'features']]\n",
    "train_set\n",
    "\n",
    "tree3 = DecisionTreeRegressor(max_leaf_nodes=4)\n",
    "tree3.fit(train_set['features'].tolist(), train_set['lambda'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
    "### Label each row with its unique prediction (ie tree path)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 98,
=======
   "execution_count": 542,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 187,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 217,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 30,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 98,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_paths(tree, X):\n",
    "    paths_as_array = tree.decision_path(X).toarray()\n",
    "    paths = [\"\".join(item) for item in paths_as_array.astype(str)]\n",
    "    return paths\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "lambdas_per_query['path'] = tree_paths(tree3, train_set['features'].tolist())"
=======
    "lambdas_per_query['path'] = tree_paths(tree3, features)"
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
    "lambdas_per_query['path'] = tree_paths(tree3, train_set['features'].tolist())"
>>>>>>> e7358dd (Use a stable sorting algorithm)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
>>>>>>> 4ef4e05 (Save lambda mart)
=======
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
    "### Override outputs using our own weighted average\n",
    "\n",
    "The typical decision tree uses either the [median or mean of the target values](https://scikit-learn.org/stable/modules/tree.html#regression-criteria) classified to a given leaf node as the prediction. However, in the case of lambdaMART, we want to use a weighted average that accounts for how much of the DCG error out there has been accounted for. Thus the psuedoresponses are summed and divided by the remaining error DCG.\n",
    "\n",
    "rho=0, then an example is weighed by `1/0.25*deltaNDCG` as there's a lot of outstanding DCG error left."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path\n",
       "1010001    1673.720249\n",
       "1010010    1467.050422\n",
       "1100100     538.598514\n",
       "1101000    4655.114588\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
=======
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-474-421c2af06928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlambdas_per_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'groupby'"
     ]
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 543,
=======
   "execution_count": 188,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 218,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 31,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 99,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path\n",
       "1010001    1673.720249\n",
       "1010010    1467.050422\n",
       "1100100     538.598514\n",
       "1101000    4655.114588\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
    }
   ],
   "source": [
    "lambdas_per_query.groupby('path')['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 100,
=======
   "execution_count": 393,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 544,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 189,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 219,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 32,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 100,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "1010001    3334.073882\n",
       "1010010    2787.629391\n",
       "1100100     893.120752\n",
       "1101000   -7014.824025\n",
<<<<<<< HEAD
       "Name: lambda, dtype: float64"
      ]
     },
     "execution_count": 100,
=======
       "1010101     21.084755\n",
       "1010110     26.392483\n",
=======
       "1010101     50.899615\n",
       "1010110     34.429523\n",
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
       "1011000     78.211815\n",
       "1100000   -163.540952\n",
       "Name: lambda, dtype: float64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 393,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 544,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
       "1010001    1258.452118\n",
       "1010010    1047.308463\n",
       "1100100     344.116290\n",
       "1101000   -2649.876872\n",
       "Name: lambda, dtype: float64"
      ]
     },
     "execution_count": 189,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "1010001    3062.805039\n",
       "1010010    2234.978630\n",
       "1100100     973.921128\n",
       "1101000   -6271.704798\n",
       "Name: lambda, dtype: float64"
      ]
     },
     "execution_count": 219,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
       "Name: lambda, dtype: float64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 32,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 100,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas_per_query.groupby('path')['lambda'].sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 101,
=======
   "execution_count": 394,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 545,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 190,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": 220,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 33,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 101,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
       "{'1010001': 1.9920138295288714,\n",
       " '1010010': 1.9001592234365985,\n",
       " '1100100': 1.658230999946508,\n",
       " '1101000': -1.5069068425436136}"
<<<<<<< HEAD
      ]
     },
     "execution_count": 101,
=======
       "{'1010101': 0.7250098367343205,\n",
       " '1010110': 1.9965848868529685,\n",
=======
       "{'1010101': 1.2156213554683677,\n",
       " '1010110': 1.989574489468554,\n",
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
       " '1011000': 2.0,\n",
       " '1100000': -1.25839909859753}"
      ]
     },
<<<<<<< HEAD
     "execution_count": 394,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 545,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
       "{'1010001': 1.7082490575792086,\n",
       " '1010010': 1.6577480195599843,\n",
       " '1100100': 1.529716742261577,\n",
       " '1101000': -1.2715166988494222}"
      ]
     },
     "execution_count": 190,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "{'1010001': 1.7020283776078502,\n",
       " '1010010': 1.6439358780484803,\n",
       " '1100100': 1.5034989256812759,\n",
       " '1101000': -1.3363099128340716}"
      ]
     },
     "execution_count": 220,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
       "{'1010001': 1.9920138295288718,\n",
       " '1010010': 1.9001592234365976,\n",
       " '1100100': 1.6582309999465077,\n",
       " '1101000': -1.5069068425436145}"
      ]
     },
     "execution_count": 33,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
      ]
     },
     "execution_count": 101,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_predictions = lambdas_per_query.groupby('path')['lambda'].sum() / lambdas_per_query.groupby('path')['weight'].sum()\n",
    "round_predictions.to_dict()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 102,
=======
   "execution_count": 395,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 546,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 191,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": null,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 34,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 102,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
       "[Text(167.4, 181.2, 'X[0] <= 10.328\\nmse = 883.211\\nsamples = 1390\\nvalue = -0.0'),\n",
       " Text(83.7, 108.72, 'X[0] <= 9.182\\nmse = 179.235\\nsamples = 1324\\nvalue = -4.624'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 62.9\\nsamples = 1301\\nvalue = -5.392'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 4838.036\\nsamples = 23\\nvalue = 38.831'),\n",
       " Text(251.10000000000002, 108.72, 'X[0] <= 13.782\\nmse = 5973.405\\nsamples = 66\\nvalue = 92.753'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 5828.45\\nsamples = 39\\nvalue = 71.478'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 4584.565\\nsamples = 27\\nvalue = 123.484')]"
<<<<<<< HEAD
      ]
     },
     "execution_count": 102,
=======
       "[Text(111.60000000000001, 190.26, 'X[0] <= 8.205\\nmse = 5.779\\nsamples = 1390\\nvalue = -0.0'),\n",
       " Text(55.800000000000004, 135.9, 'mse = 0.912\\nsamples = 1246\\nvalue = -0.101'),\n",
       " Text(167.4, 135.9, 'X[0] <= 8.242\\nmse = 47.043\\nsamples = 144\\nvalue = 0.873'),\n",
       " Text(111.60000000000001, 81.53999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 78.212'),\n",
       " Text(223.20000000000002, 81.53999999999999, 'X[0] <= 8.4\\nmse = 5.252\\nsamples = 143\\nvalue = 0.332'),\n",
       " Text(167.4, 27.180000000000007, 'mse = 53.276\\nsamples = 12\\nvalue = 2.199'),\n",
       " Text(279.0, 27.180000000000007, 'mse = 0.504\\nsamples = 131\\nvalue = 0.161')]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 395,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
     "execution_count": 546,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
       "[Text(167.4, 181.2, 'X[0] <= 10.328\\nmse = 115.263\\nsamples = 1390\\nvalue = 0.0'),\n",
       " Text(83.7, 108.72, 'X[0] <= 9.182\\nmse = 25.618\\nsamples = 1324\\nvalue = -1.742'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 11.202\\nsamples = 1301\\nvalue = -2.037'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 557.146\\nsamples = 23\\nvalue = 14.962'),\n",
       " Text(251.10000000000002, 108.72, 'X[0] <= 13.782\\nmse = 632.245\\nsamples = 66\\nvalue = 34.936'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 669.361\\nsamples = 39\\nvalue = 26.854'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 348.018\\nsamples = 27\\nvalue = 46.609')]"
      ]
     },
     "execution_count": 191,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "[Text(167.4, 181.2, 'X[0] <= 10.666\\nmse = 671.843\\nsamples = 1390\\nvalue = -0.0'),\n",
       " Text(83.7, 108.72, 'X[0] <= 9.182\\nmse = 149.122\\nsamples = 1329\\nvalue = -3.986'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 52.282\\nsamples = 1301\\nvalue = -4.821'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 3113.338\\nsamples = 28\\nvalue = 34.783'),\n",
       " Text(251.10000000000002, 108.72, 'X[0] <= 13.782\\nmse = 4171.35\\nsamples = 61\\nvalue = 86.849'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 4449.08\\nsamples = 34\\nvalue = 65.735'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 2553.287\\nsamples = 27\\nvalue = 113.437')]"
      ]
     },
     "execution_count": 221,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
      ]
     },
<<<<<<< HEAD
     "execution_count": 34,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 102,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "image/png": "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\n",
=======
      "image/png": "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\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
      "image/png": "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\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
      "image/png": "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\n",
>>>>>>> bd537d0 (Fix DCG calculation)
=======
      "image/png": "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\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(tree3)"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap the original tree, and provide new value\n",
    "\n",
    "Instead of directly using the provided decision tree, we want to use our prediction for each leaf. This `OverridenDecisionTree` takes the original tree, looks up the prediction path in the original tree, but uses our values for the predicted variable instead of what's here."
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 103,
=======
   "cell_type": "code",
   "execution_count": 473,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 547,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 192,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
   "execution_count": null,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": 35,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
   "execution_count": 103,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "array([-1.50690684,  1.658231  ])"
      ]
     },
     "execution_count": 103,
=======
       "array([-0.85598879,  0.72500984])"
      ]
     },
     "execution_count": 473,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "array([-1.2583991 ,  1.21562136])"
      ]
     },
     "execution_count": 547,
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
       "array([-1.2715167 ,  1.52971674])"
      ]
     },
     "execution_count": 192,
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
       "array([-1.33630991,  1.50349893])"
      ]
     },
     "execution_count": 222,
>>>>>>> bd537d0 (Fix DCG calculation)
=======
       "array([-1.50690684,  1.658231  ])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 35,
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
     "execution_count": 103,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OverridenRegressionTree:\n",
    "    def __init__(self, predictions, tree):\n",
    "        self.predictions = predictions\n",
    "        self.tree = tree\n",
    "        \n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    def predict(self, X, use_original=False):\n",
    "        if use_original:\n",
    "            return self.predict(X)\n",
=======
    "    def predict(self, X):\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "    def predict(self, X, use_original=False):\n",
    "        if use_original:\n",
    "            return self.predict(X)\n",
>>>>>>> e7358dd (Use a stable sorting algorithm)
    "        path = self.tree.decision_path(X).toarray().astype(str)\n",
    "        path = \"\".join(path[0])\n",
    "        \n",
    "        paths_as_array = self.tree.decision_path(X).toarray()\n",
    "        paths = [\"\".join(item) for item in paths_as_array.astype(str)]\n",
    "        \n",
    "        predictions = self.predictions[paths]\n",
    "        \n",
    "        # Any NaN predictions is a red flag, debug\n",
    "        if np.any(predictions.isnull()):\n",
    "            print(predictions[predictions.isnull()])\n",
    "            print(pd.DataFrame(X)[predictions.isnull().reset_index(drop=True)])\n",
    "            raise AssertionError(\"No prediction should be NaN\")\n",
    "        return np.array(self.predictions[paths].tolist())\n",
    "        \n",
    "override_tree = OverridenRegressionTree(predictions = round_predictions, tree=tree3)\n",
    "override_tree.predict([[0.0, 6.869545], [10.0, 10.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Four - Putting it all together, from the top!\n",
    "\n",
    "Now we can put together the full lambdamart algorithm that \n",
    "\n",
    "1. Uses pair-wise swaps on our our metric (ie DCG) to generate decision tree predictors (the 'lambdas')\n",
    "2. Focuses in on predicting where current model makes the wrong call when ranking by DCG\n",
    "3. Predicts using a weighted average, weighed by 1 / (remaining DCG)\n",
    "\n",
    "TODOs / known issues\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "* While DCG converges, it does sometimes wander a tad, so there might be more room for improvement\n",
=======
    "* Why is DCG performance so different from Ranklib, and it seems to wander around more (precision does this)\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "* While DCG converges, it does sometimes wander a tad, so there might be more room for improvement\n",
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
    "* Speeding up the inner loop of the `compute_swaps_scaled_with_weights` that must run for ever query's swaps"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 104,
=======
   "execution_count": 470,
>>>>>>> 4ef4e05 (Save lambda mart)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'qid', 'keywords', 'docId', 'grade', 'features'], dtype='object')\n",
      "round 0\n",
      "Train DCGs\n",
<<<<<<< HEAD
      "mean    20.03521601393222\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 1\n",
      "Train DCGs\n",
      "mean    20.572514984109958\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 2\n",
      "Train DCGs\n",
      "mean    20.572514984109958\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 3\n",
      "Train DCGs\n",
      "mean    20.572514984109958\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 4\n",
      "Train DCGs\n",
      "mean    20.558839639948378\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-285d00895833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mjudgments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftr_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mlambdas_per_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_mart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudgments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjudgments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-285d00895833>\u001b[0m in \u001b[0;36mlambda_mart\u001b[0;34m(judgments, rounds, learning_rate, max_leaf_nodes, metric)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# ------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#1. Build pair-wise predictors for this round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         lambdas_per_query = lambdas_per_query.groupby('qid').apply(compute_swaps_scaled_with_weights, \n\u001b[0m\u001b[1;32m     32\u001b[0m                                                                    axis=1, metric=dcg)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \"\"\"\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mresult_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, sdata, names)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;31m# must return keys::list, values::list, mutated::bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1257\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnanops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nan\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-10840cc48db9>\u001b[0m in \u001b[0;36mcompute_swaps_scaled_with_weights\u001b[0;34m(query_judgments, axis, metric, at)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mquery_judgments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mquery_judgments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1815\u001b[0m             \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_2d_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0;31m# set the item, possibly having a dtype change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m             \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m             \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m             \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5931\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5932\u001b[0m         \"\"\"\n\u001b[0;32m-> 5933\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5934\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;31m# ---------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block_same_class\u001b[0;34m(self, values, placement)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# We assume maybe_coerce_values has already been called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
      "mean    10.61593108150268\n",
      "median  10.739621334025406\n",
      "----------\n",
      "round 1\n",
      "Train DCGs\n",
      "mean    14.34966497096901\n",
      "median  13.216212771507438\n",
      "----------\n",
      "round 2\n",
      "Train DCGs\n",
      "mean    12.357610149958038\n",
      "median  11.567827400752915\n",
      "----------\n",
      "round 3\n",
      "Train DCGs\n",
      "mean    14.24721713178369\n",
      "median  13.016486241731291\n",
      "----------\n",
      "round 4\n",
      "Train DCGs\n",
      "mean    13.441858214366144\n",
      "median  12.506165082920402\n",
      "----------\n",
      "round 5\n",
      "Train DCGs\n",
      "mean    14.091782646778626\n",
      "median  13.016486241731291\n",
      "----------\n",
      "round 6\n",
      "Train DCGs\n",
      "mean    13.426222703083178\n",
      "median  12.460843740423556\n",
      "----------\n",
      "round 7\n",
      "Train DCGs\n",
      "mean    14.008223263605812\n",
      "median  13.016486241731291\n",
      "----------\n",
      "round 8\n",
      "Train DCGs\n",
      "mean    13.434549080998451\n",
      "median  12.346789866126002\n",
      "----------\n",
      "round 9\n",
      "Train DCGs\n",
      "mean    13.862740868310802\n",
      "median  12.615453090513515\n",
      "----------\n"
>>>>>>> 4ef4e05 (Save lambda mart)
     ]
    }
   ],
=======
   "execution_count": null,
=======
   "execution_count": 104,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [],
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 548,
=======
   "execution_count": null,
>>>>>>> e7358dd (Use a stable sorting algorithm)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'qid', 'keywords', 'docId', 'grade', 'features'], dtype='object')\n",
      "round 0\n",
      "Train DCGs\n",
      "mean    20.03521601393222\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 1\n",
      "Train DCGs\n",
      "mean    20.572514984109958\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 2\n",
      "Train DCGs\n",
      "mean    20.572514984109958\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 3\n",
      "Train DCGs\n",
      "mean    20.572514984109958\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 4\n",
      "Train DCGs\n",
      "mean    20.558839639948378\n",
      "median  18.543559338088343\n",
      "----------\n",
      "round 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-285d00895833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mjudgments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftr_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mlambdas_per_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_mart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudgments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjudgments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-285d00895833>\u001b[0m in \u001b[0;36mlambda_mart\u001b[0;34m(judgments, rounds, learning_rate, max_leaf_nodes, metric)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# ------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#1. Build pair-wise predictors for this round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         lambdas_per_query = lambdas_per_query.groupby('qid').apply(compute_swaps_scaled_with_weights, \n\u001b[0m\u001b[1;32m     32\u001b[0m                                                                    axis=1, metric=dcg)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \"\"\"\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0msdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mresult_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, sdata, names)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;31m# must return keys::list, values::list, mutated::bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1257\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnanops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nan\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-10840cc48db9>\u001b[0m in \u001b[0;36mcompute_swaps_scaled_with_weights\u001b[0;34m(query_judgments, axis, metric, at)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mquery_judgments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mquery_judgments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1815\u001b[0m             \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_2d_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0;31m# set the item, possibly having a dtype change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m             \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m             \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m             \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5931\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5932\u001b[0m         \"\"\"\n\u001b[0;32m-> 5933\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5934\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;31m# ---------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block_same_class\u001b[0;34m(self, values, placement)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# We assume maybe_coerce_values has already been called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
>>>>>>> 95bbadd (use absolute value in delta calculatio)
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "\n",
    "def predict(ensemble, X, learning_rate=0.1):\n",
    "    prediction = 0\n",
    "    for tree in ensemble:\n",
    "        prediction += tree.predict(X) * learning_rate\n",
    "    return prediction.rename('prediction')\n",
    "\n",
    "\n",
    "def tree_paths(tree, X):\n",
    "    paths_as_array = tree.decision_path(X).toarray()\n",
    "    paths = [\"\".join(item) for item in paths_as_array.astype(str)]\n",
    "    return paths\n",
    "\n",
    "ensemble=[]\n",
    "def lambda_mart(judgments, rounds=20, learning_rate=0.1, max_leaf_nodes=8, metric=dcg):\n",
    "\n",
    "    print(judgments.columns)\n",
    "    # Convert to Pandas Dataframe\n",
    "    lambdas_per_query = judgments.copy()\n",
    "\n",
    "\n",
    "    lambdas_per_query['last_prediction'] = 0.0\n",
    "\n",
    "    for i in range(0, rounds):\n",
    "        print(f\"round {i}\")\n",
    "\n",
    "        # ------------------\n",
    "        #1. Build pair-wise predictors for this round\n",
    "        lambdas_per_query = lambdas_per_query.groupby('qid').apply(compute_swaps_scaled_with_weights, \n",
    "                                                                   axis=1, metric=dcg)\n",
    "\n",
    "        # ------------------\n",
    "        #2. Train a regression tree on this round's lambdas\n",
    "        features = lambdas_per_query['features'].tolist()\n",
    "        tree = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes)\n",
    "        tree.fit(features, lambdas_per_query['lambda'])    \n",
    "\n",
    "        # ------------------\n",
    "        #3. Reweight based on LambdaMART's weighted average\n",
    "        # Add each tree's paths\n",
    "        lambdas_per_query['path'] = tree_paths(tree, features)\n",
    "        predictions = lambdas_per_query.groupby('path')['lambda'].sum() / lambdas_per_query.groupby('path')['weight'].sum()\n",
    "        predictions = predictions.fillna(0.0) # for divide by 0\n",
    "\n",
    "        # -------------------\n",
    "        #4. Add to ensemble, recreate last prediction\n",
    "        new_tree = OverridenRegressionTree(predictions=predictions, tree=tree)\n",
    "        ensemble.append(new_tree)\n",
    "        next_predictions = new_tree.predict(features)\n",
    "        lambdas_per_query['last_prediction'] += (next_predictions * learning_rate) \n",
    "        \n",
    "        print(\"Train DCGs\")\n",
    "        print(\"mean   \", lambdas_per_query['train_dcg'].mean())\n",
    "        print(\"median \", lambdas_per_query['train_dcg'].median())\n",
    "        print(\"----------\")\n",
    "\n",
    "        \n",
    "        # Reset the dataframe for further processing\n",
    "\n",
    "        lambdas_per_query = lambdas_per_query.drop('qid', axis=1).reset_index().drop(['level_1', 'index'], axis=1)\n",
    "\n",
    "judgments = to_dataframe(ftr_logger.logged)\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "lambdas_per_query = lambda_mart(judgments=judgments, rounds=50, max_leaf_nodes=10, learning_rate=0.1, metric=dcg)"
=======
    "lambdas_per_query = lambda_mart(judgments=judgments, rounds=10, max_leaf_nodes=10, metric=dcg)"
>>>>>>> 4ef4e05 (Save lambda mart)
=======
    "lambdas_per_query = lambda_mart(judgments=judgments, rounds=10, max_leaf_nodes=10, learning_rate=0.1, metric=dcg)"
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
    "lambdas_per_query = lambda_mart(judgments=judgments, rounds=50, max_leaf_nodes=10, learning_rate=0.1, metric=dcg)"
>>>>>>> bd537d0 (Fix DCG calculation)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                 262\n",
       "uid                               8_69315\n",
       "qid                                     8\n",
       "keywords             battlestar galactica\n",
       "docId                               69315\n",
       "grade                                   3\n",
       "features           [15.908707, 31.961138]\n",
       "last_prediction                       NaN\n",
       "display_rank                           26\n",
       "train_dcg                               0\n",
       "dcg                                     0\n",
       "lambda                                  0\n",
       "weight                                  0\n",
       "path                  1010001000000000001\n",
       "Name: (8, 26), dtype: object"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
   "execution_count": 549,
=======
   "execution_count": 180,
>>>>>>> e7358dd (Use a stable sorting algorithm)
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-2e26dd037e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlambdas_per_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m282\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iloc'"
     ]
    }
   ],
>>>>>>> 95bbadd (use absolute value in delta calculatio)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
   "source": [
    "lambdas_per_query.iloc[282]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path\n",
       "1010001000000000001         NaN\n",
       "1010001000000000010    1.995794\n",
       "1010010000100000000   -2.000000\n",
       "1010010001001010000    2.000000\n",
       "1010010001001100000    1.846154\n",
       "1010010001010000000    2.000000\n",
       "1100100010000000000    1.415385\n",
       "1100100100000000100    2.000000\n",
       "1100100100000001000   -2.000000\n",
       "1101000000000000000   -1.297171\n",
       "dtype: float64"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "source": [
    "ensemble[0].predictions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(141.64615384615385, 199.32, 'X[0] <= 10.666\\nmse = 0.044\\nsamples = 1390\\nvalue = 0.0'),\n",
       " Text(51.50769230769231, 163.07999999999998, 'X[0] <= 9.182\\nmse = 0.014\\nsamples = 1329\\nvalue = -0.029'),\n",
       " Text(25.753846153846155, 126.83999999999999, 'mse = 0.007\\nsamples = 1301\\nvalue = -0.035'),\n",
       " Text(77.26153846153846, 126.83999999999999, 'X[0] <= 9.451\\nmse = 0.252\\nsamples = 28\\nvalue = 0.244'),\n",
       " Text(51.50769230769231, 90.6, 'X[1] <= 4.527\\nmse = 0.302\\nsamples = 4\\nvalue = 0.847'),\n",
       " Text(25.753846153846155, 54.359999999999985, 'mse = 0.0\\nsamples = 1\\nvalue = -0.05'),\n",
       " Text(77.26153846153846, 54.359999999999985, 'mse = 0.045\\nsamples = 3\\nvalue = 1.146'),\n",
       " Text(103.01538461538462, 90.6, 'mse = 0.173\\nsamples = 24\\nvalue = 0.144'),\n",
       " Text(231.7846153846154, 163.07999999999998, 'X[0] <= 13.528\\nmse = 0.297\\nsamples = 61\\nvalue = 0.625'),\n",
       " Text(180.27692307692308, 126.83999999999999, 'X[1] <= 10.412\\nmse = 0.312\\nsamples = 32\\nvalue = 0.451'),\n",
       " Text(154.52307692307693, 90.6, 'X[0] <= 10.761\\nmse = 0.322\\nsamples = 27\\nvalue = 0.538'),\n",
       " Text(128.76923076923077, 54.359999999999985, 'mse = 0.003\\nsamples = 2\\nvalue = 1.331'),\n",
       " Text(180.27692307692308, 54.359999999999985, 'X[1] <= 9.943\\nmse = 0.293\\nsamples = 25\\nvalue = 0.474'),\n",
       " Text(154.52307692307693, 18.119999999999976, 'mse = 0.259\\nsamples = 22\\nvalue = 0.382'),\n",
       " Text(206.03076923076924, 18.119999999999976, 'mse = 0.023\\nsamples = 3\\nvalue = 1.15'),\n",
       " Text(206.03076923076924, 90.6, 'mse = 0.0\\nsamples = 5\\nvalue = -0.018'),\n",
       " Text(283.2923076923077, 126.83999999999999, 'X[1] <= 25.987\\nmse = 0.209\\nsamples = 29\\nvalue = 0.818'),\n",
       " Text(257.53846153846155, 90.6, 'mse = 0.192\\nsamples = 28\\nvalue = 0.847'),\n",
       " Text(309.04615384615386, 90.6, 'mse = -0.0\\nsamples = 1\\nvalue = 0.0')]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "source": [
    "plot_tree(ensemble[0].tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to ranklib output"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET http://es-learn-to-rank.labs.o19s.com/RankyMcRankFace.jar\n",
      "Running java -jar /var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/RankyMcRankFace.jar -ranker 6 -shrinkage 0.1 -metric2t DCG@10 -tree 10 -bag 1 -leaf 10 -frate 1.0 -srate 1.0 -train /var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/training.txt -save data/title_model.txt \n",
      "Delete model title: 404\n",
      "Created Model title [Status: 201]\n",
      "Model saved\n",
      "Every N rounds of ranklib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.692,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.73,\n",
       " 20.7506,\n",
       " 20.6507,\n",
       " 20.7237,\n",
       " 20.7237]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 4ef4e05 (Save lambda mart)
=======
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET http://es-learn-to-rank.labs.o19s.com/RankyMcRankFace.jar\n",
      "Running java -jar /var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/RankyMcRankFace.jar -ranker 6 -shrinkage 0.1 -metric2t DCG@10 -tree 10 -bag 1 -leaf 10 -frate 1.0 -srate 1.0 -train /var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/training.txt -save data/title_model.txt \n",
      "Delete model title: 404\n",
      "Created Model title [Status: 201]\n",
      "Model saved\n",
      "Every N rounds of ranklib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.692,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.73,\n",
       " 20.7506,\n",
       " 20.6507,\n",
       " 20.7237,\n",
       " 20.7237]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> bd537d0 (Fix DCG calculation)
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
   "source": [
    "from ltr.ranklib import train\n",
    "trainLog  = train(client,\n",
    "                  training_set=ftr_logger.logged,\n",
    "                  index='tmdb',\n",
    "                  trees=10,\n",
    "                  featureSet='movies',\n",
    "                  modelName='title')\n",
    "\n",
    "print(\"Every N rounds of ranklib\")\n",
    "trainLog.trainingLogs[0].rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine queries we learned\n",
    "\n",
    "Try out some queries, look at the final model prediction `last_prediction` compare to the correct ordering `grade`."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_per_query[lambdas_per_query['qid'] == 2]"
   ]
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pure Pandas Implementation?\n",
    "\n",
    "Can we make it faster by vectorizing with pandas?\n",
    "\n",
    "Turns out Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_per_query = judgments.copy()\n",
    "\n",
    "\n",
    "lambdas_per_query['last_prediction'] = 0.0\n",
    "lambdas_per_query.sort_values(['qid', 'last_prediction'], ascending=[True, False], kind='stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_per_query['display_rank'] = lambdas_per_query.groupby('qid').cumcount()\n",
    "\n",
    "#TBD - How do generalize this?\n",
    "lambdas_per_query['discount'] = 1 / np.log2(2 + lambdas_per_query['display_rank'])\n",
    "lambdas_per_query['gain'] = (2**lambdas_per_query['grade'] - 1) # * lambdas_per_query['discount']\n",
    "\n",
    "lambdas_per_query[['join_key', 'qid', 'display_rank', 'discount', 'grade', 'gain']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise deltas\n",
    "\n",
    "Delta captures pair-wise difference of the ranking metric (ie DCG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each group paired with each other group\n",
    "swaps = lambdas_per_query.merge(lambdas_per_query, on='qid', how='outer')\n",
    "# changes[j][i] = changes[i][j] = (discount(i) - discount(j)) * (gain(rel[i]) - gain(rel[j]));\n",
    "swaps['delta'] = np.abs((swaps['discount_x'] - swaps['discount_y']) * (swaps['gain_x'] - swaps['gain_y']))\n",
    "swaps[['qid', 'display_rank_x', 'display_rank_y', 'delta']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise rhos\n",
    "\n",
    "Rho captures pair-wise difference of the current model's prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaps['rho'] = 1 / (1 + np.exp(swaps['last_prediction_x'] - swaps['last_prediction_y']))\n",
    "swaps[['qid', 'display_rank_x', 'display_rank_y', 'delta', 'last_prediction_x', 'last_prediction_y', 'rho']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute lambdas\n",
    "\n",
    "For every row where grade_x > grade_y,  compute `delta*rho`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaps['lambda'] = 0\n",
    "slice_x_better =swaps[swaps['grade_x'] > swaps['grade_y']]\n",
    "swaps.loc[swaps['grade_x'] > swaps['grade_y'], 'lambda'] = slice_x_better['delta'] * slice_x_better['rho']\n",
    "swaps[['qid', 'display_rank_x', 'display_rank_y', 'delta', 'last_prediction_x', 'last_prediction_y', 'rho', 'lambda']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get per-key lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid  display_rank_x\n",
       "1    0                 211.781688\n",
       "     1                  46.938369\n",
       "     2                  30.637615\n",
       "     3                   5.888732\n",
       "     4                  43.177578\n",
       "                          ...    \n",
       "40   25                 -9.853045\n",
       "     26                 -9.911575\n",
       "     27                 -9.966853\n",
       "     28                -10.019174\n",
       "     29                -10.068796\n",
       "Name: lambda, Length: 1390, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better minus worse\n",
    "lambdas_x = swaps.groupby(['qid', 'display_rank_x'])['lambda'].sum().rename('lambda')\n",
    "lambdas_y = swaps.groupby(['qid', 'display_rank_y'])['lambda'].sum().rename('lambda')\n",
    "lambdas = lambdas_x - lambdas_y\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
<<<<<<< HEAD
=======
   "execution_count": 399,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <th>qid</th>\n",
       "      <th>uid</th>\n",
=======
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <th>qid</th>\n",
       "      <th>uid</th>\n",
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "      <th>features</th>\n",
       "      <th>last_prediction</th>\n",
       "      <th>display_rank</th>\n",
       "      <th>discount</th>\n",
       "      <th>gain</th>\n",
       "      <th>train_dcg</th>\n",
       "      <th>dcg</th>\n",
       "      <th>lambda</th>\n",
       "      <th>weight</th>\n",
       "      <th>path</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <th>lambdas</th>\n",
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
>>>>>>> 4ef4e05 (Save lambda mart)
=======
       "      <th>lambdas</th>\n",
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_7555</td>\n",
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "      <td>[11.657399, 10.083591]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>213.776822</td>\n",
       "      <td>106.888411</td>\n",
       "      <td>1010010</td>\n",
       "      <td>211.781688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1370</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "      <td>[9.456276, 13.265001]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>4.416508</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>48.010828</td>\n",
       "      <td>26.458003</td>\n",
       "      <td>1100100</td>\n",
       "      <td>49.390958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1369</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.036743, 11.113943]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>31.382749</td>\n",
       "      <td>18.143963</td>\n",
       "      <td>1101000</td>\n",
       "      <td>33.090203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1_13258</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 6.869545]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>1.292030</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>6.460558</td>\n",
       "      <td>7.448315</td>\n",
       "      <td>1101000</td>\n",
       "      <td>10.106768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1_1368</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 11.113943]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>5.802792</td>\n",
       "      <td>30.700871</td>\n",
       "      <td>30.552986</td>\n",
       "      <td>43.639845</td>\n",
       "      <td>21.819923</td>\n",
       "      <td>1101000</td>\n",
       "      <td>43.177578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>40</td>\n",
       "      <td>40_37079</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.846078</td>\n",
       "      <td>4.923039</td>\n",
       "      <td>1101000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>40</td>\n",
       "      <td>40_126757</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.903461</td>\n",
       "      <td>4.951730</td>\n",
       "      <td>1101000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>40</td>\n",
       "      <td>40_39797</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-9.957655</td>\n",
       "      <td>4.978827</td>\n",
       "      <td>1101000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>40</td>\n",
       "      <td>40_18112</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-10.008949</td>\n",
       "      <td>5.004475</td>\n",
       "      <td>1101000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>40</td>\n",
       "      <td>40_43052</td>\n",
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.207651</td>\n",
       "      <td>30.120435</td>\n",
       "      <td>-10.057598</td>\n",
       "      <td>5.028799</td>\n",
       "      <td>1101000</td>\n",
       "      <td>0.568410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid        uid   keywords   docId  grade                features  \\\n",
       "0       1     1_7555      rambo    7555      4  [11.657399, 10.083591]   \n",
       "1       1     1_1370      rambo    1370      3   [9.456276, 13.265001]   \n",
       "2       1     1_1369      rambo    1369      3   [6.036743, 11.113943]   \n",
       "3       1    1_13258      rambo   13258      2         [0.0, 6.869545]   \n",
       "4       1     1_1368      rambo    1368      4        [0.0, 11.113943]   \n",
       "...   ...        ...        ...     ...    ...                     ...   \n",
       "1385   40   40_37079  star wars   37079      0              [0.0, 0.0]   \n",
       "1386   40  40_126757  star wars  126757      0              [0.0, 0.0]   \n",
       "1387   40   40_39797  star wars   39797      0              [0.0, 0.0]   \n",
       "1388   40   40_18112  star wars   18112      0              [0.0, 0.0]   \n",
       "1389   40   40_43052  star wars   43052      0              [0.0, 0.0]   \n",
       "\n",
       "      last_prediction  display_rank  discount       gain  train_dcg  \\\n",
       "0                   0             0  1.000000  15.000000  30.700871   \n",
       "1                   0             1  0.630930   4.416508  30.700871   \n",
       "2                   0             2  0.500000   3.500000  30.700871   \n",
       "3                   0             3  0.430677   1.292030  30.700871   \n",
       "4                   0             4  0.386853   5.802792  30.700871   \n",
       "...               ...           ...       ...        ...        ...   \n",
       "1385                0            25  0.210310   0.000000  30.207651   \n",
       "1386                0            26  0.208015   0.000000  30.207651   \n",
       "1387                0            27  0.205847   0.000000  30.207651   \n",
       "1388                0            28  0.203795   0.000000  30.207651   \n",
       "1389                0             9  0.289065   0.000000  30.207651   \n",
       "\n",
       "            dcg      lambda      weight     path     lambdas  \n",
       "0     30.552986  213.776822  106.888411  1010010  211.781688  \n",
       "1     30.552986   48.010828   26.458003  1100100   49.390958  \n",
       "2     30.552986   31.382749   18.143963  1101000   33.090203  \n",
       "3     30.552986    6.460558    7.448315  1101000   10.106768  \n",
       "4     30.552986   43.639845   21.819923  1101000   43.177578  \n",
       "...         ...         ...         ...      ...         ...  \n",
       "1385  30.120435   -9.846078    4.923039  1101000    0.000000  \n",
       "1386  30.120435   -9.903461    4.951730  1101000    0.000000  \n",
       "1387  30.120435   -9.957655    4.978827  1101000    0.000000  \n",
       "1388  30.120435  -10.008949    5.004475  1101000    0.000000  \n",
       "1389  30.120435  -10.057598    5.028799  1101000    0.568410  \n",
       "\n",
       "[1390 rows x 16 columns]"
      ]
     },
     "execution_count": 106,
<<<<<<< HEAD
=======
       "      <th rowspan=\"41\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>2_1366</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1366</td>\n",
       "      <td>4</td>\n",
       "      <td>[10.00459, 8.694555]</td>\n",
       "      <td>3.798236</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>2.485134</td>\n",
       "      <td>2.452373</td>\n",
       "      <td>1010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>2_152601</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>152601</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.022374</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>2_198001</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>198001</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>2_170430</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>170430</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>3</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.039345</td>\n",
       "      <td>0.038826</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>2_18206</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>18206</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.043712</td>\n",
       "      <td>0.043136</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>2_47059</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>47059</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>5</td>\n",
       "      <td>0.262650</td>\n",
       "      <td>0.525299</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>1.592257</td>\n",
       "      <td>0.861259</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>2_18215</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>18215</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.055760</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69</td>\n",
       "      <td>2_70808</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>70808</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>7</td>\n",
       "      <td>0.239812</td>\n",
       "      <td>0.479625</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>1.147813</td>\n",
       "      <td>0.645303</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70</td>\n",
       "      <td>2_351862</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>351862</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>8</td>\n",
       "      <td>0.231378</td>\n",
       "      <td>0.462756</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>0.986005</td>\n",
       "      <td>0.566714</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>2_154019</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>154019</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>9</td>\n",
       "      <td>0.224244</td>\n",
       "      <td>0.448488</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>0.849135</td>\n",
       "      <td>0.500237</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72</td>\n",
       "      <td>2_70</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>40</td>\n",
       "      <td>0.156438</td>\n",
       "      <td>0.312876</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.059459</td>\n",
       "      <td>0.058675</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>73</td>\n",
       "      <td>2_22777</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>22777</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>11</td>\n",
       "      <td>0.212746</td>\n",
       "      <td>0.212746</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.167689</td>\n",
       "      <td>0.113340</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74</td>\n",
       "      <td>2_43189</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>43189</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>12</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.187613</td>\n",
       "      <td>0.123788</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>75</td>\n",
       "      <td>2_318</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>13</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.205381</td>\n",
       "      <td>0.133105</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>76</td>\n",
       "      <td>2_39829</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>39829</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>14</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.221361</td>\n",
       "      <td>0.141485</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>77</td>\n",
       "      <td>2_1578</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1578</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>15</td>\n",
       "      <td>0.196562</td>\n",
       "      <td>0.393123</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.064003</td>\n",
       "      <td>0.063159</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78</td>\n",
       "      <td>2_25855</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>25855</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>16</td>\n",
       "      <td>0.193426</td>\n",
       "      <td>0.193426</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.249042</td>\n",
       "      <td>0.156001</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79</td>\n",
       "      <td>2_42012</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>42012</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>17</td>\n",
       "      <td>0.190551</td>\n",
       "      <td>0.381103</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.065270</td>\n",
       "      <td>0.064410</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80</td>\n",
       "      <td>2_32276</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>32276</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>18</td>\n",
       "      <td>0.187902</td>\n",
       "      <td>0.187902</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.272306</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>63</td>\n",
       "      <td>2_17819</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>17819</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>19</td>\n",
       "      <td>0.185449</td>\n",
       "      <td>0.185449</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.282634</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61</td>\n",
       "      <td>2_330459</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>330459</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>20</td>\n",
       "      <td>0.183169</td>\n",
       "      <td>0.183169</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.292234</td>\n",
       "      <td>0.178650</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>2_1374</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1374</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.115546, 9.808358]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>21</td>\n",
       "      <td>0.181043</td>\n",
       "      <td>1.448341</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.067276</td>\n",
       "      <td>0.066389</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>2_1893</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1893</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>22</td>\n",
       "      <td>0.179052</td>\n",
       "      <td>0.179052</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.309571</td>\n",
       "      <td>0.187741</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>2_1371</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1371</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.115546, 5.557296]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>23</td>\n",
       "      <td>0.177184</td>\n",
       "      <td>1.417471</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.068090</td>\n",
       "      <td>0.067192</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44</td>\n",
       "      <td>2_1246</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1246</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.115546, 9.540649]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>24</td>\n",
       "      <td>0.175425</td>\n",
       "      <td>1.403401</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.068461</td>\n",
       "      <td>0.067558</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45</td>\n",
       "      <td>2_1375</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1375</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.115546, 9.472043]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>25</td>\n",
       "      <td>0.173765</td>\n",
       "      <td>1.390123</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.068811</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>46</td>\n",
       "      <td>2_1367</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>1367</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.115546, 8.262948]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>26</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>1.377563</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.069142</td>\n",
       "      <td>0.068231</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>47</td>\n",
       "      <td>2_60375</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>60375</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.115546, 7.819334]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>27</td>\n",
       "      <td>0.170707</td>\n",
       "      <td>1.365658</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.069456</td>\n",
       "      <td>0.068540</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48</td>\n",
       "      <td>2_110123</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>110123</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.8909245, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>28</td>\n",
       "      <td>0.169294</td>\n",
       "      <td>0.338588</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.069754</td>\n",
       "      <td>0.068834</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49</td>\n",
       "      <td>2_36685</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>36685</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.8909245, 5.777752]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>29</td>\n",
       "      <td>0.167949</td>\n",
       "      <td>0.335898</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.070038</td>\n",
       "      <td>0.069114</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50</td>\n",
       "      <td>2_17711</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>17711</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.8265696, 8.381828]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>30</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.070308</td>\n",
       "      <td>0.069381</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>51</td>\n",
       "      <td>2_2153</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>2153</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>31</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.366880</td>\n",
       "      <td>0.217793</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>52</td>\n",
       "      <td>2_339403</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>339403</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>32</td>\n",
       "      <td>0.164272</td>\n",
       "      <td>0.164272</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.371809</td>\n",
       "      <td>0.220378</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>53</td>\n",
       "      <td>2_21501</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>21501</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>33</td>\n",
       "      <td>0.163151</td>\n",
       "      <td>0.163151</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.376529</td>\n",
       "      <td>0.222853</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>54</td>\n",
       "      <td>2_81182</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>81182</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>34</td>\n",
       "      <td>0.162077</td>\n",
       "      <td>0.162077</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.381054</td>\n",
       "      <td>0.225226</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>55</td>\n",
       "      <td>2_62414</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>62414</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>35</td>\n",
       "      <td>0.161045</td>\n",
       "      <td>0.161045</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.385399</td>\n",
       "      <td>0.227504</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>56</td>\n",
       "      <td>2_21989</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>21989</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>36</td>\n",
       "      <td>0.160053</td>\n",
       "      <td>0.160053</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.389575</td>\n",
       "      <td>0.229694</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>57</td>\n",
       "      <td>2_11</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>37</td>\n",
       "      <td>0.159099</td>\n",
       "      <td>0.159099</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.393593</td>\n",
       "      <td>0.231801</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>58</td>\n",
       "      <td>2_12180</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>12180</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>38</td>\n",
       "      <td>0.158180</td>\n",
       "      <td>0.158180</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.397464</td>\n",
       "      <td>0.233831</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>59</td>\n",
       "      <td>2_140607</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>140607</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>39</td>\n",
       "      <td>0.157293</td>\n",
       "      <td>0.157293</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.401196</td>\n",
       "      <td>0.235788</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>81</td>\n",
       "      <td>2_105536</td>\n",
       "      <td>2</td>\n",
       "      <td>rocky</td>\n",
       "      <td>105536</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>10</td>\n",
       "      <td>0.218104</td>\n",
       "      <td>0.218104</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>11.466327</td>\n",
       "      <td>-0.404799</td>\n",
       "      <td>0.237677</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index       uid  qid keywords   docId  grade               features  \\\n",
       "qid                                                                           \n",
       "2   0      41    2_1366    2    rocky    1366      4   [10.00459, 8.694555]   \n",
       "    1      62  2_152601    2    rocky  152601      0             [0.0, 0.0]   \n",
       "    2      64  2_198001    2    rocky  198001      0             [0.0, 0.0]   \n",
       "    3      65  2_170430    2    rocky  170430      0             [0.0, 0.0]   \n",
       "    4      66   2_18206    2    rocky   18206      0             [0.0, 0.0]   \n",
       "    5      67   2_47059    2    rocky   47059      1             [0.0, 0.0]   \n",
       "    6      68   2_18215    2    rocky   18215      0             [0.0, 0.0]   \n",
       "    7      69   2_70808    2    rocky   70808      1             [0.0, 0.0]   \n",
       "    8      70  2_351862    2    rocky  351862      1             [0.0, 0.0]   \n",
       "    9      71  2_154019    2    rocky  154019      1             [0.0, 0.0]   \n",
       "    10     72      2_70    2    rocky      70      1             [0.0, 0.0]   \n",
       "    11     73   2_22777    2    rocky   22777      0             [0.0, 0.0]   \n",
       "    12     74   2_43189    2    rocky   43189      0             [0.0, 0.0]   \n",
       "    13     75     2_318    2    rocky     318      0             [0.0, 0.0]   \n",
       "    14     76   2_39829    2    rocky   39829      0             [0.0, 0.0]   \n",
       "    15     77    2_1578    2    rocky    1578      1             [0.0, 0.0]   \n",
       "    16     78   2_25855    2    rocky   25855      0             [0.0, 0.0]   \n",
       "    17     79   2_42012    2    rocky   42012      1             [0.0, 0.0]   \n",
       "    18     80   2_32276    2    rocky   32276      0             [0.0, 0.0]   \n",
       "    19     63   2_17819    2    rocky   17819      0             [0.0, 0.0]   \n",
       "    20     61  2_330459    2    rocky  330459      0             [0.0, 0.0]   \n",
       "    21     42    2_1374    2    rocky    1374      3   [8.115546, 9.808358]   \n",
       "    22     60    2_1893    2    rocky    1893      0             [0.0, 0.0]   \n",
       "    23     43    2_1371    2    rocky    1371      3   [8.115546, 5.557296]   \n",
       "    24     44    2_1246    2    rocky    1246      3   [8.115546, 9.540649]   \n",
       "    25     45    2_1375    2    rocky    1375      3   [8.115546, 9.472043]   \n",
       "    26     46    2_1367    2    rocky    1367      3   [8.115546, 8.262948]   \n",
       "    27     47   2_60375    2    rocky   60375      3   [8.115546, 7.819334]   \n",
       "    28     48  2_110123    2    rocky  110123      1       [5.8909245, 0.0]   \n",
       "    29     49   2_36685    2    rocky   36685      1  [5.8909245, 5.777752]   \n",
       "    30     50   2_17711    2    rocky   17711      1  [6.8265696, 8.381828]   \n",
       "    31     51    2_2153    2    rocky    2153      0             [0.0, 0.0]   \n",
       "    32     52  2_339403    2    rocky  339403      0             [0.0, 0.0]   \n",
       "    33     53   2_21501    2    rocky   21501      0             [0.0, 0.0]   \n",
       "    34     54   2_81182    2    rocky   81182      0             [0.0, 0.0]   \n",
       "    35     55   2_62414    2    rocky   62414      0             [0.0, 0.0]   \n",
       "    36     56   2_21989    2    rocky   21989      0             [0.0, 0.0]   \n",
       "    37     57      2_11    2    rocky      11      0             [0.0, 0.0]   \n",
       "    38     58   2_12180    2    rocky   12180      0             [0.0, 0.0]   \n",
       "    39     59  2_140607    2    rocky  140607      0             [0.0, 0.0]   \n",
       "    40     81  2_105536    2    rocky  105536      0             [0.0, 0.0]   \n",
       "\n",
       "        last_prediction  display_rank  discount      gain  train_dcg  \\\n",
       "qid                                                                    \n",
       "2   0          3.798236             0  0.500000  8.000000  11.466327   \n",
       "    1         -0.517338             1  0.386853  0.386853  11.466327   \n",
       "    2         -0.517338             2  0.333333  0.333333  11.466327   \n",
       "    3         -0.517338             3  0.301030  0.301030  11.466327   \n",
       "    4         -0.517338             4  0.278943  0.278943  11.466327   \n",
       "    5         -0.517338             5  0.262650  0.525299  11.466327   \n",
       "    6         -0.517338             6  0.250000  0.250000  11.466327   \n",
       "    7         -0.517338             7  0.239812  0.479625  11.466327   \n",
       "    8         -0.517338             8  0.231378  0.462756  11.466327   \n",
       "    9         -0.517338             9  0.224244  0.448488  11.466327   \n",
       "    10        -0.517338            40  0.156438  0.312876  11.466327   \n",
       "    11        -0.517338            11  0.212746  0.212746  11.466327   \n",
       "    12        -0.517338            12  0.208015  0.208015  11.466327   \n",
       "    13        -0.517338            13  0.203795  0.203795  11.466327   \n",
       "    14        -0.517338            14  0.200000  0.200000  11.466327   \n",
       "    15        -0.517338            15  0.196562  0.393123  11.466327   \n",
       "    16        -0.517338            16  0.193426  0.193426  11.466327   \n",
       "    17        -0.517338            17  0.190551  0.381103  11.466327   \n",
       "    18        -0.517338            18  0.187902  0.187902  11.466327   \n",
       "    19        -0.517338            19  0.185449  0.185449  11.466327   \n",
       "    20        -0.517338            20  0.183169  0.183169  11.466327   \n",
       "    21        -0.517338            21  0.181043  1.448341  11.466327   \n",
       "    22        -0.517338            22  0.179052  0.179052  11.466327   \n",
       "    23        -0.517338            23  0.177184  1.417471  11.466327   \n",
       "    24        -0.517338            24  0.175425  1.403401  11.466327   \n",
       "    25        -0.517338            25  0.173765  1.390123  11.466327   \n",
       "    26        -0.517338            26  0.172195  1.377563  11.466327   \n",
       "    27        -0.517338            27  0.170707  1.365658  11.466327   \n",
       "    28        -0.517338            28  0.169294  0.338588  11.466327   \n",
       "    29        -0.517338            29  0.167949  0.335898  11.466327   \n",
       "    30        -0.517338            30  0.166667  0.333333  11.466327   \n",
       "    31        -0.517338            31  0.165443  0.165443  11.466327   \n",
       "    32        -0.517338            32  0.164272  0.164272  11.466327   \n",
       "    33        -0.517338            33  0.163151  0.163151  11.466327   \n",
       "    34        -0.517338            34  0.162077  0.162077  11.466327   \n",
       "    35        -0.517338            35  0.161045  0.161045  11.466327   \n",
       "    36        -0.517338            36  0.160053  0.160053  11.466327   \n",
       "    37        -0.517338            37  0.159099  0.159099  11.466327   \n",
       "    38        -0.517338            38  0.158180  0.158180  11.466327   \n",
       "    39        -0.517338            39  0.157293  0.157293  11.466327   \n",
       "    40        -0.517338            10  0.218104  0.218104  11.466327   \n",
       "\n",
       "              dcg    lambda    weight     path  \n",
       "qid                                             \n",
       "2   0   11.466327  2.485134  2.452373  1010101  \n",
       "    1   11.466327 -0.022374  0.022079  1100000  \n",
       "    2   11.466327 -0.032957  0.032522  1100000  \n",
       "    3   11.466327 -0.039345  0.038826  1100000  \n",
       "    4   11.466327 -0.043712  0.043136  1100000  \n",
       "    5   11.466327  1.592257  0.861259  1100000  \n",
       "    6   11.466327 -0.055760  0.051946  1100000  \n",
       "    7   11.466327  1.147813  0.645303  1100000  \n",
       "    8   11.466327  0.986005  0.566714  1100000  \n",
       "    9   11.466327  0.849135  0.500237  1100000  \n",
       "    10  11.466327 -0.059459  0.058675  1100000  \n",
       "    11  11.466327 -0.167689  0.113340  1100000  \n",
       "    12  11.466327 -0.187613  0.123788  1100000  \n",
       "    13  11.466327 -0.205381  0.133105  1100000  \n",
       "    14  11.466327 -0.221361  0.141485  1100000  \n",
       "    15  11.466327 -0.064003  0.063159  1100000  \n",
       "    16  11.466327 -0.249042  0.156001  1100000  \n",
       "    17  11.466327 -0.065270  0.064410  1100000  \n",
       "    18  11.466327 -0.272306  0.168200  1100000  \n",
       "    19  11.466327 -0.282634  0.173616  1100000  \n",
       "    20  11.466327 -0.292234  0.178650  1100000  \n",
       "    21  11.466327 -0.067276  0.066389  1100000  \n",
       "    22  11.466327 -0.309571  0.187741  1100000  \n",
       "    23  11.466327 -0.068090  0.067192  1100000  \n",
       "    24  11.466327 -0.068461  0.067558  1100000  \n",
       "    25  11.466327 -0.068811  0.067904  1100000  \n",
       "    26  11.466327 -0.069142  0.068231  1100000  \n",
       "    27  11.466327 -0.069456  0.068540  1100000  \n",
       "    28  11.466327 -0.069754  0.068834  1100000  \n",
       "    29  11.466327 -0.070038  0.069114  1100000  \n",
       "    30  11.466327 -0.070308  0.069381  1100000  \n",
       "    31  11.466327 -0.366880  0.217793  1100000  \n",
       "    32  11.466327 -0.371809  0.220378  1100000  \n",
       "    33  11.466327 -0.376529  0.222853  1100000  \n",
       "    34  11.466327 -0.381054  0.225226  1100000  \n",
       "    35  11.466327 -0.385399  0.227504  1100000  \n",
       "    36  11.466327 -0.389575  0.229694  1100000  \n",
       "    37  11.466327 -0.393593  0.231801  1100000  \n",
       "    38  11.466327 -0.397464  0.233831  1100000  \n",
       "    39  11.466327 -0.401196  0.235788  1100000  \n",
       "    40  11.466327 -0.404799  0.237677  1100000  "
      ]
     },
     "execution_count": 399,
>>>>>>> 4ef4e05 (Save lambda mart)
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
<<<<<<< HEAD
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
   "source": [
<<<<<<< HEAD
=======
   "source": [
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
    "lambdas_per_query.merge(lambdas, left_on=['qid', 'display_rank'], right_on=['qid', 'display_rank_x'], how='left')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 167,
=======
   "execution_count": 124,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambdas(lambdas_per_query):\n",
<<<<<<< HEAD
    "    lambdas_per_query = lambdas_per_query.sort_values(['qid', 'last_prediction'], ascending=[True, False], kind='stable')\n",
=======
    "    lambdas_per_query.sort_values(['qid', 'last_prediction'], ascending=[True, False], kind='stable')\n",
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
    "    lambdas_per_query['display_rank'] = lambdas_per_query.groupby('qid').cumcount()\n",
    "\n",
    "    #TBD - How do generalize this to any metric?\n",
    "    lambdas_per_query['discount'] = 1 / np.log2(2 + lambdas_per_query['display_rank'])\n",
    "    lambdas_per_query['gain'] = (2**lambdas_per_query['grade'] - 1)\n",
    "\n",
<<<<<<< HEAD
    "    # swaps dataframe holds each pair-wise swap computed (shrink columns for memory?)   \n",
    "    # Optimization of swaps = lambdas_per_query.merge(lambdas_per_query, on='qid', how='outer')\n",
    "    # to limit to just needed columns\n",
    "    to_swap = lambdas_per_query[['qid', 'display_rank', 'grade', 'last_prediction', 'discount', 'gain']]\n",
    "    #to_swap = lambdas_per_query\n",
    "    swaps = to_swap.merge(to_swap, on='qid', how='outer')\n",
=======
    "    # swaps dataframe holds each pair-wise swap computed (shrink columns for memory?)    \n",
    "    swaps = lambdas_per_query.merge(lambdas_per_query, on='qid', how='outer')\n",
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
    "\n",
    "    # delta - delta in DCG due to swap\n",
    "    swaps['delta'] = np.abs((swaps['discount_x'] - swaps['discount_y']) * (swaps['gain_x'] - swaps['gain_y']))\n",
    "    \n",
    "    # rho - based on current model prediction delta\n",
    "    swaps['rho'] = 1 / (1 + np.exp(swaps['last_prediction_x'] - swaps['last_prediction_y']))\n",
    "    swaps['weight'] = swaps['rho'] * (1.0 - swaps['rho']) * swaps['delta']\n",
    "\n",
    "    # Compute lambdas (the next model in ensemble's predictors) when grade_x > grade_y\n",
    "    swaps['lambda'] = 0\n",
    "    slice_x_better =swaps[swaps['grade_x'] > swaps['grade_y']]\n",
    "    swaps.loc[swaps['grade_x'] > swaps['grade_y'], 'lambda'] = slice_x_better['delta'] * slice_x_better['rho']\n",
    "    \n",
    "    # accumulate lambdas and add back to model\n",
    "    lambdas_x = swaps.groupby(['qid', 'display_rank_x'])['lambda'].sum().rename('lambda')\n",
    "    lambdas_y = swaps.groupby(['qid', 'display_rank_y'])['lambda'].sum().rename('lambda')\n",
    "\n",
    "    weights_x = swaps.groupby(['qid', 'display_rank_x'])['weight'].sum().rename('weight')\n",
    "    weights_y = swaps.groupby(['qid', 'display_rank_y'])['weight'].sum().rename('weight')\n",
    "    \n",
    "    weights = weights_x + weights_y\n",
    "    lambdas = lambdas_x - lambdas_y\n",
    "\n",
    "    lambdas_per_query = lambdas_per_query.merge(lambdas, \n",
    "                                                left_on=['qid', 'display_rank'], \n",
    "                                                right_on=['qid', 'display_rank_x'], \n",
    "                                                how='left')\n",
    "    lambdas_per_query = lambdas_per_query.merge(weights, \n",
    "                                                left_on=['qid', 'display_rank'], \n",
    "                                                right_on=['qid', 'display_rank_x'], \n",
    "                                                how='left')\n",
    "\n",
    "    return lambdas_per_query"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 168,
=======
   "execution_count": 136,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'qid', 'keywords', 'docId', 'grade', 'features'], dtype='object')\n",
      "round 0\n",
<<<<<<< HEAD
      "grade                 4\n",
      "last_prediction    0.01\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.193092700772873\n",
      "----------\n",
      "round 1\n",
      "grade                     4\n",
      "last_prediction    0.019915\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 2\n",
      "grade                     4\n",
      "last_prediction    0.029745\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 3\n",
      "grade                     4\n",
      "last_prediction    0.039492\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 4\n",
      "grade                     4\n",
      "last_prediction    0.049159\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 5\n",
      "grade                     4\n",
      "last_prediction    0.058748\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 6\n",
      "grade                    4\n",
      "last_prediction    0.06826\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 7\n",
      "grade                     4\n",
      "last_prediction    0.077698\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 8\n",
      "grade                     4\n",
      "last_prediction    0.087063\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 9\n",
      "grade                     4\n",
      "last_prediction    0.096357\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 10\n",
      "grade                     4\n",
      "last_prediction    0.105582\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 11\n",
      "grade                     4\n",
      "last_prediction    0.114739\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 12\n",
      "grade                    4\n",
      "last_prediction    0.12383\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 13\n",
      "grade                     4\n",
      "last_prediction    0.132857\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 14\n",
      "grade                    4\n",
      "last_prediction    0.14182\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 15\n",
      "grade                     4\n",
      "last_prediction    0.150722\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 16\n",
      "grade                     4\n",
      "last_prediction    0.159564\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 17\n",
      "grade                     4\n",
      "last_prediction    0.168347\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 18\n",
      "grade                     4\n",
      "last_prediction    0.177072\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 19\n",
      "grade                     4\n",
      "last_prediction    0.185742\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 20\n",
      "grade                     4\n",
      "last_prediction    0.194356\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 21\n",
      "grade                     4\n",
      "last_prediction    0.202916\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 22\n",
      "grade                     4\n",
      "last_prediction    0.211424\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 23\n",
      "grade                    4\n",
      "last_prediction    0.21988\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 24\n",
      "grade                     4\n",
      "last_prediction    0.228285\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 25\n",
      "grade                     4\n",
      "last_prediction    0.236641\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 26\n",
      "grade                     4\n",
      "last_prediction    0.244949\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 27\n",
      "grade                     4\n",
      "last_prediction    0.253209\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 28\n",
      "grade                     4\n",
      "last_prediction    0.261423\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 29\n",
      "grade                     4\n",
      "last_prediction    0.269591\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 30\n",
      "grade                     4\n",
      "last_prediction    0.277715\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 31\n",
      "grade                     4\n",
      "last_prediction    0.285795\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 32\n",
      "grade                     4\n",
      "last_prediction    0.293832\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 33\n",
      "grade                     4\n",
      "last_prediction    0.301828\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 34\n",
      "grade                     4\n",
      "last_prediction    0.309782\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 35\n",
      "grade                     4\n",
      "last_prediction    0.317695\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 36\n",
      "grade                     4\n",
      "last_prediction    0.325569\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 37\n",
      "grade                     4\n",
      "last_prediction    0.333405\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 38\n",
      "grade                     4\n",
      "last_prediction    0.341202\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 39\n",
      "grade                     4\n",
      "last_prediction    0.348962\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 40\n",
      "grade                     4\n",
      "last_prediction    0.356685\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 41\n",
      "grade                     4\n",
      "last_prediction    0.364372\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 42\n",
      "grade                     4\n",
      "last_prediction    0.372024\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 43\n",
      "grade                     4\n",
      "last_prediction    0.379641\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 44\n",
      "grade                     4\n",
      "last_prediction    0.387224\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 45\n",
      "grade                     4\n",
      "last_prediction    0.394774\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 46\n",
      "grade                     4\n",
      "last_prediction    0.402291\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 47\n",
      "grade                     4\n",
      "last_prediction    0.409776\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 48\n",
      "grade                     4\n",
      "last_prediction    0.417229\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 49\n",
      "grade                     4\n",
      "last_prediction    0.424651\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n"
=======
      "Train CGs\n",
      "mean    28.2\n",
      "----------\n",
      "> <ipython-input-136-2eef5eabcd24>(15)lambda_mart_pure()\n",
      "-> for i in range(0, rounds):\n",
      "(Pdb) lambdas_per_query['last_prediction']\n",
      "0       0.100000\n",
      "1       0.085934\n",
      "2      -0.073459\n",
      "3      -0.073459\n",
      "4      -0.073459\n",
      "          ...   \n",
      "1385   -0.073459\n",
      "1386   -0.073459\n",
      "1387   -0.073459\n",
      "1388   -0.073459\n",
      "1389   -0.073459\n",
      "Name: last_prediction, Length: 1390, dtype: float64\n",
      "(Pdb) continue\n",
      "round 1\n",
      "Train CGs\n",
      "mean    28.2\n",
      "----------\n",
      "> <ipython-input-136-2eef5eabcd24>(15)lambda_mart_pure()\n",
      "-> for i in range(0, rounds):\n",
      "(Pdb) continue\n",
      "round 2\n",
      "Train CGs\n",
      "mean    28.2\n",
      "----------\n",
      "> <ipython-input-136-2eef5eabcd24>(15)lambda_mart_pure()\n",
      "-> for i in range(0, rounds):\n",
      "(Pdb)     lambdas_per_query.sort_values(['qid', 'last_prediction'], ascending=[True, False], kind='stable')\n",
      "            uid  qid   keywords   docId  grade                features  \\\n",
      "0        1_7555    1      rambo    7555      4  [11.657399, 10.083591]   \n",
      "1        1_1370    1      rambo    1370      3   [9.456276, 13.265001]   \n",
      "2        1_1369    1      rambo    1369      3   [6.036743, 11.113943]   \n",
      "3       1_13258    1      rambo   13258      2         [0.0, 6.869545]   \n",
      "4        1_1368    1      rambo    1368      4        [0.0, 11.113943]   \n",
      "...         ...  ...        ...     ...    ...                     ...   \n",
      "1385   40_37079   40  star wars   37079      0              [0.0, 0.0]   \n",
      "1386  40_126757   40  star wars  126757      0              [0.0, 0.0]   \n",
      "1387   40_39797   40  star wars   39797      0              [0.0, 0.0]   \n",
      "1388   40_18112   40  star wars   18112      0              [0.0, 0.0]   \n",
      "1389   40_43052   40  star wars   43052      0              [0.0, 0.0]   \n",
      "\n",
      "      last_prediction  display_rank  discount  gain                 path  \n",
      "0            0.278019             0  1.000000    15  1011000000010010000  \n",
      "1            0.238354             1  0.630930     7  1100001010100000000  \n",
      "2           -0.203811             2  0.500000     7  1100010000000000000  \n",
      "3           -0.203811             3  0.430677     3  1100010000000000000  \n",
      "4           -0.203811             4  0.386853    15  1100010000000000000  \n",
      "...               ...           ...       ...   ...                  ...  \n",
      "1385        -0.203811            25  0.210310     0  1100010000000000000  \n",
      "1386        -0.203811            26  0.208015     0  1100010000000000000  \n",
      "1387        -0.203811            27  0.205847     0  1100010000000000000  \n",
      "1388        -0.203811            28  0.203795     0  1100010000000000000  \n",
      "1389        -0.203811            29  0.201849     0  1100010000000000000  \n",
      "\n",
      "[1390 rows x 11 columns]\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-2eef5eabcd24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mjudgments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftr_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mlambdas_per_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_mart_pure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudgments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjudgments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-136-2eef5eabcd24>\u001b[0m in \u001b[0;36mlambda_mart_pure\u001b[0;34m(judgments, rounds, learning_rate, max_leaf_nodes, metric)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlambdas_per_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"round {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-2eef5eabcd24>\u001b[0m in \u001b[0;36mlambda_mart_pure\u001b[0;34m(judgments, rounds, learning_rate, max_leaf_nodes, metric)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlambdas_per_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"round {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ensemble=[]\n",
    "def lambda_mart_pure(judgments, rounds=20, learning_rate=0.1, max_leaf_nodes=8, metric=dcg):\n",
    "\n",
    "    print(judgments.columns)\n",
    "    # Convert to Pandas Dataframe\n",
    "    lambdas_per_query = judgments.copy()\n",
    "\n",
    "\n",
    "    lambdas_per_query['last_prediction'] = 0.0\n",
    "\n",
    "    for i in range(0, rounds):\n",
    "        print(f\"round {i}\")\n",
    "\n",
    "        # ------------------\n",
    "        #1. Build pair-wise predictors for this round\n",
    "        lambdas_per_query = compute_lambdas(lambdas_per_query)\n",
    "\n",
    "        # ------------------\n",
    "        #2. Train a regression tree on this round's lambdas\n",
    "        features = lambdas_per_query['features'].tolist()\n",
    "        tree = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes)\n",
    "        tree.fit(features, lambdas_per_query['lambda'])    \n",
    "\n",
    "        # ------------------\n",
    "        #3. Reweight based on LambdaMART's weighted average\n",
    "        # Add each tree's paths\n",
    "        lambdas_per_query['path'] = tree_paths(tree, features)\n",
    "        predictions = lambdas_per_query.groupby('path')['lambda'].sum() / lambdas_per_query.groupby('path')['weight'].sum()\n",
    "        predictions = predictions.fillna(0.0) # for divide by 0\n",
    "\n",
    "        # -------------------\n",
    "        #4. Add to ensemble, recreate last prediction\n",
    "        new_tree = OverridenRegressionTree(predictions=predictions, tree=tree)\n",
    "        ensemble.append(new_tree)\n",
    "        next_predictions = new_tree.predict(features)\n",
    "        lambdas_per_query['last_prediction'] += (next_predictions * learning_rate) \n",
    "        \n",
<<<<<<< HEAD
    "        print(lambdas_per_query.loc[0, ['grade', 'last_prediction']])\n",
    "        \n",
    "        print(\"Train DCGs\")\n",
    "        lambdas_per_query['discounted_gain'] = lambdas_per_query['gain'] * lambdas_per_query['discount'] \n",
    "        dcg = lambdas_per_query[lambdas_per_query['display_rank'] < 10].groupby('qid')['discounted_gain'].sum().mean()\n",
    "        print(\"mean   \", dcg)\n",
    "        print(\"----------\")\n",
    "        \n",
    "        lambdas_per_query = lambdas_per_query.drop(['lambda', 'weight'], axis=1)\n",
=======
    "        print(\"Train CGs\")\n",
    "        cg = lambdas_per_query[lambdas_per_query['display_rank'] < 10].groupby('qid')['gain'].sum().mean()\n",
    "        print(\"mean   \", cg)\n",
    "        print(\"----------\")\n",
    "        \n",
    "        lambdas_per_query = lambdas_per_query.drop(['lambda', 'weight'], axis=1)\n",
    "        import pdb; pdb.set_trace()\n",
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
    "    return lambdas_per_query\n",
    "\n",
    "\n",
    "judgments = to_dataframe(ftr_logger.logged)\n",
<<<<<<< HEAD
    "lambdas_per_query = lambda_mart_pure(judgments=judgments, rounds=50, max_leaf_nodes=10, learning_rate=0.01, metric=dcg)"
=======
    "lambdas_per_query = lambda_mart_pure(judgments=judgments, rounds=50, max_leaf_nodes=10, learning_rate=0.1, metric=dcg)"
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'qid', 'keywords', 'docId', 'grade', 'features'], dtype='object')\n",
      "round 0\n",
      "grade                 4\n",
      "last_prediction    0.01\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.193092700772873\n",
      "----------\n",
      "round 1\n",
      "grade                     4\n",
      "last_prediction    0.019915\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 2\n",
      "grade                     4\n",
      "last_prediction    0.029745\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 3\n",
      "grade                     4\n",
      "last_prediction    0.039492\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 4\n",
      "grade                     4\n",
      "last_prediction    0.049159\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 5\n",
      "grade                     4\n",
      "last_prediction    0.058748\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 6\n",
      "grade                    4\n",
      "last_prediction    0.06826\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 7\n",
      "grade                     4\n",
      "last_prediction    0.077698\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.709013438589473\n",
      "----------\n",
      "round 8\n",
      "grade                     4\n",
      "last_prediction    0.087063\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 9\n",
      "grade                     4\n",
      "last_prediction    0.096357\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 10\n",
      "grade                     4\n",
      "last_prediction    0.105582\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 11\n",
      "grade                     4\n",
      "last_prediction    0.114739\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 12\n",
      "grade                    4\n",
      "last_prediction    0.12383\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 13\n",
      "grade                     4\n",
      "last_prediction    0.132857\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 14\n",
      "grade                    4\n",
      "last_prediction    0.14182\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 15\n",
      "grade                     4\n",
      "last_prediction    0.150722\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 16\n",
      "grade                     4\n",
      "last_prediction    0.159564\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 17\n",
      "grade                     4\n",
      "last_prediction    0.168347\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 18\n",
      "grade                     4\n",
      "last_prediction    0.177072\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 19\n",
      "grade                     4\n",
      "last_prediction    0.185742\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 20\n",
      "grade                     4\n",
      "last_prediction    0.194356\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 21\n",
      "grade                     4\n",
      "last_prediction    0.202916\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 22\n",
      "grade                     4\n",
      "last_prediction    0.211424\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 23\n",
      "grade                    4\n",
      "last_prediction    0.21988\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 24\n",
      "grade                     4\n",
      "last_prediction    0.228285\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 25\n",
      "grade                     4\n",
      "last_prediction    0.236641\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 26\n",
      "grade                     4\n",
      "last_prediction    0.244949\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 27\n",
      "grade                     4\n",
      "last_prediction    0.253209\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 28\n",
      "grade                     4\n",
      "last_prediction    0.261423\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 29\n",
      "grade                     4\n",
      "last_prediction    0.269591\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 30\n",
      "grade                     4\n",
      "last_prediction    0.277715\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 31\n",
      "grade                     4\n",
      "last_prediction    0.285795\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 32\n",
      "grade                     4\n",
      "last_prediction    0.293832\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 33\n",
      "grade                     4\n",
      "last_prediction    0.301828\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 34\n",
      "grade                     4\n",
      "last_prediction    0.309782\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 35\n",
      "grade                     4\n",
      "last_prediction    0.317695\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 36\n",
      "grade                     4\n",
      "last_prediction    0.325569\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 37\n",
      "grade                     4\n",
      "last_prediction    0.333405\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 38\n",
      "grade                     4\n",
      "last_prediction    0.341202\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 39\n",
      "grade                     4\n",
      "last_prediction    0.348962\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 40\n",
      "grade                     4\n",
      "last_prediction    0.356685\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 41\n",
      "grade                     4\n",
      "last_prediction    0.364372\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 42\n",
      "grade                     4\n",
      "last_prediction    0.372024\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 43\n",
      "grade                     4\n",
      "last_prediction    0.379641\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 44\n",
      "grade                     4\n",
      "last_prediction    0.387224\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 45\n",
      "grade                     4\n",
      "last_prediction    0.394774\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 46\n",
      "grade                     4\n",
      "last_prediction    0.402291\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 47\n",
      "grade                     4\n",
      "last_prediction    0.409776\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 48\n",
      "grade                     4\n",
      "last_prediction    0.417229\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      "round 49\n",
      "grade                     4\n",
      "last_prediction    0.424651\n",
      "Name: 0, dtype: object\n",
      "Train DCGs\n",
      "mean    20.692041359674654\n",
      "----------\n",
      " "
     ]
    }
   ],
   "source": [
    "judgments = to_dataframe(ftr_logger.logged)\n",
    "%prun -s cumtime lambdas_per_query = lambda_mart_pure(judgments=judgments, rounds=50, max_leaf_nodes=10, learning_rate=0.01, metric=dcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/RankyMcRankFace.jar already exists\n",
      "Running java -jar /var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/RankyMcRankFace.jar -ranker 6 -shrinkage 0.1 -metric2t DCG@10 -tree 10 -bag 1 -leaf 10 -frate 1.0 -srate 1.0 -train /var/folders/bz/schh49y93yg6323ynrz7j8j00000gn/T/training.txt -save data/title_model.txt \n",
      "Delete model title: 200\n",
      "Created Model title [Status: 201]\n",
      "Model saved\n",
      " Every N rounds of ranklib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.692,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.669,\n",
       " 20.73,\n",
       " 20.7506,\n",
       " 20.6507,\n",
       " 20.7237,\n",
       " 20.7237]"
      ]
     },
     "execution_count": 171,
=======
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid\n",
       "1     49\n",
       "2     60\n",
       "3      7\n",
       "4     42\n",
       "5     32\n",
       "6     24\n",
       "7     15\n",
       "8     31\n",
       "9     15\n",
       "10    29\n",
       "11    15\n",
       "12    15\n",
       "13    15\n",
       "14    22\n",
       "15    52\n",
       "16    44\n",
       "17    23\n",
       "18    16\n",
       "19    43\n",
       "20    29\n",
       "21    15\n",
       "22    16\n",
       "23    37\n",
       "24    67\n",
       "25    37\n",
       "26    18\n",
       "27    19\n",
       "28    22\n",
       "29    36\n",
       "30    16\n",
       "31    20\n",
       "32    47\n",
       "33    15\n",
       "34    42\n",
       "35    15\n",
       "36    15\n",
       "37    16\n",
       "38    23\n",
       "39    24\n",
       "40    50\n",
       "Name: gain, dtype: int64"
      ]
     },
     "execution_count": 133,
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "from ltr.ranklib import train\n",
    "%prun -s cumtime trainLog  = train(client, training_set=ftr_logger.logged, index='tmdb', trees=10, featureSet='movies', modelName='title')\n",
    "\n",
    "print(\"Every N rounds of ranklib\")\n",
    "trainLog.trainingLogs[0].rounds"
   ]
  },
  {
=======
>>>>>>> e7358dd (Use a stable sorting algorithm)
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
=======
    "lambdas_per_query[lambdas_per_query['qid'] == 2]"
   ]
<<<<<<< HEAD
>>>>>>> 4ef4e05 (Save lambda mart)
=======
=======
    "lambdas_per_query[lambdas_per_query['display_rank'] < 10].groupby('qid')['gain'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid\n",
       "1     4.543559\n",
       "2     4.543559\n",
       "3     4.543559\n",
       "4     4.543559\n",
       "5     4.543559\n",
       "6     4.543559\n",
       "7     4.543559\n",
       "8     4.543559\n",
       "9     4.543559\n",
       "10    4.543559\n",
       "11    4.543559\n",
       "12    4.543559\n",
       "13    4.543559\n",
       "14    4.543559\n",
       "15    4.543559\n",
       "16    4.543559\n",
       "17    4.543559\n",
       "18    4.543559\n",
       "19    4.543559\n",
       "20    4.543559\n",
       "21    4.543559\n",
       "22    4.543559\n",
       "23    4.543559\n",
       "24    4.543559\n",
       "25    4.543559\n",
       "26    4.543559\n",
       "27    4.543559\n",
       "28    4.543559\n",
       "29    4.543559\n",
       "30    4.543559\n",
       "31    4.543559\n",
       "32    4.543559\n",
       "33    4.543559\n",
       "34    4.543559\n",
       "35    4.543559\n",
       "36    4.543559\n",
       "37    4.543559\n",
       "38    4.543559\n",
       "39    4.543559\n",
       "40    4.543559\n",
       "Name: discount, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas_per_query[lambdas_per_query['display_rank'] < 10].groupby('qid')['discount'].sum()"
   ]
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
>>>>>>> 12bbee8 (Fix a few minor bugs / add back deleted cells)
=======
>>>>>>> e7358dd (Use a stable sorting algorithm)
=======
>>>>>>> fe36f49 (Save lambdamart implementation on ranklib)
=======
>>>>>>> 2c12ace (Pure pandas implementation wasn't that hard :))
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
