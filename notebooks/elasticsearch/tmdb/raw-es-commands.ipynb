{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from ltr.client import ElasticClient\n",
    "client = ElasticClient()\n",
    "\n",
    "host = client.get_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTR Plugin Initialization\n",
    "The feature store can be removed by sending a DELETE request to `_ltr` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://{}:9200/_ltr/'.format(host)\n",
    "print(url)\n",
    "requests.delete(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the LTR plugin, issue a PUT request to the `_ltr` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://{}:9200/_ltr/'.format(host)\n",
    "print(url)\n",
    "requests.put(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature set can be created by issuing a PUT to `_ltr/featureset/[feature_name]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "   \"featureset\": {\n",
    "      \"features\": [\n",
    "         {\n",
    "            \"name\": \"title_bm25\",\n",
    "            \"params\": [\n",
    "               \"keywords\"\n",
    "            ],\n",
    "            \"template\": {\n",
    "                     \"match\": {\n",
    "                        \"title\": \"{{keywords}}\"\n",
    "                     }\n",
    "               }\n",
    "         },\n",
    "         {\n",
    "            \"name\": \"overview_bm25\",\n",
    "            \"params\": [\n",
    "               \"keywords\"\n",
    "            ],\n",
    "            \"template\": {\n",
    "                     \"match\": {\n",
    "                        \"overview\": \"{{keywords}}\"\n",
    "                     }\n",
    "               }\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "     \"validation\": {\n",
    "      \"index\": \"tmdb\",\n",
    "      \"params\": {\n",
    "         \"keywords\": \"rambo\"\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/_ltr/_featureset/my_feature_set'.format(host)\n",
    "print(url)\n",
    "requests.put(url, json=feature_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching and Logging\n",
    "\n",
    "The following request demonstrates issuing a basic search and viewing the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = {\n",
    "    \"query\": { \n",
    "    \"match\": {\n",
    "        \"title\": \"First Blood\"\n",
    "    }}\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/tmdb/_search'.format(host)\n",
    "print(url)\n",
    "resp = requests.get(url, json=search).json()\n",
    "print(resp['hits']['hits'][0]['_source']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next request demonstrates how to utilize the logging extension with a sltr query.  The sltr query specifies which feature set to utilize and specifies any parameters that the feature set may need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_log = {\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": [\n",
    "        {\n",
    "          \"sltr\": {\n",
    "            \"_name\": \"logged_features\",\n",
    "            \"featureset\": \"my_feature_set\",\n",
    "            \"params\": {\n",
    "              \"keywords\": \"rambo\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "         {\n",
    "          \"terms\": {\n",
    "            \"_id\": [\n",
    "              \"7555\",\"1370\", \"1369\", \"1368\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"ext\": {\n",
    "    \"ltr_log\": {\n",
    "      \"log_specs\": {\n",
    "        \"name\": \"ltr_features\",\n",
    "        \"named_query\": \"logged_features\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/tmdb/_search'.format(host)\n",
    "print(url)\n",
    "resp = requests.get(url, json=search_with_log).json()\n",
    "print(json.dumps(resp['hits']['hits'][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading a Model\n",
    "Once features have been logged and training data has been generated, a model can be pushed into Elasticsearch.  The following shows what a request to PUT a new model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"## LambdaMART\n",
    "## No. of trees = 10\n",
    "## No. of leaves = 10\n",
    "## No. of threshold candidates = 256\n",
    "## Learning rate = 0.1\n",
    "## Stop early = 100\n",
    "\n",
    "<ensemble>\n",
    "\t<tree id=\"1\" weight=\"0.1\">\n",
    "\t\t<split>\n",
    "\t\t\t<feature> 2 </feature>\n",
    "\t\t\t<threshold> 10.664251 </threshold>\n",
    "\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t<output> -1.8305741548538208 </output>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t<threshold> 9.502127 </threshold>\n",
    "\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t<threshold> 7.0849166 </threshold>\n",
    "\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t<output> 0.23645669221878052 </output>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t<output> 1.7593677043914795 </output>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t<output> 1.9719607830047607 </output>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t</split>\n",
    "\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t<output> 1.3728954792022705 </output>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t<threshold> 8.602512 </threshold>\n",
    "\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t\t\t<threshold> 13.815164 </threshold>\n",
    "\t\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.9401178359985352 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.99532949924469 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t\t<threshold> 11.085816 </threshold>\n",
    "\t\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t\t<output> 2.0 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.99308180809021 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t<output> 1.9870178699493408 </output>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t</split>\n",
    "\t\t</split>\n",
    "\t</tree>\n",
    "</ensemble>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "create_model = {\n",
    "  \"model\": {\n",
    "     \"name\": \"my_model\",\n",
    "     \"model\": {\n",
    "         \"type\": \"model/ranklib\",\n",
    "         \"definition\": model\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/_ltr/_featureset/my_feature_set/_createmodel'.format(host)\n",
    "print(url)\n",
    "requests.post(url, json=create_model).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with a Model\n",
    "Now that a model has been uploaded to Elasticsearch we can use it to re-rank the results of a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = {\n",
    "  \"query\": {\n",
    "      \"sltr\": {\n",
    "          \"params\": {\n",
    "              \"keywords\": \"rambo\"\n",
    "          },\n",
    "          \"model\": \"my_model\"\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/tmdb/_search'.format(host)\n",
    "resp = requests.get(url, json=search).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(hit['_source']['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
