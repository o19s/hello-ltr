{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TermStatQuery\n",
    "Introduced in ES-LTR v1.5.2, the TermStatQuery provides for access to deep level statistics available in Lucene expression and Painless scripting contexts.\n",
    "\n",
    "This allows feature engineers to easily experiment with features derived directly from the index without having to write any Java code.\n",
    "\n",
    "Review the documentation [here](https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/advanced-functionality.html#termstat-query) and use the notebook below to experiment with the functionality that the TermStatQuery provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import ElasticClient\n",
    "client = ElasticClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Create a Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  TASK:\n",
    "  Experiment with the TermStatQuery\n",
    "  - Create a feature that utilizes a lucene expression.\n",
    "  - Create a feature that utilizes painless scripting\n",
    "'''\n",
    "\n",
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = {\n",
    "   \"featureset\": {\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"name\": \"tsq_expr_title_tfidf\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"term_stat\": {\n",
    "                        \"expr\": \"tf * idf\",             # The lucene expression evaluated for each term\n",
    "                        \"aggr\": \"max\",                  # How are the calcuated expressions for each term aggregated?\n",
    "                        \"terms\": [\"{{keywords}}\"],      # The list of terms to run the expr on\n",
    "                        \"fields\": [\"title\"]             # Which fields to lookup terms in\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"tsq_script_title_unique_terms\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template_language\": \"script_feature\",\n",
    "                \"template\": {\n",
    "                    \"lang\": \"painless\",\n",
    "                    \"source\": \"params.uniqueTerms\",\n",
    "                    \"params\": {\n",
    "                        \"term_stat\": {\n",
    "                            \"analyzer\": \"!standard\",\n",
    "                            \"terms\": \"keywordsList\",\n",
    "                            \"fields\": [\"title\"]\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "client.create_featureset(index='tmdb', name='sandbox', ftr_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Log Features for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open, to_dataframe\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='sandbox')\n",
    "with judgments_open('data/title_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))\n",
    "\n",
    "df = to_dataframe(ftr_logger.logged)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  TASK:\n",
    "  Experiment with the leafs and trees variables, how do they affect NGCG?\n",
    "  Does a high leaf value increase your NDCG?  What could be the potential downfalls?\n",
    "'''\n",
    "from ltr.ranklib import train\n",
    "trainResponse  = train(client,\n",
    "                  index='tmdb',\n",
    "                  training_set=ftr_logger.logged,\n",
    "                  metric2t='NDCG@10',\n",
    "                  leafs=20,\n",
    "                  trees=20,\n",
    "                  featureSet='sandbox',\n",
    "                  modelName='sandbox')\n",
    "\n",
    "trainLog = trainResponse.trainingLogs[0]\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(client.get_feature_name(config, ftrId), impact))\n",
    "    \n",
    "for roundDcg in trainLog.rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Train NDCG@10 %s\" % trainLog.rounds[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr import search\n",
    "search(client, \"rambo\", modelName='sandbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
