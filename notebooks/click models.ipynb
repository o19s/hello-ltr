{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.clickmodels.session import build\n",
    "\n",
    "# Sessions for search queries \"rambo\" and \"star trek\"\n",
    "sessions = build([\n",
    "      ('rambo',     ((1, True), (2, False), (3, True), (0, False))),\n",
    "      ('star trek', ((5, False), (2, True), (3, True), (0, False))),\n",
    "      ('rambo',     ((1, False), (2, False), (3, True), (0, False))),\n",
    "      ('star trek', ((1, False), (2, False), (3, False), (9, True))),\n",
    "      ('rambo',     ((9, False), (2, False), (1, True), (0, True))),\n",
    "      ('star trek', ((6, True), (2, False), (3, True), (1, False))),\n",
    "      ('rambo',     ((7, False), (4, True), (1, False), (3, False))),\n",
    "      ('star trek', ((8, True), (2, False), (3, True), (1, False))),\n",
    "      ('rambo',     ((1, False), (4, True), (2, False), (3, False))),\n",
    "      ('star trek', ((7, True), (4, False), (5, True), (1, True)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_query(judgment_dict):\n",
    "    from collections import defaultdict\n",
    "    by_query_ranked = defaultdict(list)\n",
    "    \n",
    "    for (query, doc), score in judgment_dict.items():\n",
    "        by_query_ranked[query].append((doc,score))\n",
    "        \n",
    "    for query, items in by_query_ranked.items():\n",
    "        items.sort(key=lambda score_doc: score_doc[1], reverse=True)\n",
    "        \n",
    "    return by_query_ranked\n",
    "\n",
    "def just_doc_ids(docs):\n",
    "    return [doc[0] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COEC \n",
    "(Clicks Over Expected Clicks)\n",
    "\n",
    "Clicks relative to CTR at that position. > 1 means above average, < 1 means below average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.clickmodels.coec import coec\n",
    "\n",
    "ctrs_by_rank = [0.15,0.15,0.15,0.03]\n",
    "\n",
    "model = coec(ctrs_by_rank, sessions)\n",
    "coec_judgments = by_query(model.coecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PBM\n",
    "\n",
    "(Position-Based model)\n",
    "\n",
    "We learn probability of a rank being examined and the attractiveness of a query-doc pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.clickmodels.pbm import position_based_model\n",
    "model = position_based_model(sessions, rounds=50)\n",
    "pbm_judgments = by_query(model.attracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbm_judgments['rambo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.helpers.tau import tau\n",
    "from ltr.helpers.tau import avg_tau\n",
    "\n",
    "rambo1 = just_doc_ids(coec_judgments['rambo'])\n",
    "rambo1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rambo2 = just_doc_ids(pbm_judgments['rambo'])\n",
    "rambo2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tau(rambo1, rambo2, at=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_trek1 = just_doc_ids(coec_judgments['star trek'])\n",
    "star_trek1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_trek2 = just_doc_ids(pbm_judgments['star trek'])\n",
    "star_trek2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tau(star_trek1, star_trek2, at=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UBM\n",
    "\n",
    "(User Browse Model)\n",
    "\n",
    "Variant of PBM model that computes examination as a function of this position and the last clicked position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.clickmodels.ubm import user_browse_model\n",
    "\n",
    "# Sessions for search queries \"rambo\" and \"star trek\"\n",
    "sessions2 = build([\n",
    "      ('rambo',     ((1, True), (2, False))),\n",
    "      ('star trek', ((5, False), (2, True))),\n",
    "      ('rambo',     ((1, True), (2, False))),\n",
    "      ('star trek', ((5, False), (2, True)))\n",
    "    \n",
    "    ])\n",
    "\n",
    "model = user_browse_model(sessions2, rounds=50)\n",
    "model.attracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Model\n",
    "\n",
    "A variant of the model that computes relevance based on clicks over times the article appeared at or before the first click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.clickmodels.cascade import cascade_model\n",
    "model = cascade_model(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.attracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDBN\n",
    "\n",
    "Simplified version of the Dynamic Bayesian Network, that computes satisfaction and attractiveness. Satisfaction is the times this item was clicked relative to all sessions that item was clicked. Attractiveness how often this item was clicked relative to all sessions with that query/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.clickmodels.sdbn import sdbn\n",
    "model = sdbn(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.attracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.satisfacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
